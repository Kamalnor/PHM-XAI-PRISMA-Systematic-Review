"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"A2CZCFFY","journalArticle","2020","Punn, Narinder Singh; Agarwal, Sonali","Automated diagnosis of COVID-19 with limited posteroanterior chest X-ray images using fine-tuned deep neural networks","Applied Intelligence","","1573-7497","10.1007/s10489-020-01900-3","https://doi.org/10.1007/s10489-020-01900-3","The novel coronavirus 2019 (COVID-19) is a respiratory syndrome that resembles pneumonia. The current diagnostic procedure of COVID-19 follows reverse-transcriptase polymerase chain reaction (RT-PCR) based approach which however is less sensitive to identify the virus at the initial stage. Hence, a more robust and alternate diagnosis technique is desirable. Recently, with the release of publicly available datasets of corona positive patients comprising of computed tomography (CT) and chest X-ray (CXR) imaging; scientists, researchers and healthcare experts are contributing for faster and automated diagnosis of COVID-19 by identifying pulmonary infections using deep learning approaches to achieve better cure and treatment. These datasets have limited samples concerned with the positive COVID-19 cases, which raise the challenge for unbiased learning. Following from this context, this article presents the random oversampling and weighted class loss function approach for unbiased fine-tuned learning (transfer learning) in various state-of-the-art deep learning approaches such as baseline ResNet, Inception-v3, Inception ResNet-v2, DenseNet169, and NASNetLarge to perform binary classification (as normal and COVID-19 cases) and also multi-class classification (as COVID-19, pneumonia, and normal case) of posteroanterior CXR images. Accuracy, precision, recall, loss, and area under the curve (AUC) are utilized to evaluate the performance of the models. Considering the experimental results, the performance of each model is scenario dependent; however, NASNetLarge displayed better scores in contrast to other architectures, which is further compared with other recently proposed approaches. This article also added the visual explanation to illustrate the basis of model classification and perception of COVID-19 in CXR images.","2020-10-17","2021-06-07 21:19:44","2021-06-08 18:59:25","2021-06-07 21:19:41","2689-2702","","5","51","","Appl Intell","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\CYHNB9RY\Punn and Agarwal - 2021 - Automated diagnosis of COVID-19 with limited poste.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PN5UGPPD","journalArticle","2021","Steed, Ryan; Caliskan, Aylin","A set of distinct facial traits learned by machines is not predictive of appearance bias in the wild","AI and Ethics","","2730-5961","10.1007/s43681-020-00035-y","https://doi.org/10.1007/s43681-020-00035-y","Research in social psychology has shown that people’s biased, subjective judgments about another’s personality based solely on their appearance are not predictive of their actual personality traits. But researchers and companies often utilize computer vision models to predict similarly subjective personality attributes such as “employability”. We seek to determine whether state-of-the-art, black box face processing technology can learn human-like appearance biases. With features extracted with FaceNet, a widely used face recognition framework, we train a transfer learning model on human subjects’ first impressions of personality traits in other faces as measured by social psychologists. We find that features extracted with FaceNet can be used to predict human appearance bias scores for deliberately manipulated faces but not for randomly generated faces scored by humans. Additionally, in contrast to work with human biases in social psychology, the model does not find a significant signal correlating politicians’ vote shares with perceived competence bias. With Local Interpretable Model-Agnostic Explanations (LIME), we provide several explanations for this discrepancy. Our results suggest that some signals of appearance bias documented in social psychology are not embedded by the machine learning techniques we investigate. We shed light on the ways in which appearance bias could be embedded in face processing technology and cast further doubt on the practice of predicting subjective traits based on appearances.","2021-01-12","2021-06-07 21:19:44","2021-06-07 21:19:44","2021-06-07 21:19:42","","","","","","AI Ethics","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\5SGN6UQV\Steed and Caliskan - 2021 - A set of distinct facial traits learned by machine.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UPJM6ICQ","journalArticle","2021","Ruiz, Alejandro Pasos; Flynn, Michael; Large, James; Middlehurst, Matthew; Bagnall, Anthony","The great multivariate time series classification bake off: a review and experimental evaluation of recent algorithmic advances","Data Mining and Knowledge Discovery","","1573-756X","10.1007/s10618-020-00727-3","https://doi.org/10.1007/s10618-020-00727-3","Time Series Classification (TSC) involves building predictive models for a discrete target variable from ordered, real valued, attributes. Over recent years, a new set of TSC algorithms have been developed which have made significant improvement over the previous state of the art. The main focus has been on univariate TSC, i.e. the problem where each case has a single series and a class label. In reality, it is more common to encounter multivariate TSC (MTSC) problems where the time series for a single case has multiple dimensions. Despite this, much less consideration has been given to MTSC than the univariate case. The UCR archive has provided a valuable resource for univariate TSC, and the lack of a standard set of test problems may explain why there has been less focus on MTSC. The UEA archive of 30 MTSC problems released in 2018 has made comparison of algorithms easier. We review recently proposed bespoke MTSC algorithms based on deep learning, shapelets and bag of words approaches. If an algorithm cannot naturally handle multivariate data, the simplest approach to adapt a univariate classifier to MTSC is to ensemble it over the multivariate dimensions. We compare the bespoke algorithms to these dimension independent approaches on the 26 of the 30 MTSC archive problems where the data are all of equal length. We demonstrate that four classifiers are significantly more accurate than the benchmark dynamic time warping algorithm and that one of these recently proposed classifiers, ROCKET, achieves significant improvement on the archive datasets in at least an order of magnitude less time than the other three.","2021-03-01","2021-06-07 21:19:44","2021-06-07 21:19:44","2021-06-07 21:19:42","401-449","","2","35","","Data Min Knowl Disc","The great multivariate time series classification bake off","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\DRYZD6N2\Ruiz et al. - 2021 - The great multivariate time series classification .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDNBML7V","journalArticle","2020","Yuan, Jun; Chen, Changjian; Yang, Weikai; Liu, Mengchen; Xia, Jiazhi; Liu, Shixia","A survey of visual analytics techniques for machine learning","Computational Visual Media","","2096-0662","10.1007/s41095-020-0191-7","https://doi.org/10.1007/s41095-020-0191-7","Visual analytics for machine learning has recently evolved as one of the most exciting areas in the field of visualization. To better identify which research topics are promising and to learn how to apply relevant techniques in visual analytics, we systematically review 259 papers published in the last ten years together with representative works before 2010. We build a taxonomy, which includes three first-level categories: techniques before model building, techniques during modeling building, and techniques after model building. Each category is further characterized by representative analysis tasks, and each task is exemplified by a set of recent influential works. We also discuss and highlight research challenges and promising potential future research opportunities useful for visual analytics researchers.","2020-11-25","2021-06-07 21:19:44","2021-06-08 19:01:49","2021-06-07 21:19:42","3-36","","1","7","","Comp. Visual Media","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\7UBIM9AD\Yuan et al. - 2021 - A survey of visual analytics techniques for machin.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D4CLKBQN","journalArticle","2020","Vallez, Noelia; Velasco-Mata, Alberto; Deniz, Oscar","Deep autoencoder for false positive reduction in handgun detection","Neural Computing and Applications","","1433-3058","10.1007/s00521-020-05365-w","https://doi.org/10.1007/s00521-020-05365-w","In an object detection system, the main objective during training is to maintain the detection and false positive rates under acceptable levels when the model is run over the test set. However, this typically translates into an unacceptable rate of false alarms when the system is deployed in a real surveillance scenario. To deal with this situation, which often leads to system shutdown, we propose to add a filter step to discard part of the new false positive detections that are typical of the new scenario. This step consists of a deep autoencoder trained with the false alarm detections generated after running the detector over a period of time in the new scenario. Therefore, this step will be in charge of determining whether the detection is a typical false alarm of that scenario or whether it is something anomalous for the autoencoder and, therefore, a true detection. In order to decide whether a detection must be filtered, three different approaches have been tested. The first one uses the autoencoder reconstruction error measured with the mean squared error to make the decision. The other two use the k-NN (k-nearest neighbors) and one-class SVMs (support vector machines) classifiers trained with the autoencoder vector representation. In addition, a synthetic scenario has been generated with Unreal Engine 4 to test the proposed methods in addition to a dataset with real images. The results obtained show a reduction in the number of false positives between 22.5% and 87.2% and an increase in the system’s precision of 1.2%$$-47$$% when the autoencoder is applied.","2020-09-25","2021-06-07 21:19:44","2021-06-08 18:58:47","2021-06-07 21:19:43","5885-5895","","11","33","","Neural Comput & Applic","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\TZMF6FW4\Vallez et al. - 2021 - Deep autoencoder for false positive reduction in h.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UQIXB8VW","journalArticle","2021","Yuan, Haitao; Li, Guoliang","A Survey of Traffic Prediction: from Spatio-Temporal Data to Intelligent Transportation","Data Science and Engineering","","2364-1541","10.1007/s41019-020-00151-z","https://doi.org/10.1007/s41019-020-00151-z","Intelligent transportation (e.g., intelligent traffic light) makes our travel more convenient and efficient. With the development of mobile Internet and position technologies, it is reasonable to collect spatio-temporal data and then leverage these data to achieve the goal of intelligent transportation, and here, traffic prediction plays an important role. In this paper, we provide a comprehensive survey on traffic prediction, which is from the spatio-temporal data layer to the intelligent transportation application layer. At first, we split the whole research scope into four parts from bottom to up, where the four parts are, respectively, spatio-temporal data, preprocessing, traffic prediction and traffic application. Later, we review existing work on the four parts. First, we summarize traffic data into five types according to their difference on spatial and temporal dimensions. Second, we focus on four significant data preprocessing techniques: map-matching, data cleaning, data storage and data compression. Third, we focus on three kinds of traffic prediction problems (i.e., classification, generation and estimation/forecasting). In particular, we summarize the challenges and discuss how existing methods address these challenges. Fourth, we list five typical traffic applications. Lastly, we provide emerging research challenges and opportunities. We believe that the survey can help the partitioners to understand existing traffic prediction problems and methods, which can further encourage them to solve their intelligent transportation applications.","2021-03-01","2021-06-07 21:19:44","2021-06-07 21:19:44","2021-06-07 21:19:43","63-85","","1","6","","Data Sci. Eng.","A Survey of Traffic Prediction","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\5BCC74BR\Yuan and Li - 2021 - A Survey of Traffic Prediction from Spatio-Tempor.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FHJAIH2W","journalArticle","2021","Sekiguchi, Kaira; Hori, Koichi","Designing ethical artifacts has resulted in creative design","AI & SOCIETY","","1435-5655","10.1007/s00146-020-01043-6","https://doi.org/10.1007/s00146-020-01043-6","Ethical aspects in engineering design have become increasingly important in recent years. A typical example is the recent rise of artificial intelligence (AI) ethics. This paper applies user studies of a design support tool to empirically verify that our ethical framework improves the creativity of an engineer’s design activity. The design support tool provides an environment for the promotion of ethical design perspectives and description. The experiments focus on two functionalities: semi-automatic generation and scenario path recommendation. These functions are designed around the application of ethical design theory, which extends the hierarchical representation of artifacts. Doing this enables users to reconsider their themes at the highest level of the hierarchy and to apply a wider conceptual space of design solutions. For example, by reconsidering the positions of their research themes in the space of the representation field, users can semi-automatically edit them and identify focal areas. Using the scenario path recommendation, designers can update their research themes after considering the ethical impacts of those themes on stakeholders. Both functions are realized by exploiting a knowledge base of ethical and technological discourses. Finally, the ethical design theory is updated based on some unexpected results of our user studies with regards to the cyclic relationship among theory, tools (i.e., experimental equipment), and observed data. For example, temporal dimensional aspects were confirmed as important.","2021-03-01","2021-06-07 21:19:44","2021-06-07 21:19:44","2021-06-07 21:19:43","101-148","","1","36","","AI & Soc","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\LGA595NZ\Sekiguchi and Hori - 2021 - Designing ethical artifacts has resulted in creati.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"37YAA2V8","journalArticle","2019","Manogaran, Gunasekaran; Chilamkurti, Naveen; Hsu, Ching-Hsien","A A EDITORIAL Emerging intelligent algorithms: challenges and applications","Neural Computing and Applications","","1433-3058","10.1007/s00521-018-3930-2","https://doi.org/10.1007/s00521-018-3930-2","","2019-05-01","2021-06-07 21:20:08","2021-06-17 14:06:25","2021-06-07 21:20:04","1259-1262","","5","31","","Neural Comput & Applic","Emerging intelligent algorithms","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\JTIJXFJE\Manogaran et al. - 2019 - Emerging intelligent algorithms challenges and ap.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZZCETW6P","journalArticle","2019","Ismail, Ahmed; Truong, Hong-Linh; Kastner, Wolfgang","Manufacturing process data analysis pipelines: a requirements analysis and survey","Journal of Big Data","","2196-1115","10.1186/s40537-018-0162-3","https://doi.org/10.1186/s40537-018-0162-3","Smart manufacturing is strongly correlated with the digitization of all manufacturing activities. This increases the amount of data available to drive productivity and profit through data-driven decision making programs. The goal of this article is to assist data engineers in designing big data analysis pipelines for manufacturing process data. Thus, this paper characterizes the requirements for process data analysis pipelines and surveys existing platforms from academic literature. The results demonstrate a stronger focus on the storage and analysis phases of pipelines than on the ingestion, communication, and visualization stages. Results also show a tendency towards custom tools for ingestion and visualization, and relational data tools for storage and analysis. Tools for handling heterogeneous data are generally well-represented throughout the pipeline. Finally, batch processing tools are more widely adopted than real-time stream processing frameworks, and most pipelines opt for a common script-based data processing approach. Based on these results, recommendations are offered for each phase of the pipeline.","2019-01-07","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:04","1","","1","6","","J Big Data","Manufacturing process data analysis pipelines","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\CYFIEG3C\Ismail et al. - 2019 - Manufacturing process data analysis pipelines a r.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TKKVUQ2D","journalArticle","2020","Ma, Zhengjing; Mei, Gang; Piccialli, Francesco","Machine learning for landslides prevention: a survey","Neural Computing and Applications","","1433-3058","10.1007/s00521-020-05529-8","https://doi.org/10.1007/s00521-020-05529-8","Landslides are one of the most critical categories of natural disasters worldwide and induce severely destructive outcomes to human life and the overall economic system. To reduce its negative effects, landslides prevention has become an urgent task, which includes investigating landslide-related information and predicting potential landslides. Machine learning is a state-of-the-art analytics tool that has been widely used in landslides prevention. This paper presents a comprehensive survey of relevant research on machine learning applied in landslides prevention, mainly focusing on (1) landslides detection based on images, (2) landslides susceptibility assessment, and (3) the development of landslide warning systems. Moreover, this paper discusses the current challenges and potential opportunities in the application of machine learning algorithms for landslides prevention.","2020-11-22","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:05","","","","","","Neural Comput & Applic","Machine learning for landslides prevention","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\R65RA4MB\Ma et al. - 2020 - Machine learning for landslides prevention a surv.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7CBGDIJB","journalArticle","2019","Lubba, Carl H.; Sethi, Sarab S.; Knaute, Philip; Schultz, Simon R.; Fulcher, Ben D.; Jones, Nick S.","catch22: CAnonical Time-series CHaracteristics","Data Mining and Knowledge Discovery","","1573-756X","10.1007/s10618-019-00647-x","https://doi.org/10.1007/s10618-019-00647-x","Capturing the dynamical properties of time series concisely as interpretable feature vectors can enable efficient clustering and classification for time-series applications across science and industry. Selecting an appropriate feature-based representation of time series for a given application can be achieved through systematic comparison across a comprehensive time-series feature library, such as those in the hctsa toolbox. However, this approach is computationally expensive and involves evaluating many similar features, limiting the widespread adoption of feature-based representations of time series for real-world applications. In this work, we introduce a method to infer small sets of time-series features that (i) exhibit strong classification performance across a given collection of time-series problems, and (ii) are minimally redundant. Applying our method to a set of 93 time-series classification datasets (containing over 147,000 time series) and using a filtered version of the hctsa feature library (4791 features), we introduce a set of 22 CAnonical Time-series CHaracteristics, catch22, tailored to the dynamics typically encountered in time-series data-mining tasks. This dimensionality reduction, from 4791 to 22, is associated with an approximately 1000-fold reduction in computation time and near linear scaling with time-series length, despite an average reduction in classification accuracy of just 7%. catch22 captures a diverse and interpretable signature of time series in terms of their properties, including linear and non-linear autocorrelation, successive differences, value distributions and outliers, and fluctuation scaling properties. We provide an efficient implementation of catch22, accessible from many programming environments, that facilitates feature-based time-series analysis for scientific, industrial, financial and medical applications using a common language of interpretable time-series properties.","2019-11-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:05","1821-1852","","6","33","","Data Min Knowl Disc","catch22","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\A36G99HI\Lubba et al. - 2019 - catch22 CAnonical Time-series CHaracteristics.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5JMNT76","journalArticle","2020","Karlsson, Isak; Rebane, Jonathan; Papapetrou, Panagiotis; Gionis, Aristides","Locally and globally explainable time series tweaking","Knowledge and Information Systems","","0219-3116","10.1007/s10115-019-01389-4","https://doi.org/10.1007/s10115-019-01389-4","Time series classification has received great attention over the past decade with a wide range of methods focusing on predictive performance by exploiting various types of temporal features. Nonetheless, little emphasis has been placed on interpretability and explainability. In this paper, we formulate the novel problem of explainable time series tweaking, where, given a time series and an opaque classifier that provides a particular classification decision for the time series, we want to find the changes to be performed to the given time series so that the classifier changes its decision to another class. We show that the problem is $${\mathbf {NP}}$$-hard, and focus on three instantiations of the problem using global and local transformations. In the former case, we investigate the k-nearest neighbor classifier and provide an algorithmic solution to the global time series tweaking problem. In the latter case, we investigate the random shapelet forest classifier and focus on two instantiations of the local time series tweaking problem, which we refer to as reversible and irreversible time series tweaking, and propose two algorithmic solutions for the two problems along with simple optimizations. An extensive experimental evaluation on a variety of real datasets demonstrates the usefulness and effectiveness of our problem formulation and solutions.","2020-05-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:05","1671-1700","","5","62","","Knowl Inf Syst","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\88BQ7AG5\Karlsson et al. - 2020 - Locally and globally explainable time series tweak.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GARA2CL9","journalArticle","2020","Casale, G.; Artač, M.; van den Heuvel, W.-J.; van Hoorn, A.; Jakovits, P.; Leymann, F.; Long, M.; Papanikolaou, V.; Presenza, D.; Russo, A.; Srirama, S. N.; Tamburri, D. A.; Wurster, M.; Zhu, L.","RADON: rational decomposition and orchestration for serverless computing","SICS Software-Intensive Cyber-Physical Systems","","2524-8529","10.1007/s00450-019-00413-w","https://doi.org/10.1007/s00450-019-00413-w","Emerging serverless computing technologies, such as function as a service (FaaS), enable developers to virtualize the internal logic of an application, simplifying the management of cloud-native services and allowing cost savings through billing and scaling at the level of individual functions. Serverless computing is therefore rapidly shifting the attention of software vendors to the challenge of developing cloud applications deployable on FaaS platforms. In this vision paper, we present the research agenda of the RADON project (http://radon-h2020.eu), which aims to develop a model-driven DevOps framework for creating and managing applications based on serverless computing. RADON applications will consist of fine-grained and independent microservices that can efficiently and optimally exploit FaaS and container technologies. Our methodology strives to tackle complexity in designing such applications, including the solution of optimal decomposition, the reuse of serverless functions as well as the abstraction and actuation of event processing chains, while avoiding cloud vendor lock-in through models.","2020-08-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:05","77-87","","1","35","","SICS Softw.-Inensiv. Cyber-Phys. Syst.","RADON","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\3QWRHKVT\Casale et al. - 2020 - RADON rational decomposition and orchestration fo.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MV5E6Y7N","journalArticle","2020","Pannu, Husanbir Singh; Ahuja, Sahil; Dang, Nitin; Soni, Sahil; Malhi, Avleen Kaur","Deep learning based image classification for intestinal hemorrhage","Multimedia Tools and Applications","","1573-7721","10.1007/s11042-020-08905-7","https://doi.org/10.1007/s11042-020-08905-7","Convolutional neural networks (CNN) have become a popular choice for image segmentation and classification. Internal body images are obscure in nature with involvement of noise, luminance variation, rotation and blur. Thus optimal choice of features for machine learning model to classify bleeding is still an open problem. CNN is efficient for attribute selection and ensemble learning makes a generalized robust system. Capsule endoscopy is a new technology which enables a gastroenterologist to visualize the entire digestive tract including small bowel to diagnose bleeding, ulcer and polyp. This paper presents a supervised learning ensemble to detect the bleeding in the images of Wireless Capsule Endoscopy. It accurately finds out the best possible combination of attributes required to classify bleeding symptoms in endoscopy images. A careful setting for CNN layer options and optimizer for back propagation after reducing the color palette using minimum variance quantization has shown promising results. Results of testing on public and real dataset has been analyzed. Proposed ensemble is able to achieve 0.95 on the public endoscopy dataset and 0.93 accuracy on the real video dataset. A detailed data analysis has also been incorporated in the study including RGB pixel intensities, distributions of binary classes and various class ratios for training.","2020-08-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:05","21941-21966","","29","79","","Multimed Tools Appl","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\TVL4RL2D\Pannu et al. - 2020 - Deep learning based image classification for intes.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9UIRB7TW","journalArticle","2020","Illankoon, Prasanna; Tretten, Phillip","Collaborating AI and human experts in the maintenance domain","AI & SOCIETY","","1435-5655","10.1007/s00146-020-01076-x","https://doi.org/10.1007/s00146-020-01076-x","Maintenance decision errors can result in very costly problems. The 4th industrial revolution has given new opportunities for the development of and use of intelligent decision support systems. With these technological advancements, key concerns focus on gaining a better understanding of the linkage between the technicians’ knowledge and the intelligent decision support systems. The research reported in this study has two primary objectives. (1) To propose a theoretical model that links technicians’ knowledge and intelligent decision support systems, and (2) to present a use case how to apply the theoretical model. The foundation of the new model builds upon two main streams of study in the decision support literature: “distribution” of knowledge among different agents, and “collaboration” of knowledge for reaching a shared goal. This study resulted in the identification of two main gaps: firstly, there must be a greater focus upon the technicians’ knowledge; secondly, technicians need assistance to maintain their focus on the big picture. We used the cognitive fit theory, and the theory of distributed situation awareness to propose the new theoretical model called “distributed collaborative awareness model.” The model considers both explicit and implicit knowledge and accommodates the dynamic challenges involved in operational level maintenance. As an application of this model, we identify and recommend some technological developments required in augmented reality based maintenance decision support.","2020-10-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:05","","","","","","AI & Soc","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\VVDYRY6H\Illankoon and Tretten - 2020 - Collaborating AI and human experts in the maintena.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BTT3TKVX","journalArticle","2021","Singh, Rajeev Kumar; Pandey, Rohan; Babu, Rishie Nandhan","COVIDScreen: explainable deep learning framework for differential diagnosis of COVID-19 using chest X-rays","Neural Computing and Applications","","1433-3058","10.1007/s00521-020-05636-6","https://doi.org/10.1007/s00521-020-05636-6","COVID-19 has emerged as a global crisis with unprecedented socio-economic challenges, jeopardizing our lives and livelihoods for years to come. The unavailability of vaccines for COVID-19 has rendered rapid testing of the population instrumental in order to contain the exponential rise in cases of infection. Shortage of RT-PCR test kits and delays in obtaining test results calls for alternative methods of rapid and reliable diagnosis. In this article, we propose a novel deep learning-based solution using chest X-rays which can help in rapid triaging of COVID-19 patients. The proposed solution uses image enhancement, image segmentation, and employs a modified stacked ensemble model consisting of four CNN base-learners along with Naive Bayes as meta-learner to classify chest X-rays into three classes viz. COVID-19, pneumonia, and normal. An effective pruning strategy as introduced in the proposed framework results in increased model performance, generalizability, and decreased model complexity. We incorporate explainability in our article by using Grad-CAM visualization in order to establish trust in the medical AI system. Furthermore, we evaluate multiple state-of-the-art GAN architectures and their ability to generate realistic synthetic samples of COVID-19 chest X-rays to deal with limited numbers of training samples. The proposed solution significantly outperforms existing methods, with 98.67% accuracy, 0.98 Kappa score, and F-1 scores of 100, 98, and 98 for COVID-19, normal, and pneumonia classes, respectively, on standard datasets. The proposed solution can be used as one element of patient evaluation along with gold-standard clinical and laboratory testing.","2021-01-08","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:06","","","","","","Neural Comput & Applic","COVIDScreen","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\JY56EBJZ\Singh et al. - 2021 - COVIDScreen explainable deep learning framework f.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U65SY4SW","journalArticle","2017","Zheng, Nan-ning; Liu, Zi-yi; Ren, Peng-ju; Ma, Yong-qiang; Chen, Shi-tao; Yu, Si-yu; Xue, Jian-ru; Chen, Ba-dong; Wang, Fei-yue","Hybrid-augmented intelligence: collaboration and cognition","Frontiers of Information Technology & Electronic Engineering","","2095-9230","10.1631/FITEE.1700053","https://doi.org/10.1631/FITEE.1700053","The long-term goal of artificial intelligence (AI) is to make machines learn and think like human beings. Due to the high levels of uncertainty and vulnerability in human life and the open-ended nature of problems that humans are facing, no matter how intelligent machines are, they are unable to completely replace humans. Therefore, it is necessary to introduce human cognitive capabilities or human-like cognitive models into AI systems to develop a new form of AI, that is, hybrid-augmented intelligence. This form of AI or machine intelligence is a feasible and important developing model. Hybrid-augmented intelligence can be divided into two basic models: one is human-in-the-loop augmented intelligence with human-computer collaboration, and the other is cognitive computing based augmented intelligence, in which a cognitive model is embedded in the machine learning system. This survey describes a basic framework for human-computer collaborative hybrid-augmented intelligence, and the basic elements of hybrid-augmented intelligence based on cognitive computing. These elements include intuitive reasoning, causal models, evolution of memory and knowledge, especially the role and basic principles of intuitive reasoning for complex problem solving, and the cognitive learning framework for visual scene understanding based on memory and reasoning. Several typical applications of hybrid-augmented intelligence in related fields are given.","2017-02-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:06","153-179","","2","18","","Frontiers Inf Technol Electronic Eng","Hybrid-augmented intelligence","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\2KBPCXK4\Zheng et al. - 2017 - Hybrid-augmented intelligence collaboration and c.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJC5DXS2","journalArticle","2017","Zaharieva, Maia; Breiteneder, Christian; Hudec, Marcus","Unsupervised group feature selection for media classification","International Journal of Multimedia Information Retrieval","","2192-662X","10.1007/s13735-017-0126-y","https://doi.org/10.1007/s13735-017-0126-y","The selection of an appropriate feature set is crucial for the efficient analysis of any media collection. In general, feature selection strongly depends on the data and commonly requires expert knowledge and previous experiments in related application scenarios. Current unsupervised feature selection methods usually ignore existing relationships among components of multi-dimensional features (group features) and operate on single feature components. In most applications, features carry little semantics. Thus, it is less relevant if a feature set consists of complete features or a selection of single feature components. However, in some domains, such as content-based audio retrieval, features are designed in a way that they, as a whole, have considerable semantic meaning. The disruption of a group feature in such application scenarios impedes the interpretability of the results. In this paper, we propose an unsupervised group feature selection algorithm based on canonical correlation analysis (CCA). Experiments with different audio and video classification scenarios demonstrate the outstanding performance of the proposed approach and its robustness across different datasets.","2017-09-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:06","233-249","","3","6","","Int J Multimed Info Retr","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\K3NZDYDW\Zaharieva et al. - 2017 - Unsupervised group feature selection for media cla.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DWNKB78H","journalArticle","2020","Islam, Md Rafiqul; Liu, Shaowu; Wang, Xianzhi; Xu, Guandong","Deep learning for misinformation detection on online social networks: a survey and new perspectives","Social Network Analysis and Mining","","1869-5469","10.1007/s13278-020-00696-x","https://doi.org/10.1007/s13278-020-00696-x","Recently, the use of social networks such as Facebook, Twitter, and Sina Weibo has become an inseparable part of our daily lives. It is considered as a convenient platform for users to share personal messages, pictures, and videos. However, while people enjoy social networks, many deceptive activities such as fake news or rumors can mislead users into believing misinformation. Besides, spreading the massive amount of misinformation in social networks has become a global risk. Therefore, misinformation detection (MID) in social networks has gained a great deal of attention and is considered an emerging area of research interest. We find that several studies related to MID have been studied to new research problems and techniques. While important, however, the automated detection of misinformation is difficult to accomplish as it requires the advanced model to understand how related or unrelated the reported information is when compared to real information. The existing studies have mainly focused on three broad categories of misinformation: false information, fake news, and rumor detection. Therefore, related to the previous issues, we present a comprehensive survey of automated misinformation detection on (i) false information, (ii) rumors, (iii) spam, (iv) fake news, and (v) disinformation. We provide a state-of-the-art review on MID where deep learning (DL) is used to automatically process data and create patterns to make decisions not only to extract global features but also to achieve better results. We further show that DL is an effective and scalable technique for the state-of-the-art MID. Finally, we suggest several open issues that currently limit real-world implementation and point to future directions along this dimension.","2020-09-29","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:06","82","","1","10","","Soc. Netw. Anal. Min.","Deep learning for misinformation detection on online social networks","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\T35T99ZH\Islam et al. - 2020 - Deep learning for misinformation detection on onli.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JU28443F","journalArticle","2019","Krempl, G.; Lang, D.; Hofer, V.","Temporal density extrapolation using a dynamic basis approach","Data Mining and Knowledge Discovery","","1573-756X","10.1007/s10618-019-00636-0","https://doi.org/10.1007/s10618-019-00636-0","Density estimation is a versatile technique underlying many data mining tasks and techniques, ranging from exploration and presentation of static data, to probabilistic classification, or identifying changes or irregularities in streaming data. With the pervasiveness of embedded systems and digitisation, this latter type of streaming and evolving data becomes more important. Nevertheless, research in density estimation has so far focused on stationary data, leaving the task of of extrapolating and predicting density at time points outside a training window an open problem. For this task, temporal density extrapolation (TDX) is proposed. This novel method models and predicts gradual monotonous changes in a distribution. It is based on the expansion of basis functions, whose weights are modelled as functions of compositional data over time by using an isometric log-ratio transformation. Extrapolated density estimates are then obtained by extrapolating the weights to the requested time point, and querying the density from the basis functions with back-transformed weights. Our approach aims for broad applicability by neither being restricted to a specific parametric distribution, nor relying on cluster structure in the data. It requires only two additional extrapolation-specific parameters, for which reasonable defaults exist. Experimental evaluation on various data streams, synthetic as well as from the real-world domains of credit scoring and environmental health, shows that the model manages to capture monotonous drift patterns accurately and better than existing methods. Thereby, it requires not more than 1.5 times the run time of a corresponding static density estimation approach.","2019-09-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:06","1323-1356","","5","33","","Data Min Knowl Disc","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\RKAWVB2Q\Krempl et al. - 2019 - Temporal density extrapolation using a dynamic bas.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U9YBKK4G","journalArticle","2020","Noor, Manan Binth Taj; Zenia, Nusrat Zerin; Kaiser, M. Shamim; Mamun, Shamim Al; Mahmud, Mufti","Application of deep learning in detecting neurological disorders from magnetic resonance images: a survey on the detection of Alzheimer’s disease, Parkinson’s disease and schizophrenia","Brain Informatics","","2198-4026","10.1186/s40708-020-00112-2","https://doi.org/10.1186/s40708-020-00112-2","Neuroimaging, in particular magnetic resonance imaging (MRI), has been playing an important role in understanding brain functionalities and its disorders during the last couple of decades. These cutting-edge MRI scans, supported by high-performance computational tools and novel ML techniques, have opened up possibilities to unprecedentedly identify neurological disorders. However, similarities in disease phenotypes make it very difficult to detect such disorders accurately from the acquired neuroimaging data. This article critically examines and compares performances of the existing deep learning (DL)-based methods to detect neurological disorders—focusing on Alzheimer’s disease, Parkinson’s disease and schizophrenia—from MRI data acquired using different modalities including functional and structural MRI. The comparative performance analysis of various DL architectures across different disorders and imaging modalities suggests that the Convolutional Neural Network outperforms other methods in detecting neurological disorders. Towards the end, a number of current research challenges are indicated and some possible future research directions are provided.","2020-10-09","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:06","11","","1","7","","Brain Inf.","Application of deep learning in detecting neurological disorders from magnetic resonance images","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\PSWNCP84\Noor et al. - 2020 - Application of deep learning in detecting neurolog.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IE4ARR3S","journalArticle","2020","Teh, Hui Yie; Kempa-Liehr, Andreas W.; Wang, Kevin I-Kai","Sensor data quality: a systematic review","Journal of Big Data","","2196-1115","10.1186/s40537-020-0285-1","https://doi.org/10.1186/s40537-020-0285-1","Sensor data quality plays a vital role in Internet of Things (IoT) applications as they are rendered useless if the data quality is bad. This systematic review aims to provide an introduction and guide for researchers who are interested in quality-related issues of physical sensor data. The process and results of the systematic review are presented which aims to answer the following research questions: what are the different types of physical sensor data errors, how to quantify or detect those errors, how to correct them and what domains are the solutions in. Out of 6970 literatures obtained from three databases (ACM Digital Library, IEEE Xplore and ScienceDirect) using the search string refined via topic modelling, 57 publications were selected and examined. Results show that the different types of sensor data errors addressed by those papers are mostly missing data and faults e.g. outliers, bias and drift. The most common solutions for error detection are based on principal component analysis (PCA) and artificial neural network (ANN) which accounts for about 40% of all error detection papers found in the study. Similarly, for fault correction, PCA and ANN are among the most common, along with Bayesian Networks. Missing values on the other hand, are mostly imputed using Association Rule Mining. Other techniques include hybrid solutions that combine several data science methods to detect and correct the errors. Through this systematic review, it is found that the methods proposed to solve physical sensor data errors cannot be directly compared due to the non-uniform evaluation process and the high use of non-publicly available datasets. Bayesian data analysis done on the 57 selected publications also suggests that publications using publicly available datasets for method evaluation have higher citation rates.","2020-02-11","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:07","11","","1","7","","J Big Data","Sensor data quality","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\8A88I7DA\Teh et al. - 2020 - Sensor data quality a systematic review.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NH7CKTWF","journalArticle","2018","Nolle, Timo; Luettgen, Stefan; Seeliger, Alexander; Mühlhäuser, Max","Analyzing business process anomalies using autoencoders","Machine Learning","","1573-0565","10.1007/s10994-018-5702-8","https://doi.org/10.1007/s10994-018-5702-8","Businesses are naturally interested in detecting anomalies in their internal processes, because these can be indicators for fraud and inefficiencies. Within the domain of business intelligence, classic anomaly detection is not very frequently researched. In this paper, we propose a method, using autoencoders, for detecting and analyzing anomalies occurring in the execution of a business process. Our method does not rely on any prior knowledge about the process and can be trained on a noisy dataset already containing the anomalies. We demonstrate its effectiveness by evaluating it on 700 different datasets and testing its performance against three state-of-the-art anomaly detection methods. This paper is an extension of our previous work from 2016 (Nolle et al. in Unsupervised anomaly detection in noisy business process event logs using denoising autoencoders. In: International conference on discovery science, Springer, pp 442–456, 2016). Compared to the original publication we have further refined the approach in terms of performance and conducted an elaborate evaluation on more sophisticated datasets including real-life event logs from the Business Process Intelligence Challenges of 2012 and 2017. In our experiments our approach reached an $$F_1$$score of 0.87, whereas the best unaltered state-of-the-art approach reached an $$F_1$$score of 0.72. Furthermore, our approach can be used to analyze the detected anomalies in terms of which event within one execution of the process causes the anomaly.","2018-11-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:07","1875-1893","","11","107","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\3PTTS7TM\Nolle et al. - 2018 - Analyzing business process anomalies using autoenc.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NFGUNRJQ","journalArticle","2020","Kerner, Hannah R.; Wagstaff, Kiri L.; Bue, Brian D.; Wellington, Danika F.; Jacob, Samantha; Horton, Paul; Bell, James F.; Kwan, Chiman; Ben Amor, Heni","Comparison of novelty detection methods for multispectral images in rover-based planetary exploration missions","Data Mining and Knowledge Discovery","","1573-756X","10.1007/s10618-020-00697-6","https://doi.org/10.1007/s10618-020-00697-6","Science teams for rover-based planetary exploration missions like the Mars Science Laboratory Curiosity rover have limited time for analyzing new data before making decisions about follow-up observations. There is a need for systems that can rapidly and intelligently extract information from planetary instrument datasets and focus attention on the most promising or novel observations. Several novelty detection methods have been explored in prior work for three-channel color images and non-image datasets, but few have considered multispectral or hyperspectral image datasets for the purpose of scientific discovery. We compared the performance of four novelty detection methods—Reed Xiaoli (RX) detectors, principal component analysis (PCA), autoencoders, and generative adversarial networks (GANs)—and the ability of each method to provide explanatory visualizations to help scientists understand and trust predictions made by the system. We show that pixel-wise RX and autoencoders trained with structural similarity (SSIM) loss can detect morphological novelties that are not detected by PCA, GANs, and mean squared error autoencoders, but that the latter methods are better suited for detecting spectral novelties—i.e., the best method for a given setting depends on the type of novelties that are sought. Additionally, we find that autoencoders provide the most useful explanatory visualizations for enabling users to understand and trust model detections, and that existing GAN approaches to novelty detection may be limited in this respect.","2020-11-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:08","1642-1675","","6","34","","Data Min Knowl Disc","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\ND95IDZY\Kerner et al. - 2020 - Comparison of novelty detection methods for multis.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8NABBSJ","journalArticle","2019","Torres, Leo; Suárez-Serrato, Pablo; Eliassi-Rad, Tina","Non-backtracking cycles: length spectrum theory and graph mining applications","Applied Network Science","","2364-8228","10.1007/s41109-019-0147-y","https://doi.org/10.1007/s41109-019-0147-y","Graph distance and graph embedding are two fundamental tasks in graph mining. For graph distance, determining the structural dissimilarity between networks is an ill-defined problem, as there is no canonical way to compare two networks. Indeed, many of the existing approaches for network comparison differ in their heuristics, efficiency, interpretability, and theoretical soundness. Thus, having a notion of distance that is built on theoretically robust first principles and that is interpretable with respect to features ubiquitous in complex networks would allow for a meaningful comparison between different networks. For graph embedding, many of the popular methods are stochastic and depend on black-box models such as deep networks. Regardless of their high performance, this makes their results difficult to analyze which hinders their usefulness in the development of a coherent theory of complex networks. Here we rely on the theory of the length spectrum function from algebraic topology, and its relationship to the non-backtracking cycles of a graph, in order to introduce two new techniques: Non-Backtracking Spectral Distance (NBD) for measuring the distance between undirected, unweighted graphs, and Non-Backtracking Embedding Dimensions (NBED) for finding a graph embedding in low-dimensional space. Both techniques are interpretable in terms of features of complex networks such as presence of hubs, triangles, and communities. We showcase the ability of NBD to discriminate between networks in both real and synthetic data sets, as well as the potential of NBED to perform anomaly detection. By taking a topological interpretation of non-backtracking cycles, this work presents a novel application of topological data analysis to the study of complex networks.","2019-06-25","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:08","41","","1","4","","Appl Netw Sci","Non-backtracking cycles","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\3CK4Y8UK\Torres et al. - 2019 - Non-backtracking cycles length spectrum theory an.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y4AVRIG2","journalArticle","2018","Lin, Peng; Song, Qi; Wu, Yinghui","Fact Checking in Knowledge Graphs with Ontological Subgraph Patterns","Data Science and Engineering","","2364-1541","10.1007/s41019-018-0082-4","https://doi.org/10.1007/s41019-018-0082-4","Given a knowledge graph and a fact (a triple statement), fact checking is to decide whether the fact belongs to the missing part of the graph. Facts in real-world knowledge bases are typically interpreted by both topological and semantic context that is not fully exploited by existing methods. This paper introduces a novel fact checking method that explicitly exploits discriminant subgraph structures. Our method discovers discriminant subgraphs associated with a set of training facts, characterized by a class of graph fact checking rules. These rules incorporate expressive subgraph patterns to jointly describe both topological and ontological constraints. (1) We extend graph fact checking rules ($${\mathsf{GFCs}}$$) to a class of ontological graph fact checking rules ($${\mathsf{OGFCs}}$$). $${\mathsf{OGFCs}}$$generalize $${\mathsf{GFCs}}$$by incorporating both topological constraints and ontological closeness to best distinguish between true and false fact statements. We provide quality measures to characterize useful patterns that are both discriminant and diversified. (2) Despite the increased expressiveness, we show that it is feasible to discover $${\mathsf{OGFCs}}$$in large graphs with ontologies, by developing a supervised pattern discovery algorithm. To find useful $${\mathsf{OGFCs}}$$as early as possible, it generates subgraph patterns relevant to training facts and dynamically selects patterns from a pattern stream with a small update cost per pattern. We verify that $${\mathsf{OGFCs}}$$can be used as rules and provide useful features for other statistical learning-based fact checking models. Using real-world knowledge bases, we experimentally verify the efficiency and the effectiveness of $${\mathsf{OGFC}}$$-based techniques for fact checking.","2018-12-01","2021-06-07 21:20:08","2021-06-07 21:20:08","2021-06-07 21:20:08","341-358","","4","3","","Data Sci. Eng.","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\MAWL6LED\Lin et al. - 2018 - Fact Checking in Knowledge Graphs with Ontological.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HMD9R3D","journalArticle","2015","Paulheim, Heiko; Meusel, Robert","A decomposition of the outlier detection problem into a set of supervised learning problems","Machine Learning","","1573-0565","10.1007/s10994-015-5507-y","https://doi.org/10.1007/s10994-015-5507-y","Outlier detection methods automatically identify instances that deviate from the majority of the data. In this paper, we propose a novel approach for unsupervised outlier detection, which re-formulates the outlier detection problem in numerical data as a set of supervised regression learning problems. For each attribute, we learn a predictive model which predicts the values of that attribute from the values of all other attributes, and compute the deviations between the predictions and the actual values. From those deviations, we derive both a weight for each attribute, and a final outlier score using those weights. The weights help separating the relevant attributes from the irrelevant ones, and thus make the approach well suitable for discovering outliers otherwise masked in high-dimensional data. An empirical evaluation shows that our approach outperforms existing algorithms, and is particularly robust in datasets with many irrelevant attributes. Furthermore, we show that if a symbolic machine learning method is used to solve the individual learning problems, the approach is also capable of generating concise explanations for the detected outliers.","2015-09-01","2021-06-07 21:20:35","2021-06-07 21:20:35","2021-06-07 21:20:35","509-531","","2","100","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\IS3BL6GQ\Paulheim and Meusel - 2015 - A decomposition of the outlier detection problem i.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TJP8UH4R","journalArticle","2015","Iglesias, Félix; Zseby, Tanja","Analysis of network traffic features for anomaly detection","Machine Learning","","1573-0565","10.1007/s10994-014-5473-9","https://doi.org/10.1007/s10994-014-5473-9","Anomaly detection in communication networks provides the basis for the uncovering of novel attacks, misconfigurations and network failures. Resource constraints for data storage, transmission and processing make it beneficial to restrict input data to features that are (a) highly relevant for the detection task and (b) easily derivable from network observations without expensive operations. Removing strong correlated, redundant and irrelevant features also improves the detection quality for many algorithms that are based on learning techniques. In this paper we address the feature selection problem for network traffic based anomaly detection. We propose a multi-stage feature selection method using filters and stepwise regression wrappers. Our analysis is based on 41 widely-adopted traffic features that are presented in several commonly used traffic data sets. With our combined feature selection method we could reduce the original feature vectors from 41 to only 16 features. We tested our results with five fundamentally different classifiers, observing no significant reduction of the detection performance. In order to quantify the practical benefits of our results, we analyzed the costs for generating individual features from standard IP Flow Information Export records, available at many routers. We show that we can eliminate 13 very costly features and thus reducing the computational effort for on-line feature generation from live traffic observations at network nodes.","2015-10-01","2021-06-07 21:20:35","2021-06-07 21:20:35","2021-06-07 21:20:35","59-84","","1","101","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\QCPWEEYD\Iglesias and Zseby - 2015 - Analysis of network traffic features for anomaly d.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPBJ2LG6","journalArticle","2020","","A A News","","","","","","","2020","2021-06-16 07:55:55","2021-06-17 12:45:29","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""