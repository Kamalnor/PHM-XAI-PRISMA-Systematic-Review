"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"J87Z8PWL","journalArticle","2020","Bikku, Thulasi","Multi-layered deep learning perceptron approach for health risk prediction","Journal of Big Data","","2196-1115","10.1186/s40537-020-00316-7","https://doi.org/10.1186/s40537-020-00316-7","In today's world, due to the increase of medical data there is an interest in data preprocessing, classification and prediction of disease risks. Machine learning and Artificial Intelligence indicates that the predictive analysis becomes part of the medical activities especially in the domain of medical death prevention. The proposed work is focused on supervised learning methods and their capability to find hidden patterns in the real historical medical data. The objective is to predict future risk with a certain probability using Multi-layer perceptron (MLP) method. In the proposed work, MLP based on data classification technique is used for accurate classification and risk analysis of medical data. The proposed method is compared with traditional classification methods and the results show that the proposed method is better than the traditional methods.","2020-07-23","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","50","","1","7","","J Big Data","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\M6IENQNR\Bikku - 2020 - Multi-layered deep learning perceptron approach fo.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JSVN9862","journalArticle","2020","Rehs, Andreas","A structural topic model approach to scientific reorientation of economics and chemistry after German reunification","Scientometrics","","1588-2861","10.1007/s11192-020-03640-0","https://doi.org/10.1007/s11192-020-03640-0","The detection of differences or similarities in large numbers of scientific publications is an open problem in scientometric research. In this paper we therefore develop and apply a machine learning approach based on structural topic modelling in combination with cosine similarity and a linear regression framework in order to identify differences in dissertation titles written at East and West German universities before and after German reunification. German reunification and its surrounding time period is used because it provides a structure with both minor and major differences in research topics that could be detected by our approach. Our dataset is based on dissertation titles in economics and business administration and chemistry from 1980 to 2010. We use university affiliation and year of the dissertation to train a structural topic model and then test the model on a set of unseen dissertation titles. Subsequently, we compare the resulting topic distribution of each title to every other title with cosine similarity. The cosine similarities and the regional and temporal origin of the dissertation titles they come from are then used in a linear regression approach. Our results on research topics in economics and business administration suggest substantial differences between East and West Germany before the reunification and a rapid conformation thereafter. In chemistry we observe minor differences between East and West before the reunification and a slightly increased similarity thereafter.","2020-11-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","1229-1251","","2","125","","Scientometrics","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\AGQDNWWU\Rehs - 2020 - A structural topic model approach to scientific re.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CY5WDQEH","journalArticle","2020","Bagheri, Ayoub; Sammani, Arjan; van der Heijden, Peter G. M.; Asselbergs, Folkert W.; Oberski, Daniel L.","ETM: Enrichment by topic modeling for automated clinical sentence classification to detect patients’ disease history","Journal of Intelligent Information Systems","","1573-7675","10.1007/s10844-020-00605-w","https://doi.org/10.1007/s10844-020-00605-w","Given the rapid rate at which text data are being digitally gathered in the medical domain, there is growing need for automated tools that can analyze clinical notes and classify their sentences in electronic health records (EHRs). This study uses EHR texts to detect patients’ disease history from clinical sentences. However, in EHRs, sentences are less topic-focused and shorter than that in general domain, which leads to the sparsity of co-occurrence patterns and the lack of semantic features. To tackle this challenge, current approaches for clinical sentence classification are dependent on external information to improve classification performance. However, this is implausible owing to a lack of universal medical dictionaries. This study proposes the ETM (enrichment by topic modeling) algorithm, based on latent Dirichlet allocation, to smoothen the semantic representations of short sentences. The ETM enriches text representation by incorporating probability distributions generated by an unsupervised algorithm into it. It considers the length of the original texts to enhance representation by using an internal knowledge acquisition procedure. When it comes to clinical predictive modeling, interpretability improves the acceptance of the model. Thus, for clinical sentence classification, the ETM approach employs an initial TFiDF (term frequency inverse document frequency) representation, where we use the support vector machine and neural network algorithms for the classification task. We conducted three sets of experiments on a data set consisting of clinical cardiovascular notes from the Netherlands to test the sentence classification performance of the proposed method in comparison with prevalent approaches. The results show that the proposed ETM approach outperformed state-of-the-art baselines.","2020-10-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","329-349","","2","55","","J Intell Inf Syst","ETM","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\5MZ9BELZ\Bagheri et al. - 2020 - ETM Enrichment by topic modeling for automated cl.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V53R5GQA","journalArticle","2020","Govindarajan, Satyavratan; Swaminathan, Ramakrishnan","Differentiation of COVID-19 conditions in planar chest radiographs using optimized convolutional neural networks","Applied Intelligence","","1573-7497","10.1007/s10489-020-01941-8","https://doi.org/10.1007/s10489-020-01941-8","In this study, an attempt has been made to differentiate Novel Coronavirus-2019 (COVID-19) conditions from healthy subjects in Chest radiographs using a simplified end-to-end Convolutional Neural Network (CNN) model and occlusion sensitivity maps. Early detection and faster automated screening of the COVID-19 patients is essential. For this, the images are considered from publicly available datasets. Significant biomarkers representing critical image features are extracted from CNN by experimentally investigating on cross-validation methods and hyperparameter settings. The performance of the network is evaluated using standard metrics. Perturbation based occlusion sensitivity maps are employed on the features obtained from the classification model to visualise the localization of abnormal areas. Results demonstrate that the simplified CNN model with optimised parameters is able to extract significant features with a sensitivity of 97.35% and F-measure of 96.71% to detect COVID-19 images. The algorithm achieves an Area Under the Curve-Receiver Operating Characteristic score of 99.4% with Matthews correlation coefficient of 0.93. High value of Diagnostic odds ratio is also obtained. Occlusion sensitivity maps provide precise localization of abnormal regions by identifying COVID-19 conditions. As early detection through chest radiographic images are useful for automated screening of the disease, this method appears to be clinically relevant in providing a visual diagnostic solution using a simplified and efficient model.","2020-11-06","2021-06-07 21:03:55","2021-06-07 21:49:48","2021-06-07 21:03:54","2764-2775","","5","51","","Appl Intell","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\J56P7RVI\Govindarajan and Swaminathan - 2021 - Differentiation of COVID-19 conditions in planar c.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UAJGUQ3C","journalArticle","2020","Shafik, Wasswa; Matinkhah, S. Mojtaba; Ghasemzadeh, Mohammad","Theoretical Understanding of Deep Learning in UAV Biomedical Engineering Technologies Analysis","SN Computer Science","","2661-8907","10.1007/s42979-020-00323-8","https://doi.org/10.1007/s42979-020-00323-8","The unmanned aerial vehicles (UAVs) emerged into a promising research trend within the recurrent year where current and future networks are to use enhanced connectivity in these digital immigrations in different fields like medical, communication, search, and rescue operations among others. The current technologies are using fixed base stations to operate on-site and off-site in the fixed position with its associated problems like poor connectivity. This opens gates for the UAVs technology to be used as a mobile alternative to increase accessibility with a fifth-generation (5G) connectivity that focuses on increased availability and connectivity. There has been less usage of wireless technologies in the medical field. This paper first presents a study on deep learning to medical field application in general, and provides detailed steps that are involved in the multi-armed bandit approach in solving UAV biomedical engineering technologies devices and medical exploration to exploitation dilemma. The paper further presents a detailed description of the bandit network applicability to achieve close optimal medical engineered devices’ performance and efficiency. The simulated results depicted that a multi-armed bandit problem approach can be applied in optimizing the performance of any medical networked device issue compared to the Thompson sampling, Bayesian algorithm, and ε-greedy algorithm. The results obtained further illustrated the optimized utilization of biomedical engineering technologies systems achieving thus close optimal performance on the average period through deep learning of realistic medical situations.","2020-09-24","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","307","","6","1","","SN COMPUT. SCI.","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\GGICHPYW\Shafik et al. - 2020 - Theoretical Understanding of Deep Learning in UAV .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZS9NTCA","journalArticle","2021","van der Schaar, Mihaela; Alaa, Ahmed M.; Floto, Andres; Gimson, Alexander; Scholtes, Stefan; Wood, Angela; McKinney, Eoin; Jarrett, Daniel; Lio, Pietro; Ercole, Ari","How artificial intelligence and machine learning can help healthcare systems respond to COVID-19","Machine Learning","","1573-0565","10.1007/s10994-020-05928-x","https://doi.org/10.1007/s10994-020-05928-x","The COVID-19 global pandemic is a threat not only to the health of millions of individuals, but also to the stability of infrastructure and economies around the world.The disease will inevitably place an overwhelming burden on healthcare systems that cannot be effectively dealt with by existing facilities or responses based on conventional approaches. We believe that a rigorous clinical and societal response can only be mounted by using intelligence derived from a variety of data sources to better utilize scarce healthcare resources, provide personalized patient management plans, inform policy, and expedite clinical trials.In this paper, we introduce five of the most important challenges in responding to COVID-19 and show how each of them can be addressed by recent developments in machine learning (ML) and artificial intelligence (AI).We argue that the integration of these techniques into local, national, and international healthcare systems will save lives, and propose specific methods by which implementation can happen swiftly and efficiently. We offer to extend these resources and knowledge to assist policymakers seeking to implement these techniques.","2021-01-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","1-14","","1","110","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\G8DCIR7D\van der Schaar et al. - 2021 - How artificial intelligence and machine learning c.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3YDGI3P9","journalArticle","2020","Karim, Md. Rezaul; Rahman, Ashiqur; Jares, João Bosco; Decker, Stefan; Beyan, Oya","A snapshot neural ensemble method for cancer-type prediction based on copy number variations","Neural Computing and Applications","","1433-3058","10.1007/s00521-019-04616-9","https://doi.org/10.1007/s00521-019-04616-9","An accurate diagnosis and prognosis for cancer are specific to patients with particular cancer types and molecular traits, which needs to address carefully. The discovery of important biomarkers is becoming an important step toward understanding the molecular mechanisms of carcinogenesis in which genomics data and clinical outcomes need to be analyzed before making any clinical decision. Copy number variations (CNVs) are found to be associated with the risk of individual cancers and hence can be used to reveal genetic predispositions before cancer develops. In this paper, we collect the CNVs data about 8000 cancer patients covering 14 different cancer types from The Cancer Genome Atlas. Then, two different sparse representations of CNVs based on 578 oncogenes and 20,308 protein-coding genes, including genomic deletions and duplication across the samples, are prepared. Then, we train Conv-LSTM and convolutional autoencoder (CAE) networks using both representations and create snapshot models. While the Conv-LSTM can capture locally and globally important features, CAE can utilize unsupervised pretraining to initialize the weights in the subsequent convolutional layers against the sparsity. Model averaging ensemble (MAE) is then applied to combine the snapshot models in order to make a single prediction. Finally, we identify most significant CNVs biomarkers using guided-gradient class activation map plus (GradCAM++) and rank top genes for different cancer types. Results covering several experiments show fairly high prediction accuracies for the majority of cancer types. In particular, using protein-coding genes, Conv-LSTM and CAE networks can predict cancer types correctly at least 72.96% and 76.77% of the cases, respectively. Contrarily, using oncogenes gives moderately higher accuracies of 74.25% and 78.32%, whereas the snapshot model based on MAE shows overall 2.5% of accuracy improvement.","2020-10-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","15281-15299","","19","32","","Neural Comput & Applic","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\58RHFPH8\Karim et al. - 2020 - A snapshot neural ensemble method for cancer-type .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TSZ86PZW","journalArticle","2020","Illankoon, Prasanna; Tretten, Phillip","Collaborating AI and human experts in the maintenance domain","AI & SOCIETY","","1435-5655","10.1007/s00146-020-01076-x","https://doi.org/10.1007/s00146-020-01076-x","Maintenance decision errors can result in very costly problems. The 4th industrial revolution has given new opportunities for the development of and use of intelligent decision support systems. With these technological advancements, key concerns focus on gaining a better understanding of the linkage between the technicians’ knowledge and the intelligent decision support systems. The research reported in this study has two primary objectives. (1) To propose a theoretical model that links technicians’ knowledge and intelligent decision support systems, and (2) to present a use case how to apply the theoretical model. The foundation of the new model builds upon two main streams of study in the decision support literature: “distribution” of knowledge among different agents, and “collaboration” of knowledge for reaching a shared goal. This study resulted in the identification of two main gaps: firstly, there must be a greater focus upon the technicians’ knowledge; secondly, technicians need assistance to maintain their focus on the big picture. We used the cognitive fit theory, and the theory of distributed situation awareness to propose the new theoretical model called “distributed collaborative awareness model.” The model considers both explicit and implicit knowledge and accommodates the dynamic challenges involved in operational level maintenance. As an application of this model, we identify and recommend some technological developments required in augmented reality based maintenance decision support.","2020-10-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","","","","","","AI & Soc","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\PPG2YFU7\Illankoon and Tretten - 2020 - Collaborating AI and human experts in the maintena.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RF2PNCZD","journalArticle","2021","Qian, Zhaozhi; Alaa, Ahmed M.; van der Schaar, Mihaela","CPAS: the UK’s national machine learning-based hospital capacity planning system for COVID-19","Machine Learning","","1573-0565","10.1007/s10994-020-05921-4","https://doi.org/10.1007/s10994-020-05921-4","The coronavirus disease 2019 (COVID-19) global pandemic poses the threat of overwhelming healthcare systems with unprecedented demands for intensive care resources. Managing these demands cannot be effectively conducted without a nationwide collective effort that relies on data to forecast hospital demands on the national, regional, hospital and individual levels. To this end, we developed the COVID-19 Capacity Planning and Analysis System (CPAS)—a machine learning-based system for hospital resource planning that we have successfully deployed at individual hospitals and across regions in the UK in coordination with NHS Digital. In this paper, we discuss the main challenges of deploying a machine learning-based decision support system at national scale, and explain how CPAS addresses these challenges by (1) defining the appropriate learning problem, (2) combining bottom-up and top-down analytical approaches, (3) using state-of-the-art machine learning algorithms, (4) integrating heterogeneous data sources, and (5) presenting the result with an interactive and transparent interface. CPAS is one of the first machine learning-based systems to be deployed in hospitals on a national scale to address the COVID-19 pandemic—we conclude the paper with a summary of the lessons learned from this experience.","2021-01-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:54","15-35","","1","110","","Mach Learn","CPAS","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\AB5QV3E4\Qian et al. - 2021 - CPAS the UK’s national machine learning-based hos.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X44MBWHV","journalArticle","2020","Kraaij, Wessel; Verberne, Suzan; Koldijk, Saskia; de Korte, Elsbeth; van Dantzig, Saskia; Sappelli, Maya; Shoaib, Muhammad; Bosems, Steven; Achterkamp, Reinoud; Bonomi, Alberto; Schavemaker, John; Hulsebosch, Bob; Wabeke, Thymen; Vollenbroek-Hutten, Miriam; Neerincx, Mark; Sinderen, Marten van","Personalized support for well-being at work: an overview of the SWELL project","User Modeling and User-Adapted Interaction","","1573-1391","10.1007/s11257-019-09238-3","https://doi.org/10.1007/s11257-019-09238-3","Recent advances in wearable sensor technology and smartphones enable simple and affordable collection of personal analytics. This paper reflects on the lessons learned in the SWELL project that addressed the design of user-centered ICT applications for self-management of vitality in the domain of knowledge workers. These workers often have a sedentary lifestyle and are susceptible to mental health effects due to a high workload. We present the sense–reason–act framework that is the basis of the SWELL approach and we provide an overview of the individual studies carried out in SWELL. In this paper, we revisit our work on reasoning: interpreting raw heterogeneous sensor data, and acting: providing personalized feedback to support behavioural change. We conclude that simple affordable sensors can be used to classify user behaviour and heath status in a physically non-intrusive way. The interpreted data can be used to inform personalized feedback strategies. Further longitudinal studies can now be initiated to assess the effectiveness of m-Health interventions using the SWELL methods.","2020-07-01","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:55","413-446","","3","30","","User Model User-Adap Inter","Personalized support for well-being at work","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\RPYR45IR\Kraaij et al. - 2020 - Personalized support for well-being at work an ov.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JKZQ2S2C","journalArticle","2020","Noor, Manan Binth Taj; Zenia, Nusrat Zerin; Kaiser, M. Shamim; Mamun, Shamim Al; Mahmud, Mufti","Application of deep learning in detecting neurological disorders from magnetic resonance images: a survey on the detection of Alzheimer’s disease, Parkinson’s disease and schizophrenia","Brain Informatics","","2198-4026","10.1186/s40708-020-00112-2","https://doi.org/10.1186/s40708-020-00112-2","Neuroimaging, in particular magnetic resonance imaging (MRI), has been playing an important role in understanding brain functionalities and its disorders during the last couple of decades. These cutting-edge MRI scans, supported by high-performance computational tools and novel ML techniques, have opened up possibilities to unprecedentedly identify neurological disorders. However, similarities in disease phenotypes make it very difficult to detect such disorders accurately from the acquired neuroimaging data. This article critically examines and compares performances of the existing deep learning (DL)-based methods to detect neurological disorders—focusing on Alzheimer’s disease, Parkinson’s disease and schizophrenia—from MRI data acquired using different modalities including functional and structural MRI. The comparative performance analysis of various DL architectures across different disorders and imaging modalities suggests that the Convolutional Neural Network outperforms other methods in detecting neurological disorders. Towards the end, a number of current research challenges are indicated and some possible future research directions are provided.","2020-10-09","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:55","11","","1","7","","Brain Inf.","Application of deep learning in detecting neurological disorders from magnetic resonance images","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\AUSFPJQY\Noor et al. - 2020 - Application of deep learning in detecting neurolog.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZPNE9N5","journalArticle","2020","Lehmann, Claude; Goren Huber, Lilach; Horisberger, Thomas; Scheiba, Georg; Sima, Ana Claudia; Stockinger, Kurt","Big Data architecture for intelligent maintenance: a focus on query processing and machine learning algorithms","Journal of Big Data","","2196-1115","10.1186/s40537-020-00340-7","https://doi.org/10.1186/s40537-020-00340-7","Exploiting available condition monitoring data of industrial machines for intelligent maintenance purposes has been attracting attention in various application fields. Machine learning algorithms for fault detection, diagnosis and prognosis are popular and easily accessible. However, our experience in working at the intersection of academia and industry showed that the major challenges of building an end-to-end system in a real-world industrial setting go beyond the design of machine learning algorithms. One of the major challenges is the design of an end-to-end data management solution that is able to efficiently store and process large amounts of heterogeneous data streams resulting from a variety of physical machines. In this paper we present the design of an end-to-end Big Data architecture that enables intelligent maintenance in a real-world industrial setting. In particular, we will discuss various physical design choices for optimizing high-dimensional queries, such as partitioning and Z-ordering, that serve as the basis for health analytics. Finally, we describe a concrete fault detection use case with two different health monitoring algorithms based on machine learning and classical statistics and discuss their advantages and disadvantages. The paper covers some of the most important aspects of the practical implementation of such an end-to-end solution and demonstrates the challenges and their mitigation for the specific application of laser cutting machines.","2020-08-12","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:55","61","","1","7","","J Big Data","Big Data architecture for intelligent maintenance","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\NHGZZSFH\Lehmann et al. - 2020 - Big Data architecture for intelligent maintenance.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JS5KQESN","journalArticle","2021","Rundo, Leonardo; Tangherloni, Andrea; Cazzaniga, Paolo; Mistri, Matteo; Galimberti, Simone; Woitek, Ramona; Sala, Evis; Mauri, Giancarlo; Nobile, Marco S.","A CUDA-powered method for the feature extraction and unsupervised analysis of medical images","The Journal of Supercomputing","","1573-0484","10.1007/s11227-020-03565-8","https://doi.org/10.1007/s11227-020-03565-8","Image texture extraction and analysis are fundamental steps in computer vision. In particular, considering the biomedical field, quantitative imaging methods are increasingly gaining importance because they convey scientifically and clinically relevant information for prediction, prognosis, and treatment response assessment. In this context, radiomic approaches are fostering large-scale studies that can have a significant impact in the clinical practice. In this work, we present a novel method, called CHASM (Cuda, HAralick & SoM), which is accelerated on the graphics processing unit (GPU) for quantitative imaging analyses based on Haralick features and on the self-organizing map (SOM). The Haralick features extraction step relies upon the gray-level co-occurrence matrix, which is computationally burdensome on medical images characterized by a high bit depth. The downstream analyses exploit the SOM with the goal of identifying the underlying clusters of pixels in an unsupervised manner. CHASM is conceived to leverage the parallel computation capabilities of modern GPUs. Analyzing ovarian cancer computed tomography images, CHASM achieved up to $$\sim 19.5\times $$and $$\sim 37\times $$speed-up factors for the Haralick feature extraction and for the SOM execution, respectively, compared to the corresponding C++ coded sequential versions. Such computational results point out the potential of GPUs in the clinical research.","2021-01-21","2021-06-07 21:03:55","2021-06-07 21:03:55","2021-06-07 21:03:55","","","","","","J Supercomput","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\LK7A5643\Rundo et al. - 2021 - A CUDA-powered method for the feature extraction a.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KTASPTGK","journalArticle","2020","Cerquitelli, Tania; Chiusano, Silvia; Vargas-Solar, Genoveva","A A EDITORIAL special issue on data analytics for engineering, science and society","Computing","","1436-5057","10.1007/s00607-020-00810-z","https://doi.org/10.1007/s00607-020-00810-z","","2020-05-01","2021-06-07 21:04:36","2021-06-15 09:15:23","2021-06-07 21:04:35","1093-1096","","5","102","","Computing","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\GIBGPCUZ\Cerquitelli et al. - 2020 - Editorial special issue on data analytics for engi.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W8QZ26DU","journalArticle","2019","Ismail, Ahmed; Truong, Hong-Linh; Kastner, Wolfgang","Manufacturing process data analysis pipelines: a requirements analysis and survey","Journal of Big Data","","2196-1115","10.1186/s40537-018-0162-3","https://doi.org/10.1186/s40537-018-0162-3","Smart manufacturing is strongly correlated with the digitization of all manufacturing activities. This increases the amount of data available to drive productivity and profit through data-driven decision making programs. The goal of this article is to assist data engineers in designing big data analysis pipelines for manufacturing process data. Thus, this paper characterizes the requirements for process data analysis pipelines and surveys existing platforms from academic literature. The results demonstrate a stronger focus on the storage and analysis phases of pipelines than on the ingestion, communication, and visualization stages. Results also show a tendency towards custom tools for ingestion and visualization, and relational data tools for storage and analysis. Tools for handling heterogeneous data are generally well-represented throughout the pipeline. Finally, batch processing tools are more widely adopted than real-time stream processing frameworks, and most pipelines opt for a common script-based data processing approach. Based on these results, recommendations are offered for each phase of the pipeline.","2019-01-07","2021-06-07 21:04:36","2021-06-17 13:55:01","2021-06-07 21:04:35","1","","1","6","","J Big Data","Manufacturing process data analysis pipelines","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\LNG97H5M\Ismail et al. - 2019 - Manufacturing process data analysis pipelines a r.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WZ7KLTJ6","journalArticle","2020","Kovacs, Tibor; Ko, Andrea","Monitoring Pneumatic Actuators’ Behavior Using Real-World Data Set","SN Computer Science","","2661-8907","10.1007/s42979-020-00202-2","https://doi.org/10.1007/s42979-020-00202-2","Developing a big data signal processing method is to monitor the behavior of a common component: a pneumatic actuator. The method is aimed at supporting condition-based maintenance activities: monitoring signals over an extended period, and identifying, classifying different machine states that may indicate abnormal behavior. Furthermore, preparing a balanced data set for training supervised machine learning models that represent the component’s all identified conditions. Peak detection, garbage removal and down-sampling by interpolation were applied for signal preprocessing. Undersampling the over-represented signals, Ward’s hierarchical clustering with multivariate Euclidean distance calculation and Kohonen self-organizing map (KSOM) methods were used for identifying and grouping similar signal patterns. The study demonstrated that the behavior of equipment displaying complex signals could be monitored with the method described. Both hierarchical clustering and KSOM are suitable methods for identifying and clustering signals of different machine states that may be overlooked if screened by humans. Using the proposed methods, signals could be screened thoroughly and over a long period of time that is critical when failures or abnormal behavior is rare. Visual display of the identified clusters over time could help analyzing the deterioration of machine conditions. The clustered signals could be used to create a balanced set of training data for developing supervised machine learning models to automatically identify previously recognized machine conditions that indicate abnormal behavior.","2020-06-11","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:35","196","","4","1","","SN COMPUT. SCI.","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\R4K8YZHZ\Kovacs and Ko - 2020 - Monitoring Pneumatic Actuators’ Behavior Using Rea.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62KYWAHR","journalArticle","2018","Matta, John; Zhao, Junya; Ercal, Gunes; Obafemi-Ajayi, Tayo","Applications of node-based resilience graph theoretic framework to clustering autism spectrum disorders phenotypes","Applied Network Science","","2364-8228","10.1007/s41109-018-0093-0","https://doi.org/10.1007/s41109-018-0093-0","With the growing ubiquity of data in network form, clustering in the context of a network, represented as a graph, has become increasingly important. Clustering is a very useful data exploratory machine learning tool that allows us to make better sense of heterogeneous data by grouping data with similar attributes based on some criteria. This paper investigates the application of a novel graph theoretic clustering method, Node-Based Resilience clustering (NBR-Clust), to address the heterogeneity of Autism Spectrum Disorder (ASD) and identify meaningful subgroups. The hypothesis is that analysis of these subgroups would reveal relevant biomarkers that would provide a better understanding of ASD phenotypic heterogeneity useful for further ASD studies. We address appropriate graph constructions suited for representing the ASD phenotype data. The sample population is drawn from a very large rigorous dataset: Simons Simplex Collection (SSC). Analysis of the results performed using graph quality measures, internal cluster validation measures, and clinical analysis outcome demonstrate the potential usefulness of resilience measure clustering for biomedical datasets. We also conduct feature extraction analysis to characterize relevant biomarkers that delineate the resulting subgroups. The optimal results obtained favored predominantly a 5-cluster configuration.","2018-08-29","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:35","38","","1","3","","Appl Netw Sci","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\9675EZ7H\Matta et al. - 2018 - Applications of node-based resilience graph theore.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8RDBNMCE","journalArticle","2020","Teh, Hui Yie; Kempa-Liehr, Andreas W.; Wang, Kevin I-Kai","Sensor data quality: a systematic review","Journal of Big Data","","2196-1115","10.1186/s40537-020-0285-1","https://doi.org/10.1186/s40537-020-0285-1","Sensor data quality plays a vital role in Internet of Things (IoT) applications as they are rendered useless if the data quality is bad. This systematic review aims to provide an introduction and guide for researchers who are interested in quality-related issues of physical sensor data. The process and results of the systematic review are presented which aims to answer the following research questions: what are the different types of physical sensor data errors, how to quantify or detect those errors, how to correct them and what domains are the solutions in. Out of 6970 literatures obtained from three databases (ACM Digital Library, IEEE Xplore and ScienceDirect) using the search string refined via topic modelling, 57 publications were selected and examined. Results show that the different types of sensor data errors addressed by those papers are mostly missing data and faults e.g. outliers, bias and drift. The most common solutions for error detection are based on principal component analysis (PCA) and artificial neural network (ANN) which accounts for about 40% of all error detection papers found in the study. Similarly, for fault correction, PCA and ANN are among the most common, along with Bayesian Networks. Missing values on the other hand, are mostly imputed using Association Rule Mining. Other techniques include hybrid solutions that combine several data science methods to detect and correct the errors. Through this systematic review, it is found that the methods proposed to solve physical sensor data errors cannot be directly compared due to the non-uniform evaluation process and the high use of non-publicly available datasets. Bayesian data analysis done on the 57 selected publications also suggests that publications using publicly available datasets for method evaluation have higher citation rates.","2020-02-11","2021-06-07 21:04:36","2021-06-17 13:55:06","2021-06-07 21:04:35","11","","1","7","","J Big Data","Sensor data quality","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\JBYUYC5P\Teh et al. - 2020 - Sensor data quality a systematic review.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3FVMUNNW","journalArticle","2019","Tadist, Khawla; Najah, Said; Nikolov, Nikola S.; Mrabti, Fatiha; Zahi, Azeddine","Feature selection methods and genomic big data: a systematic review","Journal of Big Data","","2196-1115","10.1186/s40537-019-0241-0","https://doi.org/10.1186/s40537-019-0241-0","In the era of accelerating growth of genomic data, feature-selection techniques are believed to become a game changer that can help substantially reduce the complexity of the data, thus making it easier to analyze and translate it into useful information. It is expected that within the next decade, researchers will head towards analyzing the genomes of all living creatures making genomics the main generator of data. Feature selection techniques are believed to become a game changer that can help substantially reduce the complexity of genomic data, thus making it easier to analyze it and translating it into useful information. With the absence of a thorough investigation of the field, it is almost impossible for researchers to get an idea of how their work relates to existing studies as well as how it contributes to the research community. In this paper, we present a systematic and structured literature review of the feature-selection techniques used in studies related to big genomic data analytics.","2019-08-27","2021-06-07 21:04:36","2021-06-17 13:54:56","2021-06-07 21:04:35","79","","1","6","","J Big Data","Feature selection methods and genomic big data","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\GLZZ6YGY\Tadist et al. - 2019 - Feature selection methods and genomic big data a .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DID5EWCV","journalArticle","2015","Vogt, Julia E.; Kloft, Marius; Stark, Stefan; Raman, Sudhir S.; Prabhakaran, Sandhya; Roth, Volker; Rätsch, Gunnar","Probabilistic clustering of time-evolving distance data","Machine Learning","","1573-0565","10.1007/s10994-015-5516-x","https://doi.org/10.1007/s10994-015-5516-x","We present a novel probabilistic clustering model for objects that are represented via pairwise distances and observed at different time points. The proposed method utilizes the information given by adjacent time points to find the underlying cluster structure and obtain a smooth cluster evolution. This approach allows the number of objects and clusters to differ at every time point, and no identification on the identities of the objects is needed. Further, the model does not require the number of clusters being specified in advance—they are instead determined automatically using a Dirichlet process prior. We validate our model on synthetic data showing that the proposed method is more accurate than state-of-the-art clustering methods. Finally, we use our dynamic clustering model to analyze and illustrate the evolution of brain cancer patients over time.","2015-09-01","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:35","635-654","","2","100","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\T2T9L6SJ\Vogt et al. - 2015 - Probabilistic clustering of time-evolving distance.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQGADUA8","journalArticle","2017","Bertsimas, Dimitris; Dunn, Jack","A A Optimal classification trees","Machine Learning","","1573-0565","10.1007/s10994-017-5633-9","https://doi.org/10.1007/s10994-017-5633-9","State-of-the-art decision tree methods apply heuristics recursively to create each split in isolation, which may not capture well the underlying characteristics of the dataset. The optimal decision tree problem attempts to resolve this by creating the entire decision tree at once to achieve global optimality. In the last 25 years, algorithmic advances in integer optimization coupled with hardware improvements have resulted in an astonishing 800 billion factor speedup in mixed-integer optimization (MIO). Motivated by this speedup, we present optimal classification trees, a novel formulation of the decision tree problem using modern MIO techniques that yields the optimal decision tree for axes-aligned splits. We also show the richness of this MIO formulation by adapting it to give optimal classification trees with hyperplanes that generates optimal decision trees with multivariate splits. Synthetic tests demonstrate that these methods recover the true decision tree more closely than heuristics, refuting the notion that optimal methods overfit the training data. We comprehensively benchmark these methods on a sample of 53 datasets from the UCI machine learning repository. We establish that these MIO methods are practically solvable on real-world datasets with sizes in the 1000s, and give average absolute improvements in out-of-sample accuracy over CART of 1–2 and 3–5% for the univariate and multivariate cases, respectively. Furthermore, we identify that optimal classification trees are likely to outperform CART by 1.2–1.3% in situations where the CART accuracy is high and we have sufficient training data, while the multivariate version outperforms CART by 4–7% when the CART accuracy or dimension of the dataset is low.","2017-07-01","2021-06-07 21:04:36","2021-06-15 08:48:49","2021-06-07 21:04:35","1039-1082","","7","106","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\QLTDXI5L\Bertsimas and Dunn - 2017 - Optimal classification trees.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MFMMMB7P","journalArticle","2020","Tsai, Shuo-Chang; Chen, Cheng-Huan; Shiao, Yi-Tzone; Ciou, Jin-Shuei; Wu, Trong-Neng","Precision education with statistical learning and deep learning: a case study in Taiwan","International Journal of Educational Technology in Higher Education","","2365-9440","10.1186/s41239-020-00186-2","https://doi.org/10.1186/s41239-020-00186-2","The low birth rate in Taiwan has led to a severe challenge for many universities to enroll a sufficient number of students. Consequently, a large number of students have been admitted to universities regardless of whether they have an aptitude for academic studies. Early diagnosis of students with a high dropout risk enables interventions to be provided early on, which can help these students to complete their studies, graduate, and enhance their future competitiveness in the workplace. Effective prelearning interventions are necessary, therefore students’ learning backgrounds should be thoroughly examined. This study investigated how big data and artificial intelligence can be used to help universities to more precisely understand student backgrounds, according to which corresponding interventions can be provided. For this study, 3552 students from a university in Taiwan were sampled. A statistical learning method and a machine learning method based on deep neural networks were used to predict their probability of dropping out. The results revealed that student academic performance (regarding the dynamics of class ranking percentage), student loan applications, the number of absences from school, and the number of alerted subjects successfully predicted whether or not students would drop out of university with an accuracy rate of 68% when the statistical learning method was employed, and 77% for the deep learning method, in the case of giving first priority to the high sensitivity in predicting dropouts. However, when the specificity metric was preferred, then the two approaches both reached more than 80% accuracy rates. These results may enable the university to provide interventions to students for assisting course selection and enhancing their competencies based on their aptitudes, potentially reducing the dropout rate and facilitating adaptive learning, thereby achieving a win-win situation for both the university and the students. This research offers a feasible direction for using artificial intelligence applications on the basis of a university’s institutional research database.","2020-04-08","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:35","12","","1","17","","Int J Educ Technol High Educ","Precision education with statistical learning and deep learning","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\UCNG6GFZ\Tsai et al. - 2020 - Precision education with statistical learning and .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R3TKCRX8","journalArticle","2016","Matusevich, David Sergio; Cabrera, Wellington; Ordonez, Carlos","Accelerating a Gibbs sampler for variable selection on genomics data with summarization and variable pre-selection combining an array DBMS and R","Machine Learning","","1573-0565","10.1007/s10994-015-5534-8","https://doi.org/10.1007/s10994-015-5534-8","Variable selection in high dimensional data is a challenging problem due to the exponential number of variable combinations, and Markov Chain Monte Carlo (MCMC) methods represent the state of the art to solve it. With genomics data this problem becomes even more difficult because there are generally more dimensions (variables) than points (records) leading to slow convergence and numerically unstable solutions. On the other hand, despite many alternative prototypes and languages, R remains a popular system to compute machine learning models. Unfortunately, R can be particularly slow with heavy matrix computations and the high number of iterations required by MCMC methods. Moreover, making R scale to large matrices, possibly beyond RAM, requires careful system integration. Recently, array DBMSs have opened the possibility of manipulating matrices of unlimited size. With such motivation in mind, we present algorithmic optimizations to accelerate the computation of variable selection in linear regression with the Gibbs sampler, a fundamental MCMC method. Such optimizations have the potential to accelerate other models. We study how to leverage the speed and scalability of the array DBMS to exploit our optimizations in R. We present a comprehensive experimental evaluation to assess time efficiency and model quality with a cancer data set containing RNA and miRNA variables to predict survival time. We show our optimized algorithm combining DBMS and R processing is significantly faster than R alone. We show our system allows fast joint analysis of RNA and miRNA variables, instead of analyzing them separately. Finally, we confirm our algorithm finds medically significant variables already identified in the biomedical literature. Our optimized MCMC method for the array DBMS can be easily called from R, leaving the final model within R runtime in RAM for further interpretation.","2016-03-01","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:35","483-504","","3","102","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\ZJ2NVTRF\Matusevich et al. - 2016 - Accelerating a Gibbs sampler for variable selectio.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9SFR373H","journalArticle","2019","Fennell, Peter G.; Zuo, Zhiya; Lerman, Kristina","Predicting and explaining behavioral data with structured feature space decomposition","EPJ Data Science","","2193-1127","10.1140/epjds/s13688-019-0201-0","https://doi.org/10.1140/epjds/s13688-019-0201-0","Modeling human behavioral data is challenging due to its scale, sparseness (few observations per individual), heterogeneity (differently behaving individuals), and class imbalance (few observations of the outcome of interest). An additional challenge is learning an interpretable model that not only accurately predicts outcomes, but also identifies important factors associated with a given behavior. To address these challenges, we describe a statistical approach to modeling behavioral data called the structured sum-of-squares decomposition (S3D). The algorithm, which is inspired by decision trees, selects important features that collectively explain the variation of the outcome, quantifies correlations between the features, and bins the subspace of important features into smaller, more homogeneous blocks that correspond to similarly-behaving subgroups within the population. This partitioned subspace allows us to predict and analyze the behavior of the outcome variable both statistically and visually, giving a medium to examine the effect of various features and to create explainable predictions. We apply S3D to learn models of online activity from large-scale data collected from diverse sites, such as Stack Exchange, Khan Academy, Twitter, Duolingo, and Digg. We show that S3D creates parsimonious models that can predict outcomes in the held-out data at levels comparable to state-of-the-art approaches, but in addition, produces interpretable models that provide insights into behaviors. This is important for informing strategies aimed at changing behavior, designing social systems, but also for explaining predictions, a critical step towards minimizing algorithmic bias.","2019-06-27","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:35","23","","1","8","","EPJ Data Sci.","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\ZA4BZPIA\Fennell et al. - 2019 - Predicting and explaining behavioral data with str.pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3XJMXMNY","journalArticle","2015","Tomczak, Jakub M.; Zięba, Maciej","Probabilistic combination of classification rules and its application to medical diagnosis","Machine Learning","","1573-0565","10.1007/s10994-015-5508-x","https://doi.org/10.1007/s10994-015-5508-x","Application of machine learning to medical diagnosis entails facing two major issues, namely, a necessity of learning comprehensible models and a need of coping with imbalanced data phenomenon. The first one corresponds to a problem of implementing interpretable models, e.g., classification rules or decision trees. The second issue represents a situation in which the number of examples from one class (e.g., healthy patients) is significantly higher than the number of examples from the other class (e.g., ill patients). Learning algorithms which are prone to the imbalance data return biased models towards the majority class. In this paper, we propose a probabilistic combination of soft rules, which can be seen as a probabilistic version of the classification rules, by introducing new latent random variable called conjunctive feature. The conjunctive features represent conjunctions of values of attribute variables (features) and we assume that for given conjunctive feature the object and its label (class) become independent random variables. In order to deal with the between class imbalance problem, we present a new estimator which incorporates the knowledge about data imbalanceness into hyperparameters of initial probability of objects with fixed class labels. Additionally, we propose a method for aggregating sufficient statistics needed to estimate probabilities in a graph-based structure to speed up computations. At the end, we carry out two experiments: (1) using benchmark datasets, (2) using medical datasets. The results are discussed and the conclusions are drawn.","2015-10-01","2021-06-07 21:04:36","2021-06-07 21:04:36","2021-06-07 21:04:36","105-135","","1","101","","Mach Learn","","","","","","","","en","","","","","Springer Link","","","","C:\Users\Asus\Zotero\storage\TJ28IWTT\Tomczak and Zięba - 2015 - Probabilistic combination of classification rules .pdf","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""