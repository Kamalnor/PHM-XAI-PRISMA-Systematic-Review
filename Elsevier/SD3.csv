"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"PGRLHFKQ","journalArticle","2019","Xue, Qinghan; Chuah, Mooi Choo","Explainable deep learning based medical diagnostic system","Smart Health","","2352-6483","10.1016/j.smhl.2019.03.002","https://www.sciencedirect.com/science/article/pii/S2352648318301090","Recently, many researchers have conducted data mining over medical data to uncover hidden patterns and use them to learn prediction models for clinical decision making and personalized medicine. While such healthcare learning models can achieve encouraging results, they seldom incorporate existing expert knowledge into their frameworks and hence prediction accuracy for individual patients can still be improved. However, expert knowledge spans across various websites and multiple databases with heterogeneous representations and hence is difficult to harness for improving learning models. In addition, patients' queries at medical consult websites are often ambiguous in their specified terms and hence the returned responses may not contain the information they seek. To tackle these problems, we first design a knowledge extraction framework that can generate an aggregated dataset to characterize diseases by integrating heterogeneous medical data sources. Then, based on the integrated dataset, we propose an end-to-end deep learning based medical diagnosis system (DL-MDS) to provide disease diagnosis for authorized users. We also provide explanations for the diagnose results. Evaluations on real-world data demonstrate that our proposed system achieves good performance on diseases diagnosis with a diverse set of patients’ queries.","2019-08-01","2021-06-05 17:54:16","2021-06-05 17:54:28","2021-06-05 17:54:14","100068","","","13","","Smart Health","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\TV2LBTKL\S2352648318301090.html","","","Deep learning; medical diagnosis; Heterogeneous representation; Knowledge extraction; Query processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5328ZR3V","journalArticle","2020","Rebane, Jonathan; Samsten, Isak; Papapetrou, Panagiotis","Exploiting complex medical data with interpretable deep learning for adverse drug event prediction","Artificial Intelligence in Medicine","","0933-3657","10.1016/j.artmed.2020.101942","https://www.sciencedirect.com/science/article/pii/S0933365719311546","A variety of deep learning architectures have been developed for the goal of predictive modelling and knowledge extraction from medical records. Several models have placed strong emphasis on temporal attention mechanisms and decay factors as a means to include highly temporally relevant information regarding the recency of medical event occurrence while facilitating medical code-level interpretability. In this study we utilise such models with a large Electronic Patient Record (EPR) data set consisting of diagnoses, medication, and clinical text data for the purpose of adverse drug event (ADE) prediction. The first contribution of this work is an empirical evaluation of two state-of-the-art medical-code based models in terms of objective performance metrics for ADE prediction on diagnosis and medication data. Secondly, as an extension of previous work, we augment an interpretable deep learning architecture to permit numerical risk and clinical text features and demonstrate how this approach yields improved predictive performance compared to the other baselines. Finally, we assess the importance of attention mechanisms in regards to their usefulness for medical code-level and text-level interpretability, which may facilitate novel insights pertaining to the nature of ADE occurrence within the health care domain.","2020-09-01","2021-06-05 17:54:16","2021-06-05 17:54:29","2021-06-05 17:54:14","101942","","","109","","Artificial Intelligence in Medicine","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\QXUMKAT8\S0933365719311546.html","","","Deep learning; Explainable AI; Adverse drug events; Medical records; Text mining","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZQ5GL38L","journalArticle","2021","Khodabandehloo, Elham; Riboni, Daniele; Alimohammadi, Abbas","HealthXAI: Collaborative and explainable AI for supporting early diagnosis of cognitive decline","Future Generation Computer Systems","","0167-739X","10.1016/j.future.2020.10.030","https://www.sciencedirect.com/science/article/pii/S0167739X20330144","Our aging society claims for innovative tools to early detect symptoms of cognitive decline. Several research efforts are being made to exploit sensorized smart-homes and artificial intelligence (AI) methods to detect a decline of the cognitive functions of the elderly in order to promptly alert practitioners. Even though those tools may provide accurate predictions, they currently provide limited support to clinicians in making a diagnosis. Indeed, most AI systems do not provide any explanation of the reason why a given prediction was computed. Other systems are based on a set of rules that are easy to interpret by a human. However, those rule-based systems can cope with a limited number of abnormal situations, and are not flexible enough to adapt to different users and contextual situations. In this paper, we tackle this challenging problem by proposing a flexible AI system to recognize early symptoms of cognitive decline in smart-homes, which is able to explain the reason of predictions at a fine-grained level. Our method relies on well known clinical indicators that consider subtle and overt behavioral anomalies, as well as spatial disorientation and wandering behaviors. In order to adapt to different individuals and situations, anomalies are recognized using a collaborative approach. We experimented our approach with a large set of real world subjects, including people with MCI and people with dementia. We also implemented a dashboard to allow clinicians to inspect anomalies together with the explanations of predictions. Results show that our system’s predictions are significantly correlated to the person’s actual diagnosis. Moreover, a preliminary user study with clinicians suggests that the explanation capabilities of our system are useful to improve the task performance and to increase trust. To the best of our knowledge, this is the first work that explores data-driven explainable AI for supporting the diagnosis of cognitive decline.","2021-03-01","2021-06-05 17:54:16","2021-06-05 17:54:29","2021-06-05 17:54:14","168-189","","","116","","Future Generation Computer Systems","HealthXAI","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\FQNR34T8\S0167739X20330144.html","","","Cognitive decline; Explainable artificial intelligence; Pervasive healthcare; Sensor-based activity recognition","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8HMZXRC","journalArticle","2020","Meldo, Anna; Utkin, Lev; Kovalev, Maxim; Kasimov, Ernest","The natural language explanation algorithms for the lung cancer computer-aided diagnosis system","Artificial Intelligence in Medicine","","0933-3657","10.1016/j.artmed.2020.101952","https://www.sciencedirect.com/science/article/pii/S0933365720303900","Two algorithms for explaining decisions of a lung cancer computer-aided diagnosis system are proposed. Their main peculiarity is that they produce explanations of diseases in the form of special sentences via natural language. The algorithms consist of two parts. The first part is a standard local post-hoc explanation model, for example, the well-known LIME, which is used for selecting important features from a special feature representation of the segmented lung suspicious objects. This part is identical for both algorithms. The second part is a model which aims to connect selected important features and to transform them to explanation sentences in natural language. This part is implemented differently for both algorithms. The training phase of the first algorithm uses a special vocabulary of simple phrases which produce sentences and their embeddings. The second algorithm significantly simplifies some parts of the first algorithm and reduces the explanation problem to a set of simple classifiers. The basic idea behind the improvement is to represent every simple phrase from vocabulary as a class of the “sparse” histograms. An implementation of the second algorithm is shown in detail.","2020-08-01","2021-06-05 17:54:16","2021-06-05 17:54:30","2021-06-05 17:54:15","101952","","","108","","Artificial Intelligence in Medicine","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\ZDTXMYPC\S0933365720303900.html","","","Classification; Computer-aided diagnosis; Lung cancer; Explainable AI; Causability; LIME; Natural language; Visual explanations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYJTXXAJ","journalArticle","2020","Brunese, Luca; Mercaldo, Francesco; Reginelli, Alfonso; Santone, Antonella","Explainable Deep Learning for Pulmonary Disease and Coronavirus COVID-19 Detection from X-rays","Computer Methods and Programs in Biomedicine","","0169-2607","10.1016/j.cmpb.2020.105608","https://www.sciencedirect.com/science/article/pii/S0169260720314413","Background and Objective: Coronavirus disease (COVID-19) is an infectious disease caused by a new virus never identified before in humans. This virus causes respiratory disease (for instance, flu) with symptoms such as cough, fever and, in severe cases, pneumonia. The test to detect the presence of this virus in humans is performed on sputum or blood samples and the outcome is generally available within a few hours or, at most, days. Analysing biomedical imaging the patient shows signs of pneumonia. In this paper, with the aim of providing a fully automatic and faster diagnosis, we propose the adoption of deep learning for COVID-19 detection from X-rays. Method: In particular, we propose an approach composed by three phases: the first one to detect if in a chest X-ray there is the presence of a pneumonia. The second one to discern between COVID-19 and pneumonia. The last step is aimed to localise the areas in the X-ray symptomatic of the COVID-19 presence. Results and Conclusion: Experimental analysis on 6,523 chest X-rays belonging to different institutions demonstrated the effectiveness of the proposed approach, with an average time for COVID-19 detection of approximately 2.5 seconds and an average accuracy equal to 0.97.","2020-11-01","2021-06-05 17:54:16","2021-06-05 17:54:30","2021-06-05 17:54:15","105608","","","196","","Computer Methods and Programs in Biomedicine","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\MN9M6S2A\S0169260720314413.html; C:\Users\Asus\Zotero\storage\TVJUYGS6\Brunese et al. - 2020 - Explainable Deep Learning for Pulmonary Disease an.pdf","","","Artificial intelligence; Deep learning; COVID-19; Transfer learning; Coronavirus; Chest","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7UHKAV5K","journalArticle","2020","Sabol, Patrik; Sinčák, Peter; Hartono, Pitoyo; Kočan, Pavel; Benetinová, Zuzana; Blichárová, Alžbeta; Verbóová, Ľudmila; Štammová, Erika; Sabolová-Fabianová, Antónia; Jašková, Anna","Explainable classifier for improving the accountability in decision-making for colorectal cancer diagnosis from histopathological images","Journal of Biomedical Informatics","","1532-0464","10.1016/j.jbi.2020.103523","https://www.sciencedirect.com/science/article/pii/S1532046420301519","Pathologists are responsible for cancer type diagnoses from histopathological cancer tissues. However, it is known that microscopic examination is tedious and time-consuming. In recent years, a long list of machine learning approaches to image classification and whole-slide segmentation has been developed to support pathologists. Although many showed exceptional performances, the majority of them are not able to rationalize their decisions. In this study, we developed an explainable classifier to support decision making for medical diagnoses. The proposed model does not provide an explanation about the causality between the input and the decisions, but offers a human-friendly explanation about the plausibility of the decision. Cumulative Fuzzy Class Membership Criterion (CFCMC) explains its decisions in three ways: through a semantical explanation about the possibilities of misclassification, showing the training sample responsible for a certain prediction and showing training samples from conflicting classes. In this paper, we explain about the mathematical structure of the classifier, which is not designed to be used as a fully automated diagnosis tool but as a support system for medical experts. We also report on the accuracy of the classifier against real world histopathological data for colorectal cancer. We also tested the acceptability of the system through clinical trials by 14 pathologists. We show that the proposed classifier is comparable to state of the art neural networks in accuracy, but more importantly it is more acceptable to be used by human experts as a diagnosis tool in the medical domain.","2020-09-01","2021-06-05 17:54:16","2021-06-05 17:54:30","2021-06-05 17:54:15","103523","","","109","","Journal of Biomedical Informatics","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\A9EBWGNR\S1532046420301519.html","","","Digital pathology; Explainable artificial intelligence; Colorectal cancer; Explainable machine learning; Uncertainty measure","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"394L59KW","journalArticle","2020","Pandit, Vedhas; Schmitt, Maximilian; Cummins, Nicholas; Schuller, Björn","I see it in your eyes: Training the shallowest-possible CNN to recognise emotions and pain from muted web-assisted in-the-wild video-chats in real-time","Information Processing & Management","","0306-4573","10.1016/j.ipm.2020.102347","https://www.sciencedirect.com/science/article/pii/S0306457320308426","A robust value- and time-continuous emotion recognition has enormous potential benefits within healthcare. For example, within mental health, a real-time patient monitoring system capable of accurately inferring a patient’s emotional state could help doctors make an appropriate diagnosis and treatment plan. Such interventions could be vital in terms of ensuring a higher quality of life for the patient involved. To make such tools a reality, the associated machine learning systems need to be fast, robust and generalisable. In this regard, we present herein, a novel emotion recognition system consisting of the shallowest realisable Convolutional Neural Network (CNN) architecture. We draw insights from visualisations of the trained filter weights and the facial action unit (FAU) activations, i. e. the inputs to the model, of the participants featured in the in-the-wild, spontaneous video-chat sessions of the SEWA corpus. Further, we demonstrate the generalisablity of this approach on the German, Hungarian, and Chinese cultures available in this corpus. The obtained cross-cultural performance is a testimony to the universality of FAUs in expression and understanding of the human affective behaviours. These learnings were moderately consistent with the human perception of emotional expression. The practicality of the proposed approach is also demonstrated in another key healthcare applications; pain intensity prediction. Key results from these experiments highlight the transparency of the shallow CNN structure. As FAU can be extracted in near real-time, and because the models we developed are exceptionally shallow, this study paves the way for a robust, cross-cultural, end-to-end, in-the-wild, explainable real-time affect and pain prediction, that is value- and time-continuous.","2020-11-01","2021-06-05 17:54:16","2021-06-05 17:54:31","2021-06-05 17:54:16","102347","","6","57","","Information Processing & Management","I see it in your eyes","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\QJ4XAPWV\S0306457320308426.html","","","Healthcare; Feature selection; Affect recognition; Explainable; In-the-wild; Real-time","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CMZXXMHH","journalArticle","2020","Magesh, Pavan Rajkumar; Myloth, Richard Delwin; Tom, Rijo Jackson","An Explainable Machine Learning Model for Early Detection of Parkinson's Disease using LIME on DaTSCAN Imagery","Computers in Biology and Medicine","","0010-4825","10.1016/j.compbiomed.2020.104041","https://www.sciencedirect.com/science/article/pii/S0010482520303723","Parkinson's Disease (PD) is a degenerative and progressive neurological condition. Early diagnosis can improve treatment for patients and is performed through dopaminergic imaging techniques like the SPECT DaTSCAN. In this study, we propose a machine learning model that accurately classifies any given DaTSCAN as having Parkinson's disease or not, in addition to providing a plausible reason for the prediction. This kind of reasoning is done through the use of visual indicators generated using Local Interpretable Model-Agnostic Explainer (LIME) methods. DaTSCANs were drawn from the Parkinson's Progression Markers Initiative database and trained on a CNN (VGG16) using transfer learning, yielding an accuracy of 95.2%, a sensitivity of 97.5%, and a specificity of 90.9%. Keeping model interpretability of paramount importance, especially in the healthcare field, this study utilises LIME explanations to distinguish PD from non-PD, using visual superpixels on the DaTSCANs. It could be concluded that the proposed system, in union with its measured interpretability and accuracy may effectively aid medical workers in the early diagnosis of Parkinson's Disease.","2020-11-01","2021-06-05 17:54:16","2021-06-05 17:54:31","2021-06-05 17:54:16","104041","","","126","","Computers in Biology and Medicine","","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\Z9DAEZBY\S0010482520303723.html; C:\Users\Asus\Zotero\storage\WNDGUUTQ\Magesh et al. - 2020 - An Explainable Machine Learning Model for Early De.pdf","","","Convolutional neural network; Computer-aided diagnosis; Interpretability; Explainable AI; Parkinson's disease","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YIEKS2WW","journalArticle","2021","Itani, Sarah; Thanou, Dorina","Combining anatomical and functional networks for neuropathology identification: A case study on autism spectrum disorder","Medical Image Analysis","","1361-8415","10.1016/j.media.2021.101986","https://www.sciencedirect.com/science/article/pii/S1361841521000323","While the prevalence of Autism Spectrum Disorder (ASD) is increasing, research continues in an effort to identify common etiological and pathophysiological bases. In this regard, modern machine learning and network science pave the way for a better understanding of the neuropathology and the development of diagnosis aid systems. The present work addresses the classification of neurotypical and ASD subjects by combining knowledge about both the structure and the functional activity of the brain. In particular, we model the brain structure as a graph, and the resting-state functional MRI (rs-fMRI) signals as values that live on the nodes of that graph. We then borrow tools from the emerging field of Graph Signal Processing (GSP) to build features related to the frequency content of these signals. In order to make these features highly discriminative, we apply an extension of the Fukunaga-Koontz transform. Finally, we use these new markers to train a decision tree, an interpretable classification scheme, which results in a final diagnosis aid model. Interestingly, the resulting decision tree outperforms state-of-the-art methods on the publicly available Autism Brain Imaging Data Exchange (ABIDE) collection. Moreover, the analysis of the predictive markers reveals the influence of the frontal and temporal lobes in the diagnosis of the disorder, which is in line with previous findings in the literature of neuroscience. Our results indicate that exploiting jointly structural and functional information of the brain can reveal important information about the complexity of the neuropathology.","2021-04-01","2021-06-05 17:54:16","2021-06-05 17:54:32","2021-06-05 17:54:16","101986","","","69","","Medical Image Analysis","Combining anatomical and functional networks for neuropathology identification","","","","","","","en","","","","","ScienceDirect","","","","C:\Users\Asus\Zotero\storage\QL56SBG8\S1361841521000323.html","","","Autism spectrum disorder; Explainable artificial intelligence; fMRI; Graph signal processing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""