"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"YUTFTX2H","journalArticle","2021","Li, Tianfu; Zhao, Zhibin; Sun, Chuang; Cheng, Li; Chen, Xuefeng; Yan, Ruqiang; Gao, Robert X.","A A WaveletKernelNet: An Interpretable Deep Neural Network for Industrial Intelligent Diagnosis","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2168-2232","10.1109/TSMC.2020.3048950","","Convolutional neural network (CNN), with the ability of feature learning and nonlinear mapping, has demonstrated its effectiveness in prognostics and health management (PHM). However, an explanation on the physical meaning of a CNN architecture has rarely been studied. In this article, a novel wavelet-driven deep neural network, termed as WaveletKernelNet (WKN), is presented, where a continuous wavelet convolutional (CWConv) layer is designed to replace the first convolutional layer of the standard CNN. This enables the first CWConv layer to discover more meaningful kernels. Furthermore, only the scale parameter and translation parameter are directly learned from raw data at this CWConv layer. This provides a very effective way to obtain a customized kernel bank, specifically tuned for extracting defect-related impact component embedded in the vibration signal. In addition, three experimental studies using data from laboratory environment are carried out to verify the effectiveness of the proposed method for mechanical fault diagnosis. The experimental results show that the accuracy of the WKNs is higher than CNN by more than 10%, which indicate the importance of the designed CWConv layer. Besides, through theoretical analysis and feature map visualization, it is found that the WKNs are interpretable, have fewer parameters, and have the ability to converge faster within the same training epochs.","2021","2021-06-04 19:11:27","2021-06-18 05:29:26","","1-11","","","","","","WaveletKernelNet","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Systems, Man, and Cybernetics: Systems","","C:\Users\Asus\Zotero\storage\XW2ZJ847\9328876.html; C:\Users\Asus\Zotero\storage\BZW7BEMW\Li et al. - 2021 - WaveletKernelNet An Interpretable Deep Neural Net.pdf","","","Neural networks; Feature extraction; Prognostics and health management; Fault diagnosis; Kernel; Continuous wavelet convolutional (CWConv) layer; continuous wavelet transform (CWT); Continuous wavelet transforms; Convolution; convolutional neural network (CNN); machine fault diagnosis; prognostic and health management (PHM)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PCS9LMEC","journalArticle","2020","Liao, WangMin; Zou, BeiJi; Zhao, RongChang; Chen, YuanQiong; He, ZhiYou; Zhou, MengJie","Clinical Interpretable Deep Learning Model for Glaucoma Diagnosis","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2019.2949075","","Despite the potential to revolutionise disease diagnosis by performing data-driven classification, clinical interpretability of ConvNet remains challenging. In this paper, a novel clinical interpretable ConvNet architecture is proposed not only for accurate glaucoma diagnosis but also for the more transparent interpretation by highlighting the distinct regions recognised by the network. To the best of our knowledge, this is the first work of providing the interpretable diagnosis of glaucoma with the popular deep learning model. We propose a novel scheme for aggregating features from different scales to promote the performance of glaucoma diagnosis, which we refer to as M-LAP. Moreover, by modelling the correspondence from binary diagnosis information to the spatial pixels, the proposed scheme generates glaucoma activations, which bridge the gap between global semantical diagnosis and precise location. In contrast to previous works, it can discover the distinguish local regions in fundus images as evidence for clinical interpretable glaucoma diagnosis. Experimental results, performed on the challenging ORIGA datasets, show that our method on glaucoma diagnosis outperforms state-of-the-art methods with the highest AUC (0.88). Remarkably, the extensive results, optic disc segmentation (dice of 0.9) and local disease focus localization based on the evidence map, demonstrate the effectiveness of our methods on clinical interpretability.","2020-05","2021-06-04 19:11:27","2021-06-04 19:11:27","","1405-1412","","5","24","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\8I44BQ4H\8880490.html","","","Feature extraction; Lesions; Semantics; Convolution; Biomedical optical imaging; clinical interpreta-tion; Computer architecture; Glaucoma diagnosis; medical image processing; Optical imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MPN46BLN","journalArticle","2020","Zhang, Shijie; Du, Huarui; Jin, Zhuang; Zhu, Yaqiong; Zhang, Ying; Xie, Fang; Zhang, Mingbo; Tian, Xiaoqi; Zhang, Jue; Luo, Yukun","A Novel Interpretable Computer-Aided Diagnosis System of Thyroid Nodules on Ultrasound Based on Clinical Experience","IEEE Access","","2169-3536","10.1109/ACCESS.2020.2976495","","Computer-aided diagnosis systems (CADs) present valuable second opinions to radiologists in diagnosis. Many studies on thyroid nodules have proposed various CADs to provide a binary result, benignity or malignancy, for doctors, ignoring interpretability of more ultrasonic features that could be more useful. We develop an interpretable CADs (iCADS) that utilizes deep-learning networks' classification power and interpretability potential of clinical guidelines, like TIRADS, a well-established scale for thyroid nodules. iCADS incorporates a main neural-networks model and six neural-network based interpreters. The outputs of the six interpreters are compared with TIRADS guidelines and the matched result will form a report, more than a benignity or malignancy result, for radiologists. Clinical images of 16,946 thyroid nodules from 5,885 patients were used to train the proposed iCADS. An extra experimental data set containing 501 images were used to test the performance of the model. For better illustrating the assistant ability of iCADS, we also recruited ten junior radiologists to make diagnosis decisions with or without the help of different versions of iCADS. The experiments demonstrated that iCADS can largely improve junior radiologists diagnosis with the help of interpreter strategy. These experiments are also the very first attempt to evaluate the effect of interpretability of deep-learning based CADs in clinical practice. Comparison experiments with other deep-learning based CADs and traditional CADs indicated that the interpreter strategy can easily be combined to other intelligent CADs without the loss of performance. The framework of iCADS can also inspire more research on the development of CADs.","2020","2021-06-04 19:11:27","2021-06-04 19:11:27","","53223-53231","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\TXIFWN7R\Zhang et al. - 2020 - A Novel Interpretable Computer-Aided Diagnosis Sys.pdf; C:\Users\Asus\Zotero\storage\DNJDT99I\9016204.html","","","Feature extraction; Lesions; Cancer; deep learning; Pathology; Guidelines; Interpretable computer-aided diagnosis system; multi-task learning; thyroid nodules; Ultrasonic imaging; ultrasound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A55BYGSJ","journalArticle","2020","Lelis, Viviane M.; Guzmán, Eduardo; Belmonte, María-Victoria","Non-Invasive Meningitis Diagnosis Using Decision Trees","IEEE Access","","2169-3536","10.1109/ACCESS.2020.2966397","","Meningitis is one of the pandemic diseases that many less developed countries suffer, primarily due to the lack of economic resources to face it. The more severe types of meningitis, Meningococcal Disease, MD, demand immediate medical attention since delays increase the risk of mortality. This paper presents an open and integrated Clinical Decision Support System to assist physicians in the different stages of meningitis diagnostics through observable symptoms. Our system integrates three intelligent components which try to give support to physicians in early diagnostics of meningitis. These components are based on interpretable tree-based machine learning models and knowledge-engineering techniques. A dataset of 26,228 records of patients with a meningitis diagnosis in Brazil was used to construct and evaluate the system. The performance indicators of the decision models exhibit an outstanding classification performance for MD meningitis with a classification accuracy of 94.3%. In order to test the correct diagnosis of the system, an evaluation study with real patients' data was performed. The experimental results concluded that excluding meningitis cases based only on observable symptoms is much more complicated than diagnosing it. However, the system properly diagnosed 88% of meningitis cases from the real database.","2020","2021-06-04 19:11:27","2021-06-04 19:11:27","","18394-18407","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\CM99FKBS\Lelis et al. - 2020 - Non-Invasive Meningitis Diagnosis Using Decision T.pdf; C:\Users\Asus\Zotero\storage\S3VXG8V5\8957562.html","","","Diseases; Medical diagnostic imaging; Machine learning; Medical diagnosis; Tools; Decision trees; meningitis diagnostic models; Microorganisms; tree-based machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WACI8CE2","journalArticle","2020","Chen, Han-Yun; Lee, Ching-Hung","A A Vibration Signals Analysis by Explainable Artificial Intelligence (XAI) Approach: Application on Bearing Faults Diagnosis","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3006491","","This study introduces an explainable artificial intelligence (XAI) approach of convolutional neural networks (CNNs) for classification in vibration signals analysis. First, vibration signals are transformed into images by short-time Fourier transform (STFT). A CNN is applied as classification model, and Gradient class activation mapping (Grad-CAM) is utilized to generate the attention of model. By analyzing the attentions, the explanation of classification models for vibration signals analysis can be carried out. Finally, the verifications of attention are introduced by neural networks, adaptive network-based fuzzy inference system (ANFIS), and decision trees to demonstrate the proposed results. By the proposed methodology, the explanation of model using highlighted attentions is carried out.","2020","2021-06-04 19:11:27","2021-06-18 05:30:03","","134246-134256","","","8","","","Vibration Signals Analysis by Explainable Artificial Intelligence (XAI) Approach","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\4B7F2W2T\Chen and Lee - 2020 - Vibration Signals Analysis by Explainable Artifici.pdf; C:\Users\Asus\Zotero\storage\2WNCUXAA\9131692.html","","","Feature extraction; Machine learning; Convolutional neural network; explainable AI; Fault diagnosis; Vibrations; fault diagnosis; Frequency-domain analysis; Contracts; Signal analysis; vibration signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J52BRWNH","journalArticle","2019","Li, Xingyu; Radulovic, Marko; Kanjer, Ksenija; Plataniotis, Konstantinos N.","Discriminative Pattern Mining for Breast Cancer Histopathology Image Classification via Fully Convolutional Autoencoder","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2904245","","Accurate diagnosis of breast cancer in histopathology images is challenging due to the heterogeneity of cancer cell growth as well as a variety of benign breast tissue proliferative lesions. In this paper, we propose a practical and self-interpretable invasive cancer diagnosis solution. With minimum annotation information, the proposed method mines contrast patterns between normal and malignant images in a weak-supervised manner and generate a probability map of abnormalities to verify its reasoning. Particularly, a fully convolutional autoencoder is used to learn the dominant structural patterns among normal image patches. Patches that do not share the characteristics of this normal population are detected and analyzed by one-class support vector machine and one-layer neural network. We apply the proposed method to a public breast cancer image set. Our results, in consultation with a senior pathologist, demonstrate that the proposed method outperforms existing methods. The obtained probability map could benefit the pathology practice by providing visualized verification data and potentially leads to a better understanding of data-driven diagnosis solutions.","2019","2021-06-04 19:11:27","2021-06-04 19:11:27","","36433-36445","","","7","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\JNFRX9GV\Li et al. - 2019 - Discriminative Pattern Mining for Breast Cancer Hi.pdf; C:\Users\Asus\Zotero\storage\S8MVDN8S\8664469.html","","","Pathology; Training; Breast cancer; Support vector machines; Image reconstruction; abnormality detection; Breast cancer diagnosis; convolutional autoencoder; discriminative pattern learning; histopathology image analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W66VDQ69","journalArticle","2020","Gu, Donghao; Li, Yaowei; Jiang, Feng; Wen, Zhaojing; Liu, Shaohui; Shi, Wuzhen; Lu, Guangming; Zhou, Changsheng","VINet: A Visually Interpretable Image Diagnosis Network","IEEE Transactions on Multimedia","","1941-0077","10.1109/TMM.2020.2971170","","Recently, due to the black box characteristics of deep learning techniques, the deep network-based computer-aided diagnosis (CADx) systems have encountered many difficulties in practical applications. The crux of the problem is that these models should be explainable the model should give doctors rationales that can explain the diagnosis. In this paper, we propose a visually interpretable network (VINet) which can generate diagnostic visual interpretations while making accurate diagnoses. VINet is an end-to-end model consisting of an importance estimation network and a classification network. The former produces a diagnostic visual interpretation for each case, and the classifier diagnoses the case. In the classifier, by exploring the information in the diagnostic visual interpretation, the irrelevant information in the feature maps is eliminated by our proposed feature destruction process. This allows the classification network to concentrate on the important features and use them as the primary references for classification. Through a joint optimization of higher classification accuracy and eliminating as many irrelevant features as possible, a precise, fine-grained diagnostic visual interpretation, along with an accurate diagnosis, can be produced by our proposed network simultaneously. Based on a computed tomography image dataset (LUNA16) on pulmonary nodule, extensive experiments have been conducted, demonstrating that the proposed VINet can produce state-of-the-art diagnostic visual interpretations compared with all baseline methods.","2020-07","2021-06-04 19:11:27","2021-06-04 19:11:27","","1720-1729","","7","22","","","VINet","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Multimedia","","C:\Users\Asus\Zotero\storage\P3Z6HYUY\8979157.html","","","Computational modeling; Solid modeling; Task analysis; Biomedical imaging; Medical services; Visualization; Machine learning; Estimation; image classification; medical diagnostic imaging; neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8G49FHK6","journalArticle","2020","Thakoor, Kaveri A.; Koorathota, Sharath C.; Hood, Donald C.; Sajda, Paul","Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images","IEEE Transactions on Biomedical Engineering","","1558-2531","10.1109/TBME.2020.3043215","","Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.","2020","2021-06-04 19:11:27","2021-06-04 19:11:27","","1-1","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Biomedical Engineering","","C:\Users\Asus\Zotero\storage\LKMRMMF9\9286420.html","","","Deep learning; Data models; Feature extraction; Training; Retina; Computer-aided decision support; Eye tracking; Medical expert systems; Optical Coherence Tomography; Robustness; Testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R888UKDG","journalArticle","2020","Lu, Jiayi; Jin, Renchao; Song, Enmin; Alrashoud, Mubarak; Al-Mutib, Khaled N.; Al-Rakhami, Mabrook S.","An Explainable System for Diagnosis and Prognosis of COVID-19","IEEE Internet of Things Journal","","2327-4662","10.1109/JIOT.2020.3037915","","The outbreak of COVID-19 has posed a threat to world health. With the increasing number of people infected, healthcare systems, especially those in developing countries, are bearing tremendous pressure. There is an urgent need for the diagnosis of COVID-19 and the prognosis of inpatients. To alleviate these problems, a data-driven medical assistance system is put forward in this paper. Based on two real-world datasets in Wuhan, China, the proposed system integrates data from different sources with tools of machine learning (ML) to predict COVID-19 infected probability of suspected patients in their first visit, and then predict mortality of confirmed cases. Rather than choosing an interpretable algorithm, this system separates the explanations from machine learning models. It can do help to patient triaging and provide some useful advice for doctors.","2020","2021-06-04 19:11:27","2021-06-04 19:11:27","","1-1","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Internet of Things Journal","","C:\Users\Asus\Zotero\storage\9PL7DK53\Lu et al. - 2020 - An Explainable System for Diagnosis and Prognosis .pdf; C:\Users\Asus\Zotero\storage\NTBK7GNT\9259025.html","","","Medical diagnostic imaging; COVID-19; Predictive models; Diagnosis; Internet of Things; Machine Learning; Mathematical model; Monitoring; Prognosis.; Prognostics and health management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7TSG49X2","journalArticle","2015","Wong, Shen Yuong; Yap, Keem Siah; Yap, Hwa Jen; Tan, Shing Chiang; Chang, Siow Wee","A A On Equivalence of FIS and ELM for Interpretable Rule-Based Knowledge Representation","IEEE Transactions on Neural Networks and Learning Systems","","2162-2388","10.1109/TNNLS.2014.2341655","","This paper presents a fuzzy extreme learning machine (F-ELM) that embeds fuzzy membership functions and rules into the hidden layer of extreme learning machine (ELM). Similar to the concept of ELM that employed the random initialization technique, three parameters of F-ELM are randomly assigned. They are the standard deviation of the membership functions, matrix-C (rule-combination matrix), and matrix-D [don't care (DC) matrix]. Fuzzy if-then rules are formulated by the rule-combination Matrix of F-ELM, and a DC approach is adopted to minimize the number of input attributes in the rules. Furthermore, F-ELM utilizes the output weights of the ELM to form the target class and confidence factor for each of the rules. This is to indicate that the corresponding consequent parameters are determined analytically. The operations of F-ELM are equivalent to a fuzzy inference system. Several benchmark data sets and a real world fault detection and diagnosis problem have been used to empirically evaluate the efficacy of the proposed F-ELM in handling pattern classification tasks. The results show that the accuracy rates of F-ELM are comparable (if not superior) to ELM with distinctive ability of providing explicit knowledge in the form of interpretable rule base.","2015-07","2021-06-04 19:11:27","2021-06-18 05:29:37","","1417-1430","","7","26","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Neural Networks and Learning Systems","","C:\Users\Asus\Zotero\storage\3P47UECN\6877713.html","","","Computational modeling; Training; Artificial neural networks; Accuracy; Extreme learning machine (ELM); fuzzy inference system (FIS); Fuzzy logic; Neurons; pattern classification; Pragmatics; rule based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L3KNMZKZ","journalArticle","2021","Tsang, Gavin; Zhou, Shang-Ming; Xie, Xianghua","Modeling Large Sparse Data for Feature Selection: Hospital Admission Predictions of the Dementia Patients Using Primary Care Electronic Health Records","IEEE Journal of Translational Engineering in Health and Medicine","","2168-2372","10.1109/JTEHM.2020.3040236","","A growing elderly population suffering from incurable, chronic conditions such as dementia present a continual strain on medical services due to mental impairment paired with high comorbidity resulting in increased hospitalization risk. The identification of at risk individuals allows for preventative measures to alleviate said strain. Electronic health records provide opportunity for big data analysis to address such applications. Such data however, provides a challenging problem space for traditional statistics and machine learning due to high dimensionality and sparse data elements. This article proposes a novel machine learning methodology: entropy regularization with ensemble deep neural networks (ECNN), which simultaneously provides high predictive performance of hospitalization of patients with dementia whilst enabling an interpretable heuristic analysis of the model architecture, able to identify individual features of importance within a large feature domain space. Experimental results on health records containing 54,647 features were able to identify 10 event indicators within a patient timeline: a collection of diagnostic events, medication prescriptions and procedural events, the highest ranked being essential hypertension. The resulting subset was still able to provide a highly competitive hospitalization prediction (Accuracy: 0.759) as compared to the full feature domain (Accuracy: 0.755) or traditional feature selection techniques (Accuracy: 0.737), a significant reduction in feature size. The discovery and heuristic evidence of correlation provide evidence for further clinical study of said medical events as potential novel indicators. There also remains great potential for adaption of ECNN within other medical big data domains as a data mining tool for novel risk factor identification.","2021","2021-06-04 19:11:27","2021-06-04 19:11:27","","1-13","","","9","","","Modeling Large Sparse Data for Feature Selection","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Translational Engineering in Health and Medicine","","C:\Users\Asus\Zotero\storage\GTIQT35E\Tsang et al. - 2021 - Modeling Large Sparse Data for Feature Selection .pdf; C:\Users\Asus\Zotero\storage\YY3YK6XH\9268962.html","","","Deep learning; Medical diagnostic imaging; Magnetic resonance imaging; machine learning; Machine learning; Training; Artificial neural networks; Sociology; feature selection; dementia; Dementia; electronic health records; hospitalization; risk factors; weight regularization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AF6PTMX4","journalArticle","2020","Chen, Richard J.; Lu, Ming Y.; Wang, Jingwen; Williamson, Drew F. K.; Rodig, Scott J.; Lindeman, Neal I.; Mahmood, Faisal","Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.3021387","","Cancer diagnosis, prognosis, and therapeutic response predictions are based on morphological information from histology slides and molecular profiles from genomic data. However, most deep learning-based objective outcome prediction and grading paradigms are based on histology or genomics alone and do not make use of the complementary information in an intuitive manner. In this work, we propose Pathomic Fusion, an interpretable strategy for end-to-end multimodal fusion of histology image and genomic (mutations, CNV, RNASeq) features for survival outcome prediction. Our approach models pairwise feature interactions across modalities by taking the Kronecker product of unimodal feature representations, and controls the expressiveness of each representation via a gatingbased attention mechanism. Following supervised learning, we are able to interpret and saliently localize features across each modality, and understand how feature importance shifts when conditioning on multimodal input. We validate our approach using glioma and clear cell renal cell carcinoma datasets from the Cancer Genome Atlas (TCGA), which contains paired wholeslide image, genotype, and transcriptome data with ground truth survival and histologic grade labels. In a 15-fold cross-validation, our results demonstrate that the proposed multimodal fusion paradigm improves prognostic determinations from ground truth grading and molecular subtyping, as well as unimodal deep networks trained on histology and genomic data alone. The proposed method establishes insight and theory on how to train deep networks on multimodal biomedical data in an intuitive manner, which will be useful for other problems in medicine that seek to combine heterogeneous data streams for understanding diseases and predicting response and resistance to treatment. Code and trained models are made available at: https://github.com/mahmoodlab/PathomicFusion.","2020","2021-06-04 19:11:27","2021-06-04 19:11:27","","1-1","","","","","","Pathomic Fusion","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\W9ZQZFL6\9186053.html; C:\Users\Asus\Zotero\storage\XSLIFMS3\Chen et al. - 2020 - Pathomic Fusion An Integrated Framework for Fusin.pdf","","","Bioinformatics; Feature extraction; Machine learning; Cancer; Genomics; Graph Convolutional Networks; Microprocessors; Multimodal Learning; Survival Analysis; Tumors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KRAAYQZC","journalArticle","2021","Jiang, Shancheng; Li, Huichuan; Jin, Zhi","A Visually Interpretable Deep Learning Framework for Histopathological Image-Based Skin Cancer Diagnosis","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2021.3052044","","Owing to the high incidence rate and the severe impact of skin cancer, the precise diagnosis of malignant skin tumors is a significant goal, especially considering treatment is normally effective if the tumor is detected early. Limited published histopathological image sets and the lack of an intuitive correspondence between the features of lesion areas and a certain type of skin cancer pose a challenge to the establishment of high-quality and interpretable computer-aided diagnostic (CAD) systems. To solve this problem, a light-weight attention mechanism-based deep learning framework, namely, DRANet, is proposed to differentiate 11 types of skin diseases based on a real histopathological image set collected by us during the last 10 years. The CAD system can output not only the name of a certain disease but also a visualized diagnostic report showing possible areas related to the disease. The experimental results demonstrate that the DRANet obtains significantly better performance than baseline models (i.e., InceptionV3, ResNet50, VGG16, and VGG19) with comparable parameter size and competitive accuracy with fewer model parameters. Visualized results produced by the hidden layers of the DRANet actually highlight part of the class-specific regions of diagnostic points and are valuable for decision making in the diagnosis of skin diseases.","2021-05","2021-06-04 19:11:27","2021-06-04 19:11:27","","1483-1494","","5","25","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\954UZZBP\9325524.html","","","Solid modeling; Deep learning; Diseases; Attention mechanism; computer-aided diagnostic system; Lesions; model visualization; Skin; Skin cancer; skin histopathological image; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKFUAF4L","journalArticle","2018","Wu, Zhenyu; Luo, Hao; Yang, Yunong; Lv, Peng; Zhu, Xinning; Ji, Yang; Wu, Bian","A A K-PdM: KPI-Oriented Machinery Deterioration Estimation Framework for Predictive Maintenance Using Cluster-Based Hidden Markov Model","IEEE Access","","2169-3536","10.1109/ACCESS.2018.2859922","","Explosive increase of industrial data collected from sensors has brought increasing attractions to the data-driven predictive maintenance for industrial machines in cyber-physical systems (CPSs). Since machinery faults are always caused by performance deterioration of components, learning the deteriorating mode from observed sensor data facilitates the prognostics of impeding faults and predicting the remaining useful life (RUL). In modern CPSs, several key performance indicators (KPIs) are monitored to detect the corresponding fine-grained deteriorating modes of industrial machines. However, the overall deterioration estimation and RUL prediction based on these KPIs with various patterns have been a great challenge, especially without labels of deteriorating index or uninterpretable of root causes. In this paper, we proposed K-PdM, a cluster-based hidden Markov model for the machinery deterioration estimation and RUL prediction based on multiple KPIs. The method uncovers the fine-grained deteriorating modes of machines through each unlabeled KPI data and learns a mapping between each deteriorating KPI index and RULs. Accordingly, an overall deterioration estimation and RUL prediction of machine are able to be achieved based on the combination of each KPI's deterioration estimation. Moreover, a set of interpretable semantic rules are setup to analyze the root cause of performance deterioration among KPIs. An experimental application is proposed to demonstrate its applicability based on the PHM08 data sets. The obtained results show their effectiveness to predict the RULs of machines.","2018","2021-06-04 19:11:27","2021-06-18 05:29:50","","41676-41687","","","6","","","K-PdM","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\RY9XPI93\Wu et al. - 2018 - K-PdM KPI-Oriented Machinery Deterioration Estima.pdf; C:\Users\Asus\Zotero\storage\73FV8XHY\8421220.html","","","Hidden Markov models; Prognostics and health management; Time series analysis; Estimation; time series analysis; Degradation; hidden Markov models (HMMs); Indexes; Machinery; remaining life assessment; Temperature measurement","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GPSDXKYS","journalArticle","2019","Liu, Chi; Huang, Yue; Ozolek, John A.; Hanna, Matthew G.; Singh, Rajendra; Rohde, Gustavo K.","SetSVM: An Approach to Set Classification in Nuclei-Based Cancer Detection","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2018.2803793","","Due to the importance of nuclear structure in cancer diagnosis, several predictive models have been described for diagnosing a wide variety of cancers based on nuclear morphology. In many computer-aided diagnosis (CAD) systems, cancer detection tasks can be generally formulated as set classification problems, which can not be directly solved by classifying single instances. In this paper, we propose a novel set classification approach SetSVM to build a predictive model by considering any nuclei set as a whole without specific assumptions. SetSVM features highly discriminative power in cancer detection challenges in the sense that it not only optimizes the classifier decision boundary but also transfers discriminative information to set representation learning. During model training, these two processes are unified in the support vector machine (SVM) maximum separation margin problem. Experiment results show that SetSVM provides significant improvements compared with five commonly used approaches in cancer detection tasks utilizing 260 patients in total across three different cancer types, namely, thyroid cancer, liver cancer, and melanoma. In addition, we show that SetSVM enables visual interpretation of discriminative nuclear characteristics representing the nuclei set. These features make SetSVM a potentially practical tool in building accurate and interpretable CAD systems for cancer detection.","2019-01","2021-06-04 19:11:27","2021-06-07 17:33:39","","351-361","","1","23","","","SetSVM","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\7IX9CZ8X\8286915.html","","","Predictive models; Cancer; Training; Kernel; visualization; Support vector machines; Cancer detection; digital pathology; nuclear quantification; nuclear structure; Prototypes; set classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6PQ7JHTM","journalArticle","2020","Han, Zhongyi; Wei, Benzheng; Hong, Yanfei; Li, Tianyang; Cong, Jinyu; Zhu, Xue; Wei, Haifeng; Zhang, Wei","Accurate Screening of COVID-19 Using Attention-Based Deep 3D Multiple Instance Learning","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2996256","","Automated Screening of COVID-19 from chest CT is of emergency and importance during the outbreak of SARS-CoV-2 worldwide in 2020. However, accurate screening of COVID-19 is still a massive challenge due to the spatial complexity of 3D volumes, the labeling difficulty of infection areas, and the slight discrepancy between COVID-19 and other viral pneumonia in chest CT. While a few pioneering works have made significant progress, they are either demanding manual annotations of infection areas or lack of interpretability. In this paper, we report our attempt towards achieving highly accurate and interpretable screening of COVID-19 from chest CT with weak labels. We propose an attention-based deep 3D multiple instance learning (AD3D-MIL) where a patient-level label is assigned to a 3D chest CT that is viewed as a bag of instances. AD3D-MIL can semantically generate deep 3D instances following the possible infection area. AD3D-MIL further applies an attention-based pooling approach to 3D instances to provide insight into each instance's contribution to the bag label. AD3D-MIL finally learns Bernoulli distributions of the bag-level labels for more accessible learning. We collected 460 chest CT examples: 230 CT examples from 79 patients with COVID-19, 100 CT examples from 100 patients with common pneumonia, and 130 CT examples from 130 people without pneumonia. A series of empirical studies show that our algorithm achieves an overall accuracy of 97.9%, AUC of 99.0%, and Cohen kappa score of 95.7%. These advantages endow our algorithm as an efficient assisted tool in the screening of COVID-19.","2020-08","2021-06-04 19:11:27","2021-06-07 17:39:08","","2584-2594","","8","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\RIVNHNEC\Han et al. - 2020 - Accurate Screening of COVID-19 Using Attention-Bas.pdf; C:\Users\Asus\Zotero\storage\RISYU7H3\9098062.html","","","Three-dimensional displays; Diseases; Medical diagnostic imaging; machine learning; Computed tomography; COVID-19; Lung; deep learning; multiple instance learning; screening; 3D; attention; computer-aided diagnosis; Manuals; SARS-CoV-2; Two dimensional displays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87CE5NTV","journalArticle","2019","Colopy, Glen Wright; Roberts, Stephen J.; Clifton, David A.","Gaussian Processes for Personalized Interpretable Volatility Metrics in the Step-Down Ward","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2019.2890823","","Patients in a hospital step-down unit require a level of care that is between that of the intensive care unit (ICU) and that of the general ward. While many patients remain physiologically stabilized, others will suffer clinical emergencies and be readmitted to the ICU, with a subsequent high risk of mortality. Had the associated physiological deterioration been detected early, the emergency may have been less severe or avoided entirely. Current clinical monitoring is largely heuristic, requiring manual calculation of risk scores and the use of heuristic decision criteria. Technical drawbacks include ignoring the time-series dynamics of physiological measurements, and lacking patient-specificity (i.e., personalization of models to the individual patient). In this paper, we demonstrate how Gaussian process regression models can supplement current monitoring practice by providing interpretable and intuitive illustrations of erratic vital-sign volatility. These personalized volatility metrics may provide significantly advanced warning of deterioration, while minimizing the false alarms that induce so-called alarm fatigue. While many AI-based approaches to healthcare are criticized for being uninterpretable “blackbox” methods, the cause of alarms generated from the proposed methods are explicitly interpretable and intuitive. We conclude that intelligent computational inference using methods such as those proposed can enhance current clinical decision making and potentially save lives.","2019-05","2021-06-04 19:11:27","2021-06-07 17:41:25","","949-959","","3","23","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\5FFGYYKW\Colopy et al. - 2019 - Gaussian Processes for Personalized Interpretable .pdf; C:\Users\Asus\Zotero\storage\UN4RFC64\8621007.html","","","Monitoring; Hospitals; Biomedical monitoring; forecasting; Gaussian processes; Ground penetrating radar; Informatics; patient monitoring; Precision medicine; statistical learning; time series analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8I8CXBDQ","journalArticle","2019","Playout, Clément; Duval, Renaud; Cheriet, Farida","A Novel Weakly Supervised Multitask Architecture for Retinal Lesions Segmentation on Fundus Images","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2019.2906319","","Obtaining the complete segmentation map of retinal lesions is the first step toward an automated diagnosis tool for retinopathy that is interpretable in its decision-making. However, the limited availability of ground truth lesion detection maps at a pixel level restricts the ability of deep segmentation neural networks to generalize over large databases. In this paper, we propose a novel approach for training a convolutional multi-task architecture with supervised learning and reinforcing it with weakly supervised learning. The architecture is simultaneously trained for three tasks: segmentation of red lesions and of bright lesions, those two tasks done concurrently with lesion detection. In addition, we propose and discuss the advantages of a new preprocessing method that guarantees the color consistency between the raw image and its enhanced version. Our complete system produces segmentations of both red and bright lesions. The method is validated at the pixel level and per-image using four databases and a cross-validation strategy. When evaluated on the task of screening for the presence or absence of lesions on the Messidor image set, the proposed method achieves an area under the ROC curve of 0.839, comparable with the state-of-the-art.","2019-10","2021-06-04 19:11:27","2021-06-07 17:32:48","","2434-2444","","10","38","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\728YUZSK\8672120.html","","","Task analysis; Diseases; Feature extraction; Image segmentation; Lesions; Training; Retina; Computer-aided diagnostic; fundus imaging; lesions segmentations; retina; screening","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LSW6QGL","journalArticle","2020","Chen, Jialei; Xie, Yujia; Wang, Kan; Zhang, Chuck; Vannan, Mani A; Wang, Ben; Qian, Zhen","Active Image Synthesis for Efficient","IEEE Transactions on Pattern Analysis and Machine Intelligence","","1939-3539","10.1109/TPAMI.2020.2993221","","The great success achieved by deep neural networks attracts increasing attention from the manufacturing and healthcare communities. However, the limited availability of data and high costs of data collection are the major challenges for the applications in those fields. We propose in this work AISEL, an active image synthesis method for efficient labeling, to improve the performance of the small-data learning tasks. Specifically, a complementary AISEL dataset is generated, with labels actively acquired via a physics-based method to incorporate underlining physical knowledge at hand. An important component of our AISEL method is the bidirectional generative invertible network (GIN), which can extract interpretable features from the training images and generate physically meaningful virtual images. Our AISEL method then efficiently samples virtual images not only further exploits the uncertain regions but also explores the entire image space. We then discuss the interpretability of GIN both theoretically and experimentally, demonstrating clear visual improvements over the benchmarks. Finally, we demonstrate the effectiveness of our AISEL framework on aortic stenosis application, in which our method lowers the labeling cost by 90% while achieving a 15% improvement in prediction accuracy.","2020","2021-06-04 19:11:27","2021-06-07 17:42:36","","1-1","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Pattern Analysis and Machine Intelligence","","C:\Users\Asus\Zotero\storage\FVGBQGU9\9091327.html; C:\Users\Asus\Zotero\storage\Z9NTWZYF\Chen et al. - 2020 - Active Image Synthesis for Efficient Labeling.pdf","","","Task analysis; Feature extraction; Medical services; Active learning; Computer-aided diagnosis; Data augmentation; Gallium nitride; Generative adversarial networks; Labeling; Manufacturing; Small-data learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"78NWGMV5","journalArticle","2021","Dong, Guanfang; Ma, Yingnan; Basu, Anup","Feature-Guided CNN for Denoising Images From Portable Ultrasound Devices","IEEE Access","","2169-3536","10.1109/ACCESS.2021.3059003","","As a non-invasive medical imaging scanning device, ultrasound has greatly increased the efficiency and accuracy of medical diagnosis. In recent years, portable ultrasound is being more widely used for its convenience and lower cost. Patients and physicians can receive the scanned images on their mobile phones at any time via a wireless network with low latency. However, it is difficult for portable ultrasound devices to capture images with the same quality as standard hospital ultrasound image acquisition systems. Usually, the images captured by portable ultrasound equipment have considerable noise. This noise undoubtedly affects the diagnosis of the physician. It is imperative to develop methods to remove the noise while preserving important information in the image. For this reason, we propose a novel denoising neural network model, called Feature-guided Denoising Convolutional Neural Network (FDCNN), to remove noise while retaining important feature information. In order to achieve high-quality denoising results, we employ a hierarchical denoising framework driven by a feature masking layer for medical images. Furthermore, we propose a feature extraction algorithm based on Explainable Artificial Intelligence (XAI) for medical images. Experimental results show that our medical image feature extraction method outperforms previous methods. Combined with the new denoising neural network architecture, portable ultrasound devices can now achieve better diagnostic performance.","2021","2021-06-04 19:11:27","2021-06-07 17:40:39","","28272-28281","","","9","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\TR3AP326\Dong et al. - 2021 - Feature-Guided CNN for Denoising Images From Porta.pdf; C:\Users\Asus\Zotero\storage\PMMKEMIW\9353537.html","","","Medical diagnostic imaging; Feature extraction; Image edge detection; Ultrasonic imaging; Anisotropic magnetoresistance; Backpropagation; Biomedical image processing; feature extraction; image denoising; image fusion; Noise reduction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KEMQ7F6M","journalArticle","2020","Biffi, Carlo; Cerrolaza, Juan J.; Tarroni, Giacomo; Bai, Wenjia; de Marvao, Antonio; Oktay, Ozan; Ledig, Christian; Le Folgoc, Loic; Kamnitsas, Konstantinos; Doumou, Georgia; Duan, Jinming; Prasad, Sanjay K.; Cook, Stuart A.; O’Regan, Declan P.; Rueckert, Daniel","Explainable Anatomical Shape Analysis Through Deep Hierarchical Generative Models","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2964499","","Quantification of anatomical shape changes currently relies on scalar global indexes which are largely insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven anatomical remodeling is a crucial step for the diagnosis and treatment of many conditions. Deep learning approaches have recently achieved wide success in the analysis of medical images, but they lack interpretability in the feature extraction and decision processes. In this work, we propose a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative networks to model a population of anatomical segmentations through a hierarchy of conditional latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously optimised to discriminate distinct clinical conditions, enabling the direct visualisation of the classification space. Moreover, the anatomical variability encoded by this discriminative latent space can be visualised in the segmentation space thanks to the generative properties of the model, making the classification task transparent. This approach yielded high accuracy in the categorisation of healthy and remodelled left ventricles when tested on unseen segmentations from our own multi-centre dataset as well as in an external validation set, and on hippocampi from healthy controls and patients with Alzheimer's disease when tested on ADNI data. More importantly, it enabled the visualisation in three-dimensions of both global and regional anatomical features which better discriminate between the conditions under exam. The proposed approach scales effectively to large populations, facilitating high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric imaging.","2020-06","2021-06-04 19:11:27","2021-06-07 17:43:14","","2088-2099","","6","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\2AI6D6CE\8950467.html; C:\Users\Asus\Zotero\storage\R8VUU8DZ\Biffi et al. - 2020 - Explainable Anatomical Shape Analysis Through Deep.pdf","","","Task analysis; Deep learning; Shape; Three-dimensional displays; Medical diagnostic imaging; Pathology; explainable deep learning; generative modeling; MRI; Shape analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C55DHVXL","journalArticle","2020","He, Ji; Wang, Yongbo; Ma, Jianhua","Radon Inversion via Deep Learning","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2964266","","The Radon transform is widely used in physical and life sciences, and one of its major applications is in medical X-ray computed tomography (CT), which is significantly important in disease screening and diagnosis. In this paper, we propose a novel reconstruction framework for Radon inversion with deep learning (DL) techniques. For simplicity, the proposed framework is denoted as iRadonMAP, i.e., inverse Radon transform approximation. Specifically, we construct an interpretable neural network that contains three dedicated components. The first component is a fully connected filtering (FCF) layer along the rotation angle direction in the sinogram domain, and the second one is a sinusoidal back-projection (SBP) layer, which back-projects the filtered sinogram data into the spatial domain. Next, a common network structure is added to further improve the overall performance. iRadonMAP is first pretrained on a large number of generic images from the ImageNet database and then fine-tuned with clinical patient data. The experimental results demonstrate the feasibility of the proposed iRadonMAP framework for Radon inversion.","2020-06","2021-06-04 19:11:27","2021-06-07 17:38:12","","2076-2087","","6","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\9AJCUX7F\8950464.html; C:\Users\Asus\Zotero\storage\IAGHSSNY\He et al. - 2020 - Radon Inversion via Deep Learning.pdf","","","Medical diagnostic imaging; X-ray imaging; Computed tomography; deep learning; Transforms; computed tomography; image reconstruction; Image reconstruction; Radon; Radon inversion; Radon transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IB3KFYI8","journalArticle","2020","Qian, Xuelin; Fu, Huazhu; Shi, Weiya; Chen, Tao; Fu, Yanwei; Shan, Fei; Xue, Xiangyang","M$^3$Lung-Sys: A Deep Learning System for Multi-Class Lung Pneumonia Screening From CT Imaging","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2020.3030853","","To counter the outbreak of COVID-19, the accurate diagnosis of suspected cases plays a crucial role in timely quarantine, medical treatment, and preventing the spread of the pandemic. Considering the limited training cases and resources (e.g, time and budget), we propose a Multi-task Multi-slice Deep Learning System (M3Lung-Sys) for multi-class lung pneumonia screening from CT imaging, which only consists of two 2D CNN networks, i.e., slice- and patient-level classification networks. The former aims to seek the feature representations from abundant CT slices instead of limited CT volumes, and for the overall pneumonia screening, the latter one could recover the temporal information by feature refinement and aggregation between different slices. In addition to distinguish COVID-19 from Healthy, H1N1, and CAP cases, our M3Lung-Sys also be able to locate the areas of relevant lesions, without any pixel-level annotation. To further demonstrate the effectiveness of our model, we conduct extensive experiments on a chest CT imaging dataset with a total of 734 patients (251 healthy people, 245 COVID-19 patients, 105 H1N1 patients, and 133 CAP patients). The quantitative results with plenty of metrics indicate the superiority of our proposed model on both slice- and patient-level classification tasks. More importantly, the generated lesion location maps make our system interpretable and more valuable to clinicians.","2020-12","2021-06-04 19:11:27","2021-06-07 17:32:23","","3539-3550","","12","24","","","M$^3$Lung-Sys","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\ZQ7ZH5QP\Qian et al. - 2020 - M$^3$Lung-Sys A Deep Learning System for Multi-Cl.pdf; C:\Users\Asus\Zotero\storage\UKJHGL3D\9222490.html","","","Deep learning; Computed tomography; COVID-19; Lung; Lesions; deep learning; Training data; CT imaging; lesion localization; multi-class pneumonia screening; weakly-supervised learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"THLIWG7I","journalArticle","2017","Abdi, Amir H.; Luong, Christina; Tsang, Teresa; Allan, Gregory; Nouranian, Saman; Jue, John; Hawley, Dale; Fleming, Sarah; Gin, Ken; Swift, Jody; Rohling, Robert; Abolmaesumi, Purang","Automatic Quality Assessment of Echocardiograms Using Convolutional Neural Networks: Feasibility on the Apical Four-Chamber View","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2017.2690836","","Echocardiography (echo) is a skilled technical procedure that depends on the experience of the operator. The aim of this paper is to reduce user variability in data acquisition by automatically computing a score of echo quality for operator feedback. To do this, a deep convolutional neural network model, trained on a large set of samples, was developed for scoring apical four-chamber (A4C) echo. In this paper, 6,916 end-systolic echo images were manually studied by an expert cardiologist and were assigned a score between 0 (not acceptable) and 5 (excellent). The images were divided into two independent training-validation and test sets. The network architecture and its parameters were based on the stochastic approach of the particle swarm optimization on the training-validation data. The mean absolute error between the scores from the ultimately trained model and the expert's manual scores was 0.71 ± 0.58. The reported error was comparable to the measured intra-rater reliability. The learned features of the network were visually interpretable and could be mapped to the anatomy of the heart in the A4C echo, giving confidence in the training result. The computation time for the proposed network architecture, running on a graphics processing unit, was less than 10 ms per frame, sufficient for real-time deployment. The proposed approach has the potential to facilitate the widespread use of echo at the point-of-care and enable early and timely diagnosis and treatment. Finally, the approach did not use any specific assumptions about the A4C echo, so it could be generalizable to other standard echo views.","2017-06","2021-06-04 19:11:27","2021-06-07 17:43:36","","1221-1230","","6","36","","","Automatic Quality Assessment of Echocardiograms Using Convolutional Neural Networks","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\8R5JCQJH\7892028.html","","","Machine learning; Convolutional neural networks; deep learning; Convolutional neural network; apical four-chamber; echocardiography; Echocardiography; Particle swarm optimization; quality assessment; Quality assessment; swarm optimization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LSEEXXD9","journalArticle","","","Interpretable Multimodal Fusion Networks Reveal Mechanisms of Brain Cognition","","","","","","","","2021-06-16 03:58:37","2021-06-16 03:58:41","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""