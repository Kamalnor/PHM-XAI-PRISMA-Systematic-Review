"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"S6QUPRDH","journalArticle","2020","Sogancioglu, Ecem; Murphy, Keelin; Calli, Erdi; Scholten, Ernst T.; Schalekamp, Steven; Van Ginneken, Bram","Cardiomegaly Detection on Chest Radiographs: Segmentation Versus Classification","IEEE Access","","2169-3536","10.1109/ACCESS.2020.2995567","","In this study, we investigate the detection of cardiomegaly on frontal chest radiographs through two alternative deep-learning approaches - via anatomical segmentation and via image-level classification. We used the publicly available ChestX-ray14 dataset, and obtained heart and lung segmentation annotations for 778 chest radiographs for the development of the segmentation-based approach. The classification-based method was trained with 65k standard chest radiographs with image-level labels. For both approaches, the best models were found through hyperparameter searches where architectural, learning, and regularization related parameters were optimized systematically. The resulting models were tested on a set of 367 held-out images for which cardiomegaly annotations were hand-labeled by two independent expert radiologists. Sensitivity, specificity, positive predictive value, negative predictive value, and area under the receiver operating characteristic curve (AUC) were calculated. The performance of the segmentation-based system with an AUC of 0.977 is significantly better for classifying cardiomegaly than the classification-based model which achieved an AUC of 0.941. Only the segmentation-based model achieved comparable performance to an independent expert reader (AUC of 0.978). We conclude that the segmentation-based model requires 100 times fewer annotated chest radiographs to achieve a substantially better performance, while also producing more interpretable results.","2020","2021-06-04 19:05:18","2021-06-04 19:05:18","","94631-94642","","","8","","","Cardiomegaly Detection on Chest Radiographs","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\434ZIHXC\Sogancioglu et al. - 2020 - Cardiomegaly Detection on Chest Radiographs Segme.pdf; C:\Users\Asus\Zotero\storage\K63CTJWZ\9096290.html","","","Deep learning; Image segmentation; Lung; Machine learning; Training; Heart; anatomy segmentations; cardiomegaly; chest radiographs; Radiography; Standards","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZG6Z76AC","journalArticle","2020","Lelis, Viviane M.; Guzmán, Eduardo; Belmonte, María-Victoria","Non-Invasive Meningitis Diagnosis Using Decision Trees","IEEE Access","","2169-3536","10.1109/ACCESS.2020.2966397","","Meningitis is one of the pandemic diseases that many less developed countries suffer, primarily due to the lack of economic resources to face it. The more severe types of meningitis, Meningococcal Disease, MD, demand immediate medical attention since delays increase the risk of mortality. This paper presents an open and integrated Clinical Decision Support System to assist physicians in the different stages of meningitis diagnostics through observable symptoms. Our system integrates three intelligent components which try to give support to physicians in early diagnostics of meningitis. These components are based on interpretable tree-based machine learning models and knowledge-engineering techniques. A dataset of 26,228 records of patients with a meningitis diagnosis in Brazil was used to construct and evaluate the system. The performance indicators of the decision models exhibit an outstanding classification performance for MD meningitis with a classification accuracy of 94.3%. In order to test the correct diagnosis of the system, an evaluation study with real patients' data was performed. The experimental results concluded that excluding meningitis cases based only on observable symptoms is much more complicated than diagnosing it. However, the system properly diagnosed 88% of meningitis cases from the real database.","2020","2021-06-04 19:05:18","2021-06-06 17:39:41","","18394-18407","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\ZW4GJXMN\Lelis et al. - 2020 - Non-Invasive Meningitis Diagnosis Using Decision T.pdf; C:\Users\Asus\Zotero\storage\UWYAWW8A\8957562.html","","","Diseases; Medical diagnostic imaging; Machine learning; Medical diagnosis; Tools; Decision trees; meningitis diagnostic models; Microorganisms; tree-based machine learning","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W4W82IUH","journalArticle","2020","Gu, Donghao; Li, Yaowei; Jiang, Feng; Wen, Zhaojing; Liu, Shaohui; Shi, Wuzhen; Lu, Guangming; Zhou, Changsheng","VINet: A Visually Interpretable Image Diagnosis Network","IEEE Transactions on Multimedia","","1941-0077","10.1109/TMM.2020.2971170","","Recently, due to the black box characteristics of deep learning techniques, the deep network-based computer-aided diagnosis (CADx) systems have encountered many difficulties in practical applications. The crux of the problem is that these models should be explainable the model should give doctors rationales that can explain the diagnosis. In this paper, we propose a visually interpretable network (VINet) which can generate diagnostic visual interpretations while making accurate diagnoses. VINet is an end-to-end model consisting of an importance estimation network and a classification network. The former produces a diagnostic visual interpretation for each case, and the classifier diagnoses the case. In the classifier, by exploring the information in the diagnostic visual interpretation, the irrelevant information in the feature maps is eliminated by our proposed feature destruction process. This allows the classification network to concentrate on the important features and use them as the primary references for classification. Through a joint optimization of higher classification accuracy and eliminating as many irrelevant features as possible, a precise, fine-grained diagnostic visual interpretation, along with an accurate diagnosis, can be produced by our proposed network simultaneously. Based on a computed tomography image dataset (LUNA16) on pulmonary nodule, extensive experiments have been conducted, demonstrating that the proposed VINet can produce state-of-the-art diagnostic visual interpretations compared with all baseline methods.","2020-07","2021-06-04 19:05:18","2021-06-04 19:05:18","","1720-1729","","7","22","","","VINet","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Multimedia","","C:\Users\Asus\Zotero\storage\VCA5HESS\8979157.html","","","Computational modeling; Solid modeling; Task analysis; Biomedical imaging; Medical services; Visualization; Machine learning; Estimation; image classification; medical diagnostic imaging; neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYDHM7ZX","journalArticle","2021","Tsang, Gavin; Zhou, Shang-Ming; Xie, Xianghua","Modeling Large Sparse Data for Feature Selection: Hospital Admission Predictions of the Dementia Patients Using Primary Care Electronic Health Records","IEEE Journal of Translational Engineering in Health and Medicine","","2168-2372","10.1109/JTEHM.2020.3040236","","A growing elderly population suffering from incurable, chronic conditions such as dementia present a continual strain on medical services due to mental impairment paired with high comorbidity resulting in increased hospitalization risk. The identification of at risk individuals allows for preventative measures to alleviate said strain. Electronic health records provide opportunity for big data analysis to address such applications. Such data however, provides a challenging problem space for traditional statistics and machine learning due to high dimensionality and sparse data elements. This article proposes a novel machine learning methodology: entropy regularization with ensemble deep neural networks (ECNN), which simultaneously provides high predictive performance of hospitalization of patients with dementia whilst enabling an interpretable heuristic analysis of the model architecture, able to identify individual features of importance within a large feature domain space. Experimental results on health records containing 54,647 features were able to identify 10 event indicators within a patient timeline: a collection of diagnostic events, medication prescriptions and procedural events, the highest ranked being essential hypertension. The resulting subset was still able to provide a highly competitive hospitalization prediction (Accuracy: 0.759) as compared to the full feature domain (Accuracy: 0.755) or traditional feature selection techniques (Accuracy: 0.737), a significant reduction in feature size. The discovery and heuristic evidence of correlation provide evidence for further clinical study of said medical events as potential novel indicators. There also remains great potential for adaption of ECNN within other medical big data domains as a data mining tool for novel risk factor identification.","2021","2021-06-04 19:05:18","2021-06-04 19:05:18","","1-13","","","9","","","Modeling Large Sparse Data for Feature Selection","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Translational Engineering in Health and Medicine","","C:\Users\Asus\Zotero\storage\KTT92HCP\Tsang et al. - 2021 - Modeling Large Sparse Data for Feature Selection .pdf; C:\Users\Asus\Zotero\storage\XITPSDKI\9268962.html","","","Deep learning; Medical diagnostic imaging; Magnetic resonance imaging; machine learning; Machine learning; Training; Artificial neural networks; Sociology; feature selection; dementia; Dementia; electronic health records; hospitalization; risk factors; weight regularization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IHG7Z97A","journalArticle","2019","Playout, Clément; Duval, Renaud; Cheriet, Farida","A Novel Weakly Supervised Multitask Architecture for Retinal Lesions Segmentation on Fundus Images","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2019.2906319","","Obtaining the complete segmentation map of retinal lesions is the first step toward an automated diagnosis tool for retinopathy that is interpretable in its decision-making. However, the limited availability of ground truth lesion detection maps at a pixel level restricts the ability of deep segmentation neural networks to generalize over large databases. In this paper, we propose a novel approach for training a convolutional multi-task architecture with supervised learning and reinforcing it with weakly supervised learning. The architecture is simultaneously trained for three tasks: segmentation of red lesions and of bright lesions, those two tasks done concurrently with lesion detection. In addition, we propose and discuss the advantages of a new preprocessing method that guarantees the color consistency between the raw image and its enhanced version. Our complete system produces segmentations of both red and bright lesions. The method is validated at the pixel level and per-image using four databases and a cross-validation strategy. When evaluated on the task of screening for the presence or absence of lesions on the Messidor image set, the proposed method achieves an area under the ROC curve of 0.839, comparable with the state-of-the-art.","2019-10","2021-06-04 19:05:18","2021-06-04 19:05:18","","2434-2444","","10","38","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\M37BXMHJ\8672120.html","","","Task analysis; Diseases; Feature extraction; Image segmentation; Lesions; Training; Retina; Computer-aided diagnostic; fundus imaging; lesions segmentations; retina; screening","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V7VNNJSV","journalArticle","2020","Han, Zhongyi; Wei, Benzheng; Hong, Yanfei; Li, Tianyang; Cong, Jinyu; Zhu, Xue; Wei, Haifeng; Zhang, Wei","Accurate Screening of COVID-19 Using Attention-Based Deep 3D Multiple Instance Learning","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2996256","","Automated Screening of COVID-19 from chest CT is of emergency and importance during the outbreak of SARS-CoV-2 worldwide in 2020. However, accurate screening of COVID-19 is still a massive challenge due to the spatial complexity of 3D volumes, the labeling difficulty of infection areas, and the slight discrepancy between COVID-19 and other viral pneumonia in chest CT. While a few pioneering works have made significant progress, they are either demanding manual annotations of infection areas or lack of interpretability. In this paper, we report our attempt towards achieving highly accurate and interpretable screening of COVID-19 from chest CT with weak labels. We propose an attention-based deep 3D multiple instance learning (AD3D-MIL) where a patient-level label is assigned to a 3D chest CT that is viewed as a bag of instances. AD3D-MIL can semantically generate deep 3D instances following the possible infection area. AD3D-MIL further applies an attention-based pooling approach to 3D instances to provide insight into each instance's contribution to the bag label. AD3D-MIL finally learns Bernoulli distributions of the bag-level labels for more accessible learning. We collected 460 chest CT examples: 230 CT examples from 79 patients with COVID-19, 100 CT examples from 100 patients with common pneumonia, and 130 CT examples from 130 people without pneumonia. A series of empirical studies show that our algorithm achieves an overall accuracy of 97.9%, AUC of 99.0%, and Cohen kappa score of 95.7%. These advantages endow our algorithm as an efficient assisted tool in the screening of COVID-19.","2020-08","2021-06-04 19:05:18","2021-06-04 19:05:18","","2584-2594","","8","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\ZJVTYE6D\Han et al. - 2020 - Accurate Screening of COVID-19 Using Attention-Bas.pdf; C:\Users\Asus\Zotero\storage\SN62VYPB\9098062.html","","","Three-dimensional displays; Diseases; Medical diagnostic imaging; machine learning; Computed tomography; COVID-19; Lung; deep learning; multiple instance learning; screening; 3D; attention; computer-aided diagnosis; Manuals; SARS-CoV-2; Two dimensional displays","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X44ESBHC","journalArticle","2021","Jiang, Shancheng; Li, Huichuan; Jin, Zhi","A Visually Interpretable Deep Learning Framework for Histopathological Image-Based Skin Cancer Diagnosis","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2021.3052044","","Owing to the high incidence rate and the severe impact of skin cancer, the precise diagnosis of malignant skin tumors is a significant goal, especially considering treatment is normally effective if the tumor is detected early. Limited published histopathological image sets and the lack of an intuitive correspondence between the features of lesion areas and a certain type of skin cancer pose a challenge to the establishment of high-quality and interpretable computer-aided diagnostic (CAD) systems. To solve this problem, a light-weight attention mechanism-based deep learning framework, namely, DRANet, is proposed to differentiate 11 types of skin diseases based on a real histopathological image set collected by us during the last 10 years. The CAD system can output not only the name of a certain disease but also a visualized diagnostic report showing possible areas related to the disease. The experimental results demonstrate that the DRANet obtains significantly better performance than baseline models (i.e., InceptionV3, ResNet50, VGG16, and VGG19) with comparable parameter size and competitive accuracy with fewer model parameters. Visualized results produced by the hidden layers of the DRANet actually highlight part of the class-specific regions of diagnostic points and are valuable for decision making in the diagnosis of skin diseases.","2021-05","2021-06-04 19:05:18","2021-06-04 19:05:18","","1483-1494","","5","25","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\7UB7B3WQ\9325524.html","","","Solid modeling; Deep learning; Diseases; Attention mechanism; computer-aided diagnostic system; Lesions; model visualization; Skin; Skin cancer; skin histopathological image; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CQ53SL6Z","journalArticle","2020","Wang, Haolin; Huang, Zhilin; Zhang, Danfeng; Arief, Johan; Lyu, Tiewei; Tian, Jie","Integrating Co-Clustering and Interpretable Machine Learning for the Prediction of Intravenous Immunoglobulin Resistance in Kawasaki Disease","IEEE Access","","2169-3536","10.1109/ACCESS.2020.2996302","","Identifying intravenous immunoglobulin-resistant patients is essential for the prompt and optimal treatment of Kawasaki disease, suggesting the need for effective risk assessment tools. Data-driven approaches have the potential to identify the high-risk individuals by capturing the complex patterns of real-world data. To enable clinically applicable prediction of intravenous immunoglobulin resistance addressing the incompleteness of clinical data and the lack of interpretability of machine learning models, a multi-stage method is developed by integrating data missing pattern mining and intelligible models. First, co-clustering is adopted to characterize the block-wise data missing patterns by simultaneously grouping the clinical features and patients to enable (a) group-based feature selection and missing data imputation and (b) patient subgroup-specific predictive models considering the availability of data. Second, feature selection is performed using the group Lasso to uncover group-specific risk factors. Third, the Explainable Boosting Machine, which is an interpretable learning method based on generalized additive models, is applied for the prediction of each patient subgroup. The experiments using real-world Electronic Health Records demonstrate the superior performance of the proposed framework for predictive modeling compared with a set of benchmark methods. This study highlights the integration of co-clustering and supervised learning methods for incomplete clinical data mining, and promotes data-driven approaches to investigate predictors and effective algorithms for decision making in healthcare.","2020","2021-06-04 19:05:18","2021-06-04 19:05:18","","97064-97071","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\7TMCDB6V\Wang et al. - 2020 - Integrating Co-Clustering and Interpretable Machin.pdf; C:\Users\Asus\Zotero\storage\9BZPFDQ8\9097874.html","","","Data models; Diseases; Medical diagnostic imaging; Machine learning; Predictive models; Data mining; Co-clustering; Immune system; interpretable machine learning; Kawasaki disease; medical informatics; predictive models","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TCYTIRYC","journalArticle","2020","Lu, Jiayi; Jin, Renchao; Song, Enmin; Alrashoud, Mubarak; Al-Mutib, Khaled N.; Al-Rakhami, Mabrook S.","An Explainable System for Diagnosis and Prognosis of COVID-19","IEEE Internet of Things Journal","","2327-4662","10.1109/JIOT.2020.3037915","","The outbreak of COVID-19 has posed a threat to world health. With the increasing number of people infected, healthcare systems, especially those in developing countries, are bearing tremendous pressure. There is an urgent need for the diagnosis of COVID-19 and the prognosis of inpatients. To alleviate these problems, a data-driven medical assistance system is put forward in this paper. Based on two real-world datasets in Wuhan, China, the proposed system integrates data from different sources with tools of machine learning (ML) to predict COVID-19 infected probability of suspected patients in their first visit, and then predict mortality of confirmed cases. Rather than choosing an interpretable algorithm, this system separates the explanations from machine learning models. It can do help to patient triaging and provide some useful advice for doctors.","2020","2021-06-04 19:05:18","2021-06-04 19:05:18","","1-1","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Internet of Things Journal","","C:\Users\Asus\Zotero\storage\5DWZZE8T\Lu et al. - 2020 - An Explainable System for Diagnosis and Prognosis .pdf; C:\Users\Asus\Zotero\storage\D3VHU4CR\9259025.html","","","Medical diagnostic imaging; COVID-19; Predictive models; Diagnosis; Internet of Things; Machine Learning; Mathematical model; Monitoring; Prognosis.; Prognostics and health management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3T3Q9D23","journalArticle","2020","Biffi, Carlo; Cerrolaza, Juan J.; Tarroni, Giacomo; Bai, Wenjia; de Marvao, Antonio; Oktay, Ozan; Ledig, Christian; Le Folgoc, Loic; Kamnitsas, Konstantinos; Doumou, Georgia; Duan, Jinming; Prasad, Sanjay K.; Cook, Stuart A.; O’Regan, Declan P.; Rueckert, Daniel","Explainable Anatomical Shape Analysis Through Deep Hierarchical Generative Models","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2964499","","Quantification of anatomical shape changes currently relies on scalar global indexes which are largely insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven anatomical remodeling is a crucial step for the diagnosis and treatment of many conditions. Deep learning approaches have recently achieved wide success in the analysis of medical images, but they lack interpretability in the feature extraction and decision processes. In this work, we propose a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative networks to model a population of anatomical segmentations through a hierarchy of conditional latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously optimised to discriminate distinct clinical conditions, enabling the direct visualisation of the classification space. Moreover, the anatomical variability encoded by this discriminative latent space can be visualised in the segmentation space thanks to the generative properties of the model, making the classification task transparent. This approach yielded high accuracy in the categorisation of healthy and remodelled left ventricles when tested on unseen segmentations from our own multi-centre dataset as well as in an external validation set, and on hippocampi from healthy controls and patients with Alzheimer's disease when tested on ADNI data. More importantly, it enabled the visualisation in three-dimensions of both global and regional anatomical features which better discriminate between the conditions under exam. The proposed approach scales effectively to large populations, facilitating high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric imaging.","2020-06","2021-06-04 19:05:18","2021-06-04 19:05:18","","2088-2099","","6","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\4WDVY2WZ\8950467.html; C:\Users\Asus\Zotero\storage\8UE2K3I7\Biffi et al. - 2020 - Explainable Anatomical Shape Analysis Through Deep.pdf","","","Task analysis; Deep learning; Shape; Three-dimensional displays; Medical diagnostic imaging; Pathology; explainable deep learning; generative modeling; MRI; Shape analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2R2LLC6J","journalArticle","2019","Liu, Chi; Huang, Yue; Ozolek, John A.; Hanna, Matthew G.; Singh, Rajendra; Rohde, Gustavo K.","SetSVM: An Approach to Set Classification in Nuclei-Based Cancer Detection","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2018.2803793","","Due to the importance of nuclear structure in cancer diagnosis, several predictive models have been described for diagnosing a wide variety of cancers based on nuclear morphology. In many computer-aided diagnosis (CAD) systems, cancer detection tasks can be generally formulated as set classification problems, which can not be directly solved by classifying single instances. In this paper, we propose a novel set classification approach SetSVM to build a predictive model by considering any nuclei set as a whole without specific assumptions. SetSVM features highly discriminative power in cancer detection challenges in the sense that it not only optimizes the classifier decision boundary but also transfers discriminative information to set representation learning. During model training, these two processes are unified in the support vector machine (SVM) maximum separation margin problem. Experiment results show that SetSVM provides significant improvements compared with five commonly used approaches in cancer detection tasks utilizing 260 patients in total across three different cancer types, namely, thyroid cancer, liver cancer, and melanoma. In addition, we show that SetSVM enables visual interpretation of discriminative nuclear characteristics representing the nuclei set. These features make SetSVM a potentially practical tool in building accurate and interpretable CAD systems for cancer detection.","2019-01","2021-06-04 19:05:18","2021-06-07 17:44:32","","351-361","","1","23","","","SetSVM","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\LZJR73H5\8286915.html","","","Predictive models; Cancer; Training; Kernel; visualization; Support vector machines; Cancer detection; digital pathology; nuclear quantification; nuclear structure; Prototypes; set classification","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"U2LZMVE7","journalArticle","2021","Dong, Guanfang; Ma, Yingnan; Basu, Anup","Feature-Guided CNN for Denoising Images From Portable Ultrasound Devices","IEEE Access","","2169-3536","10.1109/ACCESS.2021.3059003","","As a non-invasive medical imaging scanning device, ultrasound has greatly increased the efficiency and accuracy of medical diagnosis. In recent years, portable ultrasound is being more widely used for its convenience and lower cost. Patients and physicians can receive the scanned images on their mobile phones at any time via a wireless network with low latency. However, it is difficult for portable ultrasound devices to capture images with the same quality as standard hospital ultrasound image acquisition systems. Usually, the images captured by portable ultrasound equipment have considerable noise. This noise undoubtedly affects the diagnosis of the physician. It is imperative to develop methods to remove the noise while preserving important information in the image. For this reason, we propose a novel denoising neural network model, called Feature-guided Denoising Convolutional Neural Network (FDCNN), to remove noise while retaining important feature information. In order to achieve high-quality denoising results, we employ a hierarchical denoising framework driven by a feature masking layer for medical images. Furthermore, we propose a feature extraction algorithm based on Explainable Artificial Intelligence (XAI) for medical images. Experimental results show that our medical image feature extraction method outperforms previous methods. Combined with the new denoising neural network architecture, portable ultrasound devices can now achieve better diagnostic performance.","2021","2021-06-04 19:05:18","2021-06-04 19:05:18","","28272-28281","","","9","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\9LFY32C8\Dong et al. - 2021 - Feature-Guided CNN for Denoising Images From Porta.pdf; C:\Users\Asus\Zotero\storage\GUMSKEH8\9353537.html","","","Medical diagnostic imaging; Feature extraction; Image edge detection; Ultrasonic imaging; Anisotropic magnetoresistance; Backpropagation; Biomedical image processing; feature extraction; image denoising; image fusion; Noise reduction","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8K8TELJ2","journalArticle","2020","He, Ji; Wang, Yongbo; Ma, Jianhua","Radon Inversion via Deep Learning","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2964266","","The Radon transform is widely used in physical and life sciences, and one of its major applications is in medical X-ray computed tomography (CT), which is significantly important in disease screening and diagnosis. In this paper, we propose a novel reconstruction framework for Radon inversion with deep learning (DL) techniques. For simplicity, the proposed framework is denoted as iRadonMAP, i.e., inverse Radon transform approximation. Specifically, we construct an interpretable neural network that contains three dedicated components. The first component is a fully connected filtering (FCF) layer along the rotation angle direction in the sinogram domain, and the second one is a sinusoidal back-projection (SBP) layer, which back-projects the filtered sinogram data into the spatial domain. Next, a common network structure is added to further improve the overall performance. iRadonMAP is first pretrained on a large number of generic images from the ImageNet database and then fine-tuned with clinical patient data. The experimental results demonstrate the feasibility of the proposed iRadonMAP framework for Radon inversion.","2020-06","2021-06-04 19:05:18","2021-06-07 17:46:29","","2076-2087","","6","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\GYATLHFQ\8950464.html; C:\Users\Asus\Zotero\storage\IUXA973J\He et al. - 2020 - Radon Inversion via Deep Learning.pdf","","","Medical diagnostic imaging; X-ray imaging; Computed tomography; deep learning; Transforms; computed tomography; image reconstruction; Image reconstruction; Radon; Radon inversion; Radon transform","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ID5MRU9G","journalArticle","2020","Ho, Yaoshiang; Wookey, Samuel","The Real-World-Weight Cross-Entropy Loss Function: Modeling the Costs of Mislabeling","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2962617","","In this paper, we propose a new metric to measure goodness-of-fit for classifiers: the Real World Cost function. This metric factors in information about a real world problem, such as financial impact, that other measures like accuracy or F1 do not. This metric is also more directly interpretable for users. To optimize for this metric, we introduce the Real-World-Weight Cross-Entropy loss function, in both binary classification and single-label multiclass classification variants. Both variants allow direct input of real world costs as weights. For single-label, multiclass classification, our loss function also allows direct penalization of probabilistic false positives, weighted by label, during the training of a machine learning model. We compare the design of our loss function to the binary cross-entropy and categorical cross-entropy functions, as well as their weighted variants, to discuss the potential for improvement in handling a variety of known shortcomings of machine learning, ranging from imbalanced classes to medical diagnostic error to reinforcement of social bias. We create scenarios that emulate those issues using the MNIST data set and demonstrate empirical results of our new loss function. Finally, we discuss our intuition about why this approach works and sketch a proof based on Maximum Likelihood Estimation.","2020","2021-06-04 19:05:18","2021-06-07 17:46:00","","4806-4813","","","8","","","The Real-World-Weight Cross-Entropy Loss Function","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\PUWBETFZ\Ho and Wookey - 2020 - The Real-World-Weight Cross-Entropy Loss Function.pdf; C:\Users\Asus\Zotero\storage\H5MYZGSU\8943952.html","","","Neural networks; Machine learning; Training; Standards; class imbalance; cross-entropy; ethnic stereotypes; maximum likelihood estimation; Maximum likelihood estimation; Measurement; oversampling; Probabilistic logic; social bias; softmax; undersampling","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZZ6LPUB","journalArticle","2020","Ming, Yao; Xu, Panpan; Cheng, Furui; Qu, Huamin; Ren, Liu","A A ProtoSteer: Steering Deep Sequence Model with Prototypes x","IEEE Transactions on Visualization and Computer Graphics","","1941-0506","10.1109/TVCG.2019.2934267","","Recently we have witnessed growing adoption of deep sequence models (e.g. LSTMs) in many application domains, including predictive health care, natural language processing, and log analysis. However, the intricate working mechanism of these models confines their accessibility to the domain experts. Their black-box nature also makes it a challenging task to incorporate domain-specific knowledge of the experts into the model. In ProtoSteer (Prototype Steering), we tackle the challenge of directly involving the domain experts to steer a deep sequence model without relying on model developers as intermediaries. Our approach originates in case-based reasoning, which imitates the common human problem-solving process of consulting past experiences to solve new problems. We utilize ProSeNet (Prototype Sequence Network), which learns a small set of exemplar cases (i.e., prototypes) from historical data. In ProtoSteer they serve both as an efficient visual summary of the original data and explanations of model decisions. With ProtoSteer the domain experts can inspect, critique, and revise the prototypes interactively. The system then incorporates user-specified prototypes and incrementally updates the model. We conduct extensive case studies and expert interviews in application domains including sentiment analysis on texts and predictive diagnostics based on vehicle fault logs. The results demonstrate that involvements of domain users can help obtain more interpretable models with concise prototypes while retaining similar accuracy.","2020-01","2021-06-04 19:05:18","2021-06-15 11:08:44","","238-248","","1","26","","","ProtoSteer","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Visualization and Computer Graphics","","C:\Users\Asus\Zotero\storage\MQW2XUU9\8827944.html","","","Computational modeling; Task analysis; Data models; Machine learning; Predictive models; Prototypes; Data visualization; Explainable Artificial Intelligence (XAI); Prototype Learning; Recurrent Neural Networks (RNNs); Sequence Data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A8TL95WI","journalArticle","2019","Xu, Haotian; Dong, Ming; Lee, Min-Hee; O’Hara, Nolan; Asano, Eishi; Jeong, Jeong-Won","Objective Detection of Eloquent Axonal Pathways to Minimize Postoperative Deficits in Pediatric Epilepsy Surgery Using Diffusion Tractography and Convolutional Neural Networks","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2019.2902073","","Convolutional neural networks (CNNs) have recently been used in biomedical imaging applications with great success. In this paper, we investigated the classification performance of CNN models on diffusion weighted imaging (DWI) streamlines defined by functional MRI (fMRI) and electrical stimulation mapping (ESM). To learn a set of discriminative and interpretable features from the extremely unbalanced dataset, we evaluated different CNN architectures with multiple loss functions (e.g., focal loss and center loss) and a soft attention mechanism and compared our models with current state-of-the-art methods. Through extensive experiments on streamlines collected from 70 healthy children and 70 children with focal epilepsy, we demonstrated that our deep CNN model with focal and central losses and soft attention outperforms all existing models in the literature and provides clinically acceptable accuracy (73%-100%) for the objective detection of functionally important white matter pathways, including ESM determined eloquent areas such as primary motors, aphasia, speech arrest, auditory, and visual functions. The findings of this paper encourage further investigations to determine if DWI-CNN analysis can serve as a noninvasive diagnostic tool during pediatric presurgical planning by estimating not only the location of essential cortices at the gyral level but also the underlying fibers connecting these cortical areas to minimize or predict postsurgical functional deficits. This paper translates an advanced CNN model to clinical practice in the pediatric population where currently available approaches (e.g., ESM and fMRI) are suboptimal. The implementation will be released at https://github.com/HaotianMXu/Brain-fiber-classification-using-CNNs.","2019-08","2021-06-04 19:05:18","2021-06-07 17:44:11","","1910-1922","","8","38","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\WRU5AXL4\8653838.html","","","Visualization; Convolutional neural network; DWI streamline; eloquent function; Epilepsy; epilepsy surgery; Functional magnetic resonance imaging; Pediatrics; Surgery; White matter","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FN3HEGGW","journalArticle","","","Text-Guided Neural Network Training for Image Recognition in Natural Scenes and Medicine","","","","","","","","2021-06-16 02:50:22","2021-06-16 02:50:36","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""