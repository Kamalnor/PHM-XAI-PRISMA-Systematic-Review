"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"RKEZ354C","journalArticle","2021","Hu, Wenxing; Meng, Xianghe; Bai, Yuntong; Zhang, Aiying; Qu, Gang; Cai, Biao; Zhang, Gemeng; Wilson, Tony W.; Stephen, Julia M.; Calhoun, Vince D.; Wang, Yu-Ping","Interpretable Multimodal Fusion Networks Reveal Mechanisms of Brain Cognition","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2021.3057635","","The combination of multimodal imaging and genomics provides a more comprehensive way for the study of mental illnesses and brain functions. Deep network-based data fusion models have been developed to capture their complex associations, resulting in improved diagnosis of diseases. However, deep learning models are often difficult to interpret, bringing about challenges for uncovering biological mechanisms using these models. In this work, we develop an interpretable multimodal fusion model to perform automated diagnosis and result interpretation simultaneously. We name it Grad-CAM guided convolutional collaborative learning (gCAM-CCL), which is achieved by combining intermediate feature maps with gradient-based weights. The gCAM-CCL model can generate interpretable activation maps to quantify pixel-level contributions of the input features. Moreover, the estimated activation maps are class-specific, which can therefore facilitate the identification of biomarkers underlying different groups. We validate the gCAM-CCL model on a brain imaging-genetic study, and demonstrate its applications to both the classification of cognitive function groups and the discovery of underlying biological mechanisms. Specifically, our analysis results suggest that during task-fMRI scans, several object recognition related regions of interests (ROIs) are activated followed by several downstream encoding ROIs. In addition, the high cognitive group may have stronger neurotransmission signaling while the low cognitive group may have problems in brain/neuron development due to genetic variations.","2021-05","2021-06-04 18:20:08","2021-06-04 18:20:16","","1474-1483","","5","40","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\32RDZ3J2\9349455.html; C:\Users\Asus\Zotero\storage\8WW24FE8\Hu et al. - 2021 - Interpretable Multimodal Fusion Networks Reveal Me.pdf","","","Biological system modeling; Computational modeling; Data models; Diseases; Brain modeling; Feature extraction; brain functional connectivity; CAM; Correlation; Interpretable; multimodal fusion","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3LLA8LPJ","journalArticle","2021","Li, Tianfu; Zhao, Zhibin; Sun, Chuang; Cheng, Li; Chen, Xuefeng; Yan, Ruqiang; Gao, Robert X.","A A A WaveletKernelNet: An Interpretable Deep Neural Network for Industrial Intelligent Diagnosis","IEEE Transactions on Systems, Man, and Cybernetics: Systems","","2168-2232","10.1109/TSMC.2020.3048950","","Convolutional neural network (CNN), with the ability of feature learning and nonlinear mapping, has demonstrated its effectiveness in prognostics and health management (PHM). However, an explanation on the physical meaning of a CNN architecture has rarely been studied. In this article, a novel wavelet-driven deep neural network, termed as WaveletKernelNet (WKN), is presented, where a continuous wavelet convolutional (CWConv) layer is designed to replace the first convolutional layer of the standard CNN. This enables the first CWConv layer to discover more meaningful kernels. Furthermore, only the scale parameter and translation parameter are directly learned from raw data at this CWConv layer. This provides a very effective way to obtain a customized kernel bank, specifically tuned for extracting defect-related impact component embedded in the vibration signal. In addition, three experimental studies using data from laboratory environment are carried out to verify the effectiveness of the proposed method for mechanical fault diagnosis. The experimental results show that the accuracy of the WKNs is higher than CNN by more than 10%, which indicate the importance of the designed CWConv layer. Besides, through theoretical analysis and feature map visualization, it is found that the WKNs are interpretable, have fewer parameters, and have the ability to converge faster within the same training epochs.","2021","2021-06-04 18:20:08","2021-06-15 10:56:28","","1-11","","","","","","WaveletKernelNet","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Systems, Man, and Cybernetics: Systems","","C:\Users\Asus\Zotero\storage\TWA3EVF3\9328876.html; C:\Users\Asus\Zotero\storage\B54EDJRB\Li et al. - 2021 - WaveletKernelNet An Interpretable Deep Neural Net.pdf","","","Neural networks; Feature extraction; Prognostics and health management; Fault diagnosis; Kernel; Continuous wavelet convolutional (CWConv) layer; continuous wavelet transform (CWT); Continuous wavelet transforms; Convolution; convolutional neural network (CNN); machine fault diagnosis; prognostic and health management (PHM)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BKK96KBH","journalArticle","2021","Jiang, Shancheng; Li, Huichuan; Jin, Zhi","A Visually Interpretable Deep Learning Framework for Histopathological Image-Based Skin Cancer Diagnosis","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2021.3052044","","Owing to the high incidence rate and the severe impact of skin cancer, the precise diagnosis of malignant skin tumors is a significant goal, especially considering treatment is normally effective if the tumor is detected early. Limited published histopathological image sets and the lack of an intuitive correspondence between the features of lesion areas and a certain type of skin cancer pose a challenge to the establishment of high-quality and interpretable computer-aided diagnostic (CAD) systems. To solve this problem, a light-weight attention mechanism-based deep learning framework, namely, DRANet, is proposed to differentiate 11 types of skin diseases based on a real histopathological image set collected by us during the last 10 years. The CAD system can output not only the name of a certain disease but also a visualized diagnostic report showing possible areas related to the disease. The experimental results demonstrate that the DRANet obtains significantly better performance than baseline models (i.e., InceptionV3, ResNet50, VGG16, and VGG19) with comparable parameter size and competitive accuracy with fewer model parameters. Visualized results produced by the hidden layers of the DRANet actually highlight part of the class-specific regions of diagnostic points and are valuable for decision making in the diagnosis of skin diseases.","2021-05","2021-06-04 18:20:08","2021-06-04 18:20:16","","1483-1494","","5","25","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\KGUXTJNJ\9325524.html","","","Solid modeling; Deep learning; Diseases; Attention mechanism; computer-aided diagnostic system; Lesions; model visualization; Skin; Skin cancer; skin histopathological image; Visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8YYLNHBN","journalArticle","2021","Zhang, Dan; Chen, Yongyi; Guo, Fanghong; Karimi, Hamid Reza; Dong, Hui; Xuan, Qi","A A A New Interpretable Learning Method for Fault Diagnosis of Rolling Bearings","IEEE Transactions on Instrumentation and Measurement","","1557-9662","10.1109/TIM.2020.3043873","","In modern manufacturing processes, requirements for automatic fault diagnosis have been growing increasingly as it plays a vitally important role in the reliability and safety of industrial facilities. Rolling bearing systems represent a critical part in most of the industrial applications. In view of the strong environmental noise in the working environment of rolling bearing, its vibration signals have nonstationary and nonlinear characteristics, and those features are difficult to be extracted. In this article, we proposed a new intelligent fault diagnosis method for rolling bearing with unlabeled data by using the convolutional neural network (CNN) and fuzzy $C$ -means (FCM) clustering algorithm. CNN is first utilized to automatically extract features from rolling bearing vibration signals. Then, the principal component analysis (PCA) technique is used to reduce the dimension of the extracted features, and the first two principal components are selected as the fault feature vectors. Finally, the FCM algorithm is introduced to cluster those rolling bearing data in the derived feature space and identify the different fault types of rolling bearing. The results indicate that the newly proposed fault diagnosis method can achieve higher accuracy than other existing results in the literature.","2021","2021-06-04 18:20:08","2021-06-15 10:50:27","","1-10","","","70","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Instrumentation and Measurement","","C:\Users\Asus\Zotero\storage\VAEHNFAW\9290108.html","","","Neural networks; Deep learning; Feature extraction; Fault diagnosis; Vibrations; Data mining; Convolutional neural network (CNN); fault diagnosis; fuzzy C-means (FCM); principal component analysis (PCA); rolling bearing; Rolling bearings","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ACFXPLUQ","journalArticle","2021","Liu, Chao; Qin, Chengjin; Shi, Xi; Wang, Zengwei; Zhang, Gang; Han, Yunting","A A A TScatNet: An Interpretable Cross-Domain Intelligent Diagnosis Model With Antinoise and Few-Shot Learning Capability","IEEE Transactions on Instrumentation and Measurement","","1557-9662","10.1109/TIM.2020.3041905","","In a real industrial scenario, domain shift frequently occurred due to working loads variation, operation speeds variation, and environmental noise interference, severely degrading intelligent fault diagnosis models' performance. Currently, domain adaptation-based models eliminate domain shift by calibrating unlabeled target-domain data using labeled source-domain data. Nevertheless, these models may fail when encountering unseen working conditions, lacking unlabeled target-domain data for learning domain-invariant features. Besides, the existing deep domain adaptation-based models lack a few-shot learning capability and interpretability. This article develops a cross-domain diagnosis model named time-scattering convolutional network (TScatNet) to remedy these gaps. TScatNet extracts domain-invariant features using Morlet wavelet as the predefined convolutional kernel, modulus as nonlinearity, and scaling averaging as pooling layer. This predefined architecture eliminates domain shift without any domain adaptation, endows TScatNet few-shot learning capability, simplifies the hyperparameter tuning process, and brings interpretability. Both the CWRU and DDS data sets are used to verify the proposed model, which shows that TScatNet could stably realize 100% accuracy on transfer tasks across working loads and 100% accuracy across operation speeds. Moreover, even though the SNR value descends to -4, TScatNet achieved 96% accuracy on ten categories tasks and 99.8% accuracy on four categories tasks. Besides, TScatNet achieved nearly 100% accuracy both under training samples' sparsity and sparsity of working conditions.","2021","2021-06-04 18:20:08","2021-06-15 10:59:36","","1-10","","","70","","","TScatNet","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Instrumentation and Measurement","","C:\Users\Asus\Zotero\storage\V93UUXRW\9279302.html","","","Task analysis; Data models; Feature extraction; Adaptation models; Antinoise; cross-domain diagnosis; domain shift; few-shot learning; interpretability; Scattering; Transforms; Wavelet transforms; working condition variation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMUVX2RG","journalArticle","2021","Gu, Ran; Wang, Guotai; Song, Tao; Huang, Rui; Aertsen, Michael; Deprest, Jan; Ourselin, Sébastien; Vercauteren, Tom; Zhang, Shaoting","CA-Net: Comprehensive Attention Convolutional Neural Networks for Explainable Medical Image Segmentation","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.3035253","","Accurate medical image segmentation is essential for diagnosis and treatment planning of diseases. Convolutional Neural Networks (CNNs) have achieved state-of-the-art performance for automatic medical image segmentation. However, they are still challenged by complicated conditions where the segmentation target has large variations of position, shape and scale, and existing CNNs have a poor explainability that limits their application to clinical decisions. In this work, we make extensive use of multiple attentions in a CNN architecture and propose a comprehensive attention-based CNN (CA-Net) for more accurate and explainable medical image segmentation that is aware of the most important spatial positions, channels and scales at the same time. In particular, we first propose a joint spatial attention module to make the network focus more on the foreground region. Then, a novel channel attention module is proposed to adaptively recalibrate channel-wise feature responses and highlight the most relevant feature channels. Also, we propose a scale attention module implicitly emphasizing the most salient feature maps among multiple scales so that the CNN is adaptive to the size of an object. Extensive experiments on skin lesion segmentation from ISIC 2018 and multi-class segmentation of fetal MRI found that our proposed CA-Net significantly improved the average segmentation Dice score from 87.77% to 92.08% for skin lesion, 84.79% to 87.08% for the placenta and 93.20% to 95.88% for the fetal brain respectively compared with U-Net. It reduced the model size to around 15 times smaller with close or even better accuracy compared with state-of-the-art DeepLabv3+. In addition, it has a much higher explainability than existing networks by visualizing the attention weight maps. Our code is available at https://github.com/HiLab-git/CA-Net.","2021-02","2021-06-04 18:20:08","2021-06-07 17:24:20","","699-711","","2","40","","","CA-Net","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\SBPV8KSW\9246575.html; C:\Users\Asus\Zotero\storage\97NN3WMJ\Gu et al. - 2021 - CA-Net Comprehensive Attention Convolutional Neur.pdf","","","Task analysis; Shape; Medical diagnostic imaging; Feature extraction; explainability; Image segmentation; Attention; convolutional neural network; Convolutional neural networks; medical image segmentation","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGW7UFTT","journalArticle","2021","Kim, Min Su; Yun, Jong Pil; Park, PooGyeon","A A An Explainable Convolutional Neural Network for Fault Diagnosis in Linear Motion Guide","IEEE Transactions on Industrial Informatics","","1941-0050","10.1109/TII.2020.3012989","","A linear motion (LM) guide is a mechanical tool for requiring linear motion in a system. Repeating linear movements can cause cracking and deterioration of the LM guide, which can lead to a decrease in productivity. Therefore, predicting the status of the LM guide and diagnosing faults are essential for systems including the LM guide. In this article, we propose a novel framework of fault diagnosis model based on deep learning using a vibration sensor signal mounted on the LM guide. This framework contains the learning vibration signal in the time domain using the proposed 1-D convolutional neural network model and the visualization of the classification criteria in the frequency domain using the learned model in the time domain. To utilize the visualization in the frequency domain, the proposed model is designed to maintain the frequency information in the learning process. With the learned model, we propose a frequency domain-based grad-CAM to visualize the classification criteria in the frequency domain to help to explain the characteristics of normal and fault data. Using LM guide data under various conditions, we visualize the classification criteria of the learned model in the frequency domain.","2021-06","2021-06-04 18:20:08","2021-06-15 10:51:27","","4036-4045","","6","17","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Industrial Informatics","","C:\Users\Asus\Zotero\storage\Q3HVFCJM\9153108.html","","","Artificial intelligence; Feature extraction; Machine learning; Mathematical model; Fault diagnosis; visualization; Convolution; fault diagnosis; convolutional neural networks (CNNs); Frequency-domain analysis; linear motion (LM) guide; Time-domain analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EP9YLXFY","journalArticle","2020","Thakoor, Kaveri A.; Koorathota, Sharath C.; Hood, Donald C.; Sajda, Paul","Robust and Interpretable Convolutional Neural Networks to Detect Glaucoma in Optical Coherence Tomography Images","IEEE Transactions on Biomedical Engineering","","1558-2531","10.1109/TBME.2020.3043215","","Recent studies suggest that deep learning systems can now achieve performance on par with medical experts in diagnosis of disease. A prime example is in the field of ophthalmology, where convolutional neural networks (CNNs) have been used to detect retinal and ocular diseases. However, this type of artificial intelligence (AI) has yet to be adopted clinically due to questions regarding robustness of the algorithms to datasets collected at new clinical sites and a lack of explainability of AI-based predictions, especially relative to those of human expert counterparts. In this work, we develop CNN architectures that demonstrate robust detection of glaucoma in optical coherence tomography (OCT) images and test with concept activation vectors (TCAVs) to infer what image concepts CNNs use to generate predictions. Furthermore, we compare TCAV results to eye fixations of clinicians, to identify common decision-making features used by both AI and human experts. We find that employing fine-tuned transfer learning and CNN ensemble learning create end-to-end deep learning models with superior robustness compared to previously reported hybrid deep-learning/machine-learning models, and TCAV/eye-fixation comparison suggests the importance of three OCT report sub-images that are consistent with areas of interest fixated upon by OCT experts to detect glaucoma. The pipeline described here for evaluating CNN robustness and validating interpretable image concepts used by CNNs with eye movements of experts has the potential to help standardize the acceptance of new AI tools for use in the clinic.","2020","2021-06-04 18:20:08","2021-06-07 17:23:48","","1-1","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Biomedical Engineering","","C:\Users\Asus\Zotero\storage\DU7AR887\9286420.html","","","Deep learning; Data models; Feature extraction; Training; Retina; Computer-aided decision support; Eye tracking; Medical expert systems; Optical Coherence Tomography; Robustness; Testing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E7TY3624","journalArticle","2020","Ibrahim, Lujain; Mesinovic, Munib; Yang, Kai-Wen; Eid, Mohamad A.","Explainable Prediction of Acute Myocardial Infarction Using Machine Learning and Shapley Values","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3040166","","The early and accurate detection of the onset of acute myocardial infarction (AMI) is imperative for the timely provision of medical intervention and the reduction of its mortality rate. Machine learning techniques have demonstrated great potential in aiding disease diagnosis. In this paper, we present a framework to predict the onset of AMI using 713,447 extracted ECG samples and associated auxiliary data from the longitudinal and comprehensive ECG-ViEW II database, previously unexplored in the field of machine learning in healthcare. The framework is realized with two deep learning models, a convolutional neural network (CNN) and a recurrent neural network (RNN), and a decision-tree based model, XGBoost. Synthetic minority oversampling technique (SMOTE) was utilized to address class imbalance. High prediction accuracy of 89.9%, 84.6%, 97.5% and ROC curve areas of 90.7%, 82.9%, 96.5% have been achieved for the best CNN, RNN, and XGBoost models, respectively. Shapley values were utilized to identify the features that contributed most to the classification decision with XGBoost, demonstrating the high impact of auxiliary inputs such as age and sex. This paper demonstrates the promising application of explainable machine learning in the field of cardiovascular disease prediction.","2020","2021-06-04 18:20:08","2021-06-04 18:20:18","","210410-210417","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\YWBNG545\Ibrahim et al. - 2020 - Explainable Prediction of Acute Myocardial Infarct.pdf; C:\Users\Asus\Zotero\storage\IDK6SRB2\9268965.html","","","Feature extraction; Machine learning; Predictive models; Training; Databases; predictive models; acute myocardial infarction; biomedical informatics; Electrocardiography; Myocardium","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VNYAV5RV","journalArticle","2020","Lu, Jiayi; Jin, Renchao; Song, Enmin; Alrashoud, Mubarak; Al-Mutib, Khaled N.; Al-Rakhami, Mabrook S.","An Explainable System for Diagnosis and Prognosis of COVID-19","IEEE Internet of Things Journal","","2327-4662","10.1109/JIOT.2020.3037915","","The outbreak of COVID-19 has posed a threat to world health. With the increasing number of people infected, healthcare systems, especially those in developing countries, are bearing tremendous pressure. There is an urgent need for the diagnosis of COVID-19 and the prognosis of inpatients. To alleviate these problems, a data-driven medical assistance system is put forward in this paper. Based on two real-world datasets in Wuhan, China, the proposed system integrates data from different sources with tools of machine learning (ML) to predict COVID-19 infected probability of suspected patients in their first visit, and then predict mortality of confirmed cases. Rather than choosing an interpretable algorithm, this system separates the explanations from machine learning models. It can do help to patient triaging and provide some useful advice for doctors.","2020","2021-06-04 18:20:08","2021-06-04 18:20:18","","1-1","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Internet of Things Journal","","C:\Users\Asus\Zotero\storage\AGZ764MK\Lu et al. - 2020 - An Explainable System for Diagnosis and Prognosis .pdf; C:\Users\Asus\Zotero\storage\8PIU8ZB3\9259025.html","","","Medical diagnostic imaging; COVID-19; Predictive models; Diagnosis; Internet of Things; Machine Learning; Mathematical model; Monitoring; Prognosis.; Prognostics and health management","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IHIDGKHE","journalArticle","2020","Ebrahimian, Arash; Mohammadi, Hossein; Babaie, Morteza; Maftoon, Nima; Tizhoosh, H. R.","Class-Aware Image Search for Interpretable Cancer Identification","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3033492","","In recent times, the performance of computer-aided diagnosis systems in classification of malignancies has significantly improved. Search and retrieval methods are specifically important as they assist physicians in making the right diagnosis in medical imaging owing to their ability of obtaining similar cases for a query image. Supervised classification algorithms are generally more accurate than unsupervised search-based classifications; however, the latter may more easily provide insights into the decision-making process by providing a group of similar cases and their corresponding metadata (i.e., diagnostic reports) and not simply a class probability. In this study, we propose a class-aware search operating on deep image embeddings to increase the accuracy of content-based search. We validate our methodology using two different publicly available datasets, one containing endometrial cancer images and the other containing colorectal cancer images. The proposed class-aware scenarios can enhance the accuracy of the search-based classifier, thereby making them more feasible in practice. With search results providing access to the metadata of retrieved cases (i.e., pathology reports of evidently diagnosed cases), such a combination has clear benefits for assisting experts with explainable results.","2020","2021-06-04 18:20:08","2021-06-04 18:20:18","","197352-197362","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\GRTVNUPN\Ebrahimian et al. - 2020 - Class-Aware Image Search for Interpretable Cancer .pdf; C:\Users\Asus\Zotero\storage\GVG567I9\9238034.html","","","Medical diagnostic imaging; Feature extraction; Cancer; deep learning; medical image classification; Medical image search; Metadata; Pathology; pathology whole-slide images; Training","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H2CKYFSW","journalArticle","2020","Tan, Qingxiong; Ye, Mang; Ma, Andy Jinhua; Yang, Baoyao; Yip, Terry Cheuk-Fung; Wong, Grace Lai-Hung; Yuen, Pong C.","Explainable Uncertainty-Aware Convolutional Recurrent Neural Network for Irregular Medical Time Series","IEEE Transactions on Neural Networks and Learning Systems","","2162-2388","10.1109/TNNLS.2020.3025813","","Influenced by the dynamic changes in the severity of illness, patients usually take examinations in hospitals irregularly, producing a large volume of irregular medical time-series data. Performing diagnosis prediction from the irregular medical time series is challenging because the intervals between consecutive records significantly vary along time. Existing methods often handle this problem by generating regular time series from the irregular medical records without considering the uncertainty in the generated data, induced by the varying intervals. Thus, a novel Uncertainty-Aware Convolutional Recurrent Neural Network (UA-CRNN) is proposed in this article, which introduces the uncertainty information in the generated data to boost the risk prediction. To tackle the complex medical time series with subseries of different frequencies, the uncertainty information is further incorporated into the subseries level rather than the whole sequence to seamlessly adjust different time intervals. Specifically, a hierarchical uncertainty-aware decomposition layer (UADL) is designed to adaptively decompose time series into different subseries and assign them proper weights in accordance with their reliabilities. Meanwhile, an Explainable UA-CRNN (eUA-CRNN) is proposed to exploit filters with different passbands to ensure the unity of components in each subseries and the diversity of components in different subseries. Furthermore, eUA-CRNN incorporates with an uncertainty-aware attention module to learn attention weights from the uncertainty information, providing the explainable prediction results. The extensive experimental results on three real-world medical data sets illustrate the superiority of the proposed method compared with the state-of-the-art methods.","2020","2021-06-04 18:20:08","2021-06-06 13:36:59","","1-15","","","","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Neural Networks and Learning Systems","","C:\Users\Asus\Zotero\storage\PBKB9U7B\9224838.html","","","Task analysis; Medical diagnostic imaging; Machine learning; Attention module; convolutional recurrent neural network; explainable risk prediction results; Reliability; Time series analysis; time-series decomposition; Uncertainty; uncertainty-aware prediction.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HESU7I9Z","journalArticle","2020","Sun, Kyung Ho; Huh, Hyunsuk; Tama, Bayu Adhi; Lee, Soo Young; Jung, Joon Ha; Lee, Seungchul","A A A Vision-Based Fault Diagnostics Using Explainable Deep Learning With Class Activation Maps","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3009852","","In the era of the fourth industrial revolution (Industry 4.0) and the Internet of Things (IoT), real-time data is enormously collected and analyzed from mechanical equipment. By classifying and characterizing the measured signals, the fault condition of mechanical components could be identified. However, most current health monitoring techniques utilize time-consuming and labor-intensive feature engineering, i.e., feature extraction and selection, that are carried out by experts. This paper, on the contrary, deals with an automatic diagnosis method of machine monitoring using a convolutional neural network (CNN) with class activation maps (CAM). A class activation map enables us to discriminate the fault region in the images, thus allowing us to localize the fault precisely. The goal of the paper is to demonstrate how CNN and CAM could be employed to real-world vibration video to characterize the machine's status, representing normal or fault conditions. The performance of the proposed model is validated with a base-excited cantilever beam dataset and a water pump dataset. This paper presents a novel industrial application by developing a promising method for automatic machine condition-based monitoring.","2020","2021-06-04 18:20:08","2021-06-15 10:56:19","","129169-129179","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\NPPJ3H6E\Sun et al. - 2020 - Vision-Based Fault Diagnostics Using Explainable D.pdf; C:\Users\Asus\Zotero\storage\H96WQZ7E\9142228.html","","","Feature extraction; Machine learning; Artificial neural networks; class activation maps; Convolutional neural network; discriminative region; explainable AI; fault detection; Fault diagnosis; mechanical component; Mechanical sensors; Vibrations","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NEQTN3F","journalArticle","2020","Chen, Han-Yun; Lee, Ching-Hung","A A A Vibration Signals Analysis by Explainable Artificial Intelligence (XAI) Approach: Application on Bearing Faults Diagnosis","IEEE Access","","2169-3536","10.1109/ACCESS.2020.3006491","","This study introduces an explainable artificial intelligence (XAI) approach of convolutional neural networks (CNNs) for classification in vibration signals analysis. First, vibration signals are transformed into images by short-time Fourier transform (STFT). A CNN is applied as classification model, and Gradient class activation mapping (Grad-CAM) is utilized to generate the attention of model. By analyzing the attentions, the explanation of classification models for vibration signals analysis can be carried out. Finally, the verifications of attention are introduced by neural networks, adaptive network-based fuzzy inference system (ANFIS), and decision trees to demonstrate the proposed results. By the proposed methodology, the explanation of model using highlighted attentions is carried out.","2020","2021-06-04 18:20:08","2021-06-15 10:56:03","","134246-134256","","","8","","","Vibration Signals Analysis by Explainable Artificial Intelligence (XAI) Approach","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\56KSAMSW\Chen and Lee - 2020 - Vibration Signals Analysis by Explainable Artifici.pdf; C:\Users\Asus\Zotero\storage\JRK7BF55\9131692.html","","","Feature extraction; Machine learning; Convolutional neural network; explainable AI; Fault diagnosis; Vibrations; fault diagnosis; Frequency-domain analysis; Contracts; Signal analysis; vibration signal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYFQMYGZ","journalArticle","2020","Zhang, Shijie; Du, Huarui; Jin, Zhuang; Zhu, Yaqiong; Zhang, Ying; Xie, Fang; Zhang, Mingbo; Tian, Xiaoqi; Zhang, Jue; Luo, Yukun","A Novel Interpretable Computer-Aided Diagnosis System of Thyroid Nodules on Ultrasound Based on Clinical Experience","IEEE Access","","2169-3536","10.1109/ACCESS.2020.2976495","","Computer-aided diagnosis systems (CADs) present valuable second opinions to radiologists in diagnosis. Many studies on thyroid nodules have proposed various CADs to provide a binary result, benignity or malignancy, for doctors, ignoring interpretability of more ultrasonic features that could be more useful. We develop an interpretable CADs (iCADS) that utilizes deep-learning networks' classification power and interpretability potential of clinical guidelines, like TIRADS, a well-established scale for thyroid nodules. iCADS incorporates a main neural-networks model and six neural-network based interpreters. The outputs of the six interpreters are compared with TIRADS guidelines and the matched result will form a report, more than a benignity or malignancy result, for radiologists. Clinical images of 16,946 thyroid nodules from 5,885 patients were used to train the proposed iCADS. An extra experimental data set containing 501 images were used to test the performance of the model. For better illustrating the assistant ability of iCADS, we also recruited ten junior radiologists to make diagnosis decisions with or without the help of different versions of iCADS. The experiments demonstrated that iCADS can largely improve junior radiologists diagnosis with the help of interpreter strategy. These experiments are also the very first attempt to evaluate the effect of interpretability of deep-learning based CADs in clinical practice. Comparison experiments with other deep-learning based CADs and traditional CADs indicated that the interpreter strategy can easily be combined to other intelligent CADs without the loss of performance. The framework of iCADS can also inspire more research on the development of CADs.","2020","2021-06-04 18:20:08","2021-06-04 18:20:19","","53223-53231","","","8","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\JI2KFA6J\Zhang et al. - 2020 - A Novel Interpretable Computer-Aided Diagnosis Sys.pdf; C:\Users\Asus\Zotero\storage\2FB3JMXG\9016204.html","","","Feature extraction; Lesions; Cancer; deep learning; Pathology; Guidelines; Interpretable computer-aided diagnosis system; multi-task learning; thyroid nodules; Ultrasonic imaging; ultrasound","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"898RQAFT","journalArticle","2020","Gu, Donghao; Li, Yaowei; Jiang, Feng; Wen, Zhaojing; Liu, Shaohui; Shi, Wuzhen; Lu, Guangming; Zhou, Changsheng","VINet: A Visually Interpretable Image Diagnosis Network","IEEE Transactions on Multimedia","","1941-0077","10.1109/TMM.2020.2971170","","Recently, due to the black box characteristics of deep learning techniques, the deep network-based computer-aided diagnosis (CADx) systems have encountered many difficulties in practical applications. The crux of the problem is that these models should be explainable the model should give doctors rationales that can explain the diagnosis. In this paper, we propose a visually interpretable network (VINet) which can generate diagnostic visual interpretations while making accurate diagnoses. VINet is an end-to-end model consisting of an importance estimation network and a classification network. The former produces a diagnostic visual interpretation for each case, and the classifier diagnoses the case. In the classifier, by exploring the information in the diagnostic visual interpretation, the irrelevant information in the feature maps is eliminated by our proposed feature destruction process. This allows the classification network to concentrate on the important features and use them as the primary references for classification. Through a joint optimization of higher classification accuracy and eliminating as many irrelevant features as possible, a precise, fine-grained diagnostic visual interpretation, along with an accurate diagnosis, can be produced by our proposed network simultaneously. Based on a computed tomography image dataset (LUNA16) on pulmonary nodule, extensive experiments have been conducted, demonstrating that the proposed VINet can produce state-of-the-art diagnostic visual interpretations compared with all baseline methods.","2020-07","2021-06-04 18:20:08","2021-06-04 18:20:19","","1720-1729","","7","22","","","VINet","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Multimedia","","C:\Users\Asus\Zotero\storage\48DDTRCG\8979157.html","","","Computational modeling; Solid modeling; Task analysis; Biomedical imaging; Medical services; Visualization; Machine learning; Estimation; image classification; medical diagnostic imaging; neural network","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BR2GYDKX","journalArticle","2020","Biffi, Carlo; Cerrolaza, Juan J.; Tarroni, Giacomo; Bai, Wenjia; de Marvao, Antonio; Oktay, Ozan; Ledig, Christian; Le Folgoc, Loic; Kamnitsas, Konstantinos; Doumou, Georgia; Duan, Jinming; Prasad, Sanjay K.; Cook, Stuart A.; O’Regan, Declan P.; Rueckert, Daniel","Explainable Anatomical Shape Analysis Through Deep Hierarchical Generative Models x","IEEE Transactions on Medical Imaging","","1558-254X","10.1109/TMI.2020.2964499","","Quantification of anatomical shape changes currently relies on scalar global indexes which are largely insensitive to regional or asymmetric modifications. Accurate assessment of pathology-driven anatomical remodeling is a crucial step for the diagnosis and treatment of many conditions. Deep learning approaches have recently achieved wide success in the analysis of medical images, but they lack interpretability in the feature extraction and decision processes. In this work, we propose a new interpretable deep learning model for shape analysis. In particular, we exploit deep generative networks to model a population of anatomical segmentations through a hierarchy of conditional latent variables. At the highest level of this hierarchy, a two-dimensional latent space is simultaneously optimised to discriminate distinct clinical conditions, enabling the direct visualisation of the classification space. Moreover, the anatomical variability encoded by this discriminative latent space can be visualised in the segmentation space thanks to the generative properties of the model, making the classification task transparent. This approach yielded high accuracy in the categorisation of healthy and remodelled left ventricles when tested on unseen segmentations from our own multi-centre dataset as well as in an external validation set, and on hippocampi from healthy controls and patients with Alzheimer's disease when tested on ADNI data. More importantly, it enabled the visualisation in three-dimensions of both global and regional anatomical features which better discriminate between the conditions under exam. The proposed approach scales effectively to large populations, facilitating high-throughput analysis of normal anatomy and pathology in large-scale studies of volumetric imaging.","2020-06","2021-06-04 18:20:08","2021-06-06 13:35:21","","2088-2099","","6","39","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Medical Imaging","","C:\Users\Asus\Zotero\storage\A3K4MBV5\8950467.html; C:\Users\Asus\Zotero\storage\D4R7SEMN\Biffi et al. - 2020 - Explainable Anatomical Shape Analysis Through Deep.pdf","","","Task analysis; Deep learning; Shape; Three-dimensional displays; Medical diagnostic imaging; Pathology; explainable deep learning; generative modeling; MRI; Shape analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WPKSY7F2","journalArticle","2020","Grezmak, John; Zhang, Jianjing; Wang, Peng; Loparo, Kenneth A.; Gao, Robert X.","A A A Interpretable Convolutional Neural Network Through Layer-wise Relevance Propagation for Machine Fault Diagnosis","IEEE Sensors Journal","","1558-1748","10.1109/JSEN.2019.2958787","","As a state-of-the-art pattern recognition technique, convolutional neural networks (CNNs) have been increasingly investigated for machine fault diagnosis, due to their ability in analyzing nonlinear and nonstationary high-dimensional data that are typically associated with the performance degradation process of machines. A key issue of interest is how the inputs to CNNs that contain fault-related patterns are learned by CNNs to recognize discriminatory information for fault diagnosis. Understanding this link will help establish connection to the physical meaning of the diagnosis, contributing to the broad acceptance of CNNs as a trustworthy complement to physics-based reasoning by human experts. Using Layer-wise Relevance Propagation (LRP) as an indicator, this paper investigates the performance of a CNN trained by time-frequency spectra images of vibration signals measured on an induction motor. The LRP provides pixel-level representation of which values in the input signal contribute the most to the diagnosis results, thereby providing an improved understanding of how the CNN learns to distinguish between fault types from these inputs. Results have shown that the patterns learned by CNNs in the time-frequency spectra images are intuitive and consistent with respect to network re-training. Comparison with using raw time series and discrete Fourier transform coefficients as inputs reveals that time-frequency images allow for more consistent pattern recognition by CNNs.","2020-03","2021-06-04 18:20:08","2021-06-15 10:54:23","","3172-3181","","6","20","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Sensors Journal","","C:\Users\Asus\Zotero\storage\KRBEV7XF\8930493.html","","","Feature extraction; layer-wise relevance propagation; convolutional neural network; Artificial neural networks; Fault diagnosis; Vibrations; Convolution; Induction motors; Motor fault diagnosis; Time-frequency analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5RHLDIP","journalArticle","2020","Liao, WangMin; Zou, BeiJi; Zhao, RongChang; Chen, YuanQiong; He, ZhiYou; Zhou, MengJie","Clinical Interpretable Deep Learning Model for Glaucoma Diagnosis","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2019.2949075","","Despite the potential to revolutionise disease diagnosis by performing data-driven classification, clinical interpretability of ConvNet remains challenging. In this paper, a novel clinical interpretable ConvNet architecture is proposed not only for accurate glaucoma diagnosis but also for the more transparent interpretation by highlighting the distinct regions recognised by the network. To the best of our knowledge, this is the first work of providing the interpretable diagnosis of glaucoma with the popular deep learning model. We propose a novel scheme for aggregating features from different scales to promote the performance of glaucoma diagnosis, which we refer to as M-LAP. Moreover, by modelling the correspondence from binary diagnosis information to the spatial pixels, the proposed scheme generates glaucoma activations, which bridge the gap between global semantical diagnosis and precise location. In contrast to previous works, it can discover the distinguish local regions in fundus images as evidence for clinical interpretable glaucoma diagnosis. Experimental results, performed on the challenging ORIGA datasets, show that our method on glaucoma diagnosis outperforms state-of-the-art methods with the highest AUC (0.88). Remarkably, the extensive results, optic disc segmentation (dice of 0.9) and local disease focus localization based on the evidence map, demonstrate the effectiveness of our methods on clinical interpretability.","2020-05","2021-06-04 18:20:08","2021-06-04 18:20:20","","1405-1412","","5","24","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\GK297VTK\8880490.html","","","Feature extraction; Lesions; Semantics; Convolution; Biomedical optical imaging; clinical interpreta-tion; Computer architecture; Glaucoma diagnosis; medical image processing; Optical imaging","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AETDHLR2","journalArticle","2020","Amor, Boulbaba Ben; Srivastava, Anuj; Turaga, Pavan; Coleman, Grisha","A Framework for Interpretable Full-Body Kinematic Description Using Geometric and Functional Analysis","IEEE Transactions on Biomedical Engineering","","1558-2531","10.1109/TBME.2019.2946682","","Rapid advances in cost-effective and non-invasive depth sensors, and the development of reliable and real-time 3D skeletal data estimation algorithms, have opened up a new application area in computer vision - statistical analysis of human kinematic data for fast, automated assessment of body movements. These assessments can play important roles in sports, medical diagnosis, physical therapy, elderly monitoring and related applications. This paper develops a comprehensive geometric framework for quantification and statistical evaluation of kinematic features. The key idea is to avoid analysis of individual joints, as is the current paradigm, and represent movements as temporal evolutions, or trajectories, on shape space of full body skeletons. This allows metrics with appropriate invariance properties to be imposed on these trajectories and leads to definitions of higher-level features, such as spatial symmetry(sS), temporal symmetry(tS), action's velocity(Vl) and body's balance(Bl), during performance of an action. These features exploit skeletal symmetries in space and time, and capture motion cadence to naturally quantify motions of individual subjects. The study of these features as functional data allows us to formulate certain hypothesis tests in feature space. This, in turn, leads to validation of existing assumptions and discoveries of new relationships between kinematics and demographic factors, such as age, gender, and athletic training. We use the clinically validated K3Da kinect dataset to illustrate these ideas, and hope these tools will lead to discovery of new relationships between full-body kinematic features and demographic, health, and wellness factors that are clinically relevant.","2020-06","2021-06-04 18:20:08","2021-06-07 16:43:56","","1761-1774","","6","67","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Biomedical Engineering","","C:\Users\Asus\Zotero\storage\KVVMVUHB\8864039.html","","","Shape; Monitoring; Training; Kendall’s shape space; Kinematics; physical performance assessment; Senior citizens; Sensors; Skeletal shape; symmetry; Tools; trajectory","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCGMT3H4","journalArticle","2020","Yeo, Jinyoung; Park, Haeju; Lee, Sanghoon; Lee, Eric Wonhee; Hwang, Seung-won","XINA: Explainable Instance Alignment Using Dominance Relationship x","IEEE Transactions on Knowledge and Data Engineering","","1558-2191","10.1109/TKDE.2018.2881956","","Over the past few years, knowledge bases (KBs) like DBPedia, Freebase, and YAGO have accumulated a massive amount of knowledge from web data. Despite their seemingly large size, however, individual KBs often lack comprehensive information on any given domain. For example, over 70 percent of people on Freebase lack information on place of birth. For this reason, the complementary nature across different KBs motivates their integration through a process of aligning instances. Meanwhile, since application-level machine systems, such as medical diagnosis, have heavily relied on KBs, it is necessary to provide users with trustworthy reasons why the alignment decisions are made. To address this problem, we propose a new paradigm, explainable instance alignment (XINA), which provides user-understandable explanations for alignment decisions. Specifically, given an alignment candidate, XINA replaces existing scalar representation of an aggregated score, by decision and explanation-vector spaces for machine decision and user understanding, respectively. To validate XINA, we perform extensive experiments on real-world KBs and show that XINA achieves comparable performance with state-of-the-arts, even with far less human effort.","2020-02","2021-06-04 18:20:08","2021-06-06 13:41:33","","388-401","","2","32","","","XINA","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Knowledge and Data Engineering","","C:\Users\Asus\Zotero\storage\JQWXJRUB\8540085.html","","","Feature extraction; Data mining; Decision making; interpretability; entity resolution; Inference mechanisms; Information retrieval; instance alignment; KB integration; Knowledge base; Knowledge based systems; ontology matching","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SUI6RQEC","journalArticle","2019","Vásquez-Morales, Gabriel R.; Martínez-Monterrubio, Sergio M.; Moreno-Ger, Pablo; Recio-García, Juan A.","Explainable Prediction of Chronic Renal Disease in the Colombian Population Using Neural Networks and Case-Based Reasoning","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2948430","","This paper presents a neural network-based classifier to predict whether a person is at risk of developing chronic kidney disease (CKD). The model is trained with the demographic data and medical care information of two population groups: on the one hand, people diagnosed with CKD in Colombia during 2018, and on the other, a sample of people without a diagnosis of this disease. Once the model is trained and evaluation metrics for classification algorithms are applied, the model achieves 95% accuracy in the test data set, making its application for disease prognosis feasible. However, despite the demonstrated efficiency of the neural networks to predict CKD, this machine-learning paradigm is opaque to the expert regarding the explanation of the outcome. Current research on eXplainable AI proposes the use of twin systems, where a black-box machine-learning method is complemented by another white-box method that provides explanations about the predicted values. Case-Based Reasoning (CBR) has proved to be an ideal complement as this paradigm is able to find explanatory cases for an explanation-by-example justification of a neural network's prediction. In this paper, we apply and validate a NN-CBR twin system for the explanation of CKD predictions. As a result of this research, 3,494,516 people were identified as being at risk of developing CKD in Colombia, or 7% of the total population.","2019","2021-06-04 18:20:08","2021-06-07 17:23:20","","152900-152910","","","7","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\A4VG2M7L\Vásquez-Morales et al. - 2019 - Explainable Prediction of Chronic Renal Disease in.pdf; C:\Users\Asus\Zotero\storage\FNDSY8QA\8877828.html","","","Artificial intelligence; Data models; Diseases; Training; explainable AI; Biological neural networks; case-based reasoning; Chronic kidney disease prediction; neural networks; random forest; Sociology; support vector machines; twin systems","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3TACZHDA","journalArticle","2020","Zhou, Xiuzhuang; Jin, Kai; Shang, Yuanyuan; Guo, Guodong","Visually Interpretable Representation Learning for Depression Recognition from Facial Images","IEEE Transactions on Affective Computing","","1949-3045","10.1109/TAFFC.2018.2828819","","Recent evidence in mental health assessment have demonstrated that facial appearance could be highly indicative of depressive disorder. While previous methods based on the facial analysis promise to advance clinical diagnosis of depressive disorder in a more efficient and objective manner, challenges in visual representation of complex depression pattern prevent widespread practice of automated depression diagnosis. In this paper, we present a deep regression network termed DepressNet to learn a depression representation with visual explanation. Specifically, a deep convolutional neural network equipped with a global average pooling layer is first trained with facial depression data, which allows for identifying salient regions of input image in terms of its severity score based on the generated depression activation map (DAM). We then propose a multi-region DepressNet, with which multiple local deep regression models for different face regions are jointly leaned and their responses are fused to improve the overall recognition performance. We evaluate our method on two benchmark datasets, and the results show that our method significantly boosts state-of-the-art performance of the visual-based depression recognition. Most importantly, the DAM induced by our learned deep model may help reveal the visual depression pattern on faces and understand the insights of automated depression diagnosis.","2020-07","2021-06-04 18:20:08","2021-06-04 18:20:20","","542-552","","3","11","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Affective Computing","","C:\Users\Asus\Zotero\storage\ZM4A54GB\8344107.html","","","Feature extraction; Visualization; Image recognition; Computer architecture; deep convolutional neural network; depression activation map; Depression recognition; Face; face recognition; Face recognition; Videos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Q8EK4AN","journalArticle","2019","Kumar, Devinder; Sankar, Vignesh; Clausi, David; Taylor, Graham W.; Wong, Alexander","SISC: End-to-End Interpretable Discovery Radiomics-Driven Lung Cancer Prediction via Stacked Interpretable Sequencing Cells","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2945524","","Lung cancer is the leading cause of cancer-related death worldwide. Computer-aided diagnosis (CAD) systems have shown significant promise in recent years for facilitating the effective detection and classification of abnormal lung nodules in computed tomography (CT) scans. While hand-engineered radiomic features have been traditionally used for lung cancer prediction, there have been significant recent successes achieving state-of-the-art results in the area of discovery radiomics. Here, radiomic sequencers comprising of highly discriminative radiomic features are discovered directly from archival medical data. However, the interpretation of predictions made using such radiomic sequencers remains a challenge. A novel end-to-end interpretable discovery radiomics-driven lung cancer prediction pipeline has been designed, build, and tested. The radiomic sequencer being discovered possesses a deep architecture comprised of stacked interpretable sequencing cells (SISC). The SISC architecture is shown to outperform previous approaches while providing more insight in to its decision making process. The SISC radiomic sequencer is able to achieve state-of-the-art results in lung cancer prediction, and also offers prediction interpretability in the form of critical response maps. The critical response maps are useful for not only validating the predictions of the proposed SISC radiomic sequencer, but also provide improved radiologist-machine collaboration for effective diagnosis.","2019","2021-06-04 18:20:08","2021-06-04 18:20:21","","145444-145454","","","7","","","SISC","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\V4QJW3DN\Kumar et al. - 2019 - SISC End-to-End Interpretable Discovery Radiomics.pdf; C:\Users\Asus\Zotero\storage\R44D78XR\8859176.html","","","Biomedical imaging; Feature extraction; Computed tomography; Lung; Cancer; radiomics; cancer; discovery radiomics; interpretable; nodule; Sequential analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W2GJHMIR","journalArticle","2020","Abid, Firas Ben; Sallem, Marwen; Braham, Ahmed","A A A Robust Interpretable Deep Learning for Intelligent Fault Diagnosis of Induction Motors","IEEE Transactions on Instrumentation and Measurement","","1557-9662","10.1109/TIM.2019.2932162","","In modern manufacturing processes, motivations for automatic fault diagnosis (FD) are increasingly growing as a result of the great trends toward achieving zero breakdowns. Induction motors (IMs) represent a critical part in most of the applications. Due to its high potential of automatic feature extraction, the deep learning (DL)-based FD of IM has recently been introduced and has essentially emphasized on the diagnosis using the vibration analysis. However, this approach has not received considerable attention when using the current analysis, although it represents a cost-effective alternative. Moreover, the already implemented DL architectures are still suffering from lack of physical interpretability. In this article, a new DL architecture called deep-SincNet is implemented for a multi-FD task. The proposed end-to-end scheme automatically learns the fault features from the raw motor current and accordingly finalizes the FD process. A high accuracy for several separated and combined faults, a more physical interpretability, a high robustness against noisy environments, and a significant gain in implementation cost prove the competitive performance of the proposed approach.","2020-06","2021-06-04 18:20:08","2021-06-15 10:55:47","","3506-3515","","6","69","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Instrumentation and Measurement","","C:\Users\Asus\Zotero\storage\AC8RCDL9\8782837.html","","","Feature extraction; Convolution; convolutional neural network (CNN); Induction motors; Bars; Bearing fault; broken rotor bar; combined faults; condition monitoring; current analysis; deep learning (DL); Digital filters; Filter banks; induction motor (IM); Rotors","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3UM9U7UJ","journalArticle","2019","Guo, Wei; Ge, Wei; Cui, Lizhen; Li, Hui; Kong, Lanju","An Interpretable Disease Onset Predictive Model Using Crossover Attention Mechanism From Electronic Health Records","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2928579","","Analysis of patients' Electronic Health Records (EHRs) can help guide the prevention of diseases and personalization of treatment. Therefore, it is an important task to predict the disease onset information (referred to as medical codes in this paper) within the upcoming visit based on patients' EHR data. In order to achieve this objective, the real-time nature and high dimensionality of EHR data must be addressed. Moreover, the prediction results of the model must be interpretable. Existing methods mainly use Recurrent Neural Networks (RNNs) to model EHR data and adopt attention mechanism to provide interpretability. However, diagnosis and treatment information have usually been regarded as the same kind of information, the difference and relationship between the two parts being ignored. This has led to unclear analysis about the patient's disease development and inaccurate prediction results. To address this limitation, we propose a CrossOver Attention Model (COAM). This model adopts two RNNs to process diagnosis and treatment information, respectively, and then deploys a crossover attention mechanism to improve prediction accuracy by leveraging the correlation between the two parts of information. It can learn effective representations of personal medical diagnosis and treatment, and provide interpretable prediction results. Experiments demonstrate that COAM can significantly improve the accuracy of prediction and provide clinically meaningful explanations.","2019","2021-06-04 18:20:08","2021-06-04 18:20:21","","134236-134244","","","7","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\SZEXV4TV\Guo et al. - 2019 - An Interpretable Disease Onset Predictive Model Us.pdf; C:\Users\Asus\Zotero\storage\KDG893RQ\8761846.html","","","Deep learning; Diseases; Medical diagnostic imaging; Predictive models; Data mining; attention mechanism; Healthcare informatics; recurrent neural networks; Recurrent neural networks; separation of medical information","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DE4WX2WI","journalArticle","2019","Colopy, Glen Wright; Roberts, Stephen J.; Clifton, David A.","Gaussian Processes for Personalized Interpretable Volatility Metrics in the Step-Down Ward x","IEEE Journal of Biomedical and Health Informatics","","2168-2208","10.1109/JBHI.2019.2890823","","Patients in a hospital step-down unit require a level of care that is between that of the intensive care unit (ICU) and that of the general ward. While many patients remain physiologically stabilized, others will suffer clinical emergencies and be readmitted to the ICU, with a subsequent high risk of mortality. Had the associated physiological deterioration been detected early, the emergency may have been less severe or avoided entirely. Current clinical monitoring is largely heuristic, requiring manual calculation of risk scores and the use of heuristic decision criteria. Technical drawbacks include ignoring the time-series dynamics of physiological measurements, and lacking patient-specificity (i.e., personalization of models to the individual patient). In this paper, we demonstrate how Gaussian process regression models can supplement current monitoring practice by providing interpretable and intuitive illustrations of erratic vital-sign volatility. These personalized volatility metrics may provide significantly advanced warning of deterioration, while minimizing the false alarms that induce so-called alarm fatigue. While many AI-based approaches to healthcare are criticized for being uninterpretable “blackbox” methods, the cause of alarms generated from the proposed methods are explicitly interpretable and intuitive. We conclude that intelligent computational inference using methods such as those proposed can enhance current clinical decision making and potentially save lives.","2019-05","2021-06-04 18:20:08","2021-06-06 13:37:13","","949-959","","3","23","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Journal of Biomedical and Health Informatics","","C:\Users\Asus\Zotero\storage\HZ5ITZ3C\Colopy et al. - 2019 - Gaussian Processes for Personalized Interpretable .pdf; C:\Users\Asus\Zotero\storage\6UGHRQRF\8621007.html","","","Monitoring; Hospitals; Biomedical monitoring; forecasting; Gaussian processes; Ground penetrating radar; Informatics; patient monitoring; Precision medicine; statistical learning; time series analysis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6NMIL2P8","journalArticle","2019","Kumar, Devinder; Taylor, Graham W.; Wong, Alexander","Discovery Radiomics With CLEAR-DR: Interpretable Computer Aided Diagnosis of Diabetic Retinopathy","IEEE Access","","2169-3536","10.1109/ACCESS.2019.2893635","","Radiomics-driven computer aided diagnosis (CAD) has shown considerable promise in recent years as a potential tool for improving clinical decision support in medical oncology, particularly those based around the concept of discovery radiomics, where radiomic sequencers are discovered through the analysis of medical imaging data. One of the main limitations, with current CAD approaches, is that it is very difficult to gain insight or rationale as to how decisions are made, thus limiting their utility to clinicians. In this paper, we propose CLEAR-DR, a novel interpretable CAD system based on the notion of CLass-Enhanced Attentive Response Discovery Radiomics for the purpose of clinical decision support for diabetic retinopathy. In addition to disease grading via the discovered deep radiomic sequencer, the CLEAR-DR system also produces a visual interpretation of the decision-making process to provide better insight and understanding of the decision-making process of the system. We demonstrate the effectiveness and utility of the proposed CLEAR-DR system of enhancing the interpretability of diagnostic grading results for the application of diabetic retinopathy grading. CLEAR-DR can act as a potentially powerful tool to address the uninterpretability issue of current CAD systems, thus improving their utility to clinicians.","2019","2021-06-04 18:20:08","2021-06-04 18:20:21","","25891-25896","","","7","","","Discovery Radiomics With CLEAR-DR","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\ACSGK8GB\Kumar et al. - 2019 - Discovery Radiomics With CLEAR-DR Interpretable C.pdf; C:\Users\Asus\Zotero\storage\MCN2P8P8\8620505.html","","","Visualization; CLEAR; Decision making; diabetes; Diabetes; Kernel; radiomics; Retina; Retinopathy; visualization","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AAEJ4EXF","journalArticle","2018","El-Sappagh, Shaker; Alonso, José M.; Ali, Farman; Ali, Amjad; Jang, Jun-Hyeog; Kwak, Kyung-Sup","An Ontology-Based Interpretable Fuzzy Decision Support System for Diabetes Diagnosis","IEEE Access","","2169-3536","10.1109/ACCESS.2018.2852004","","Diabetes is a serious chronic disease. The importance of clinical decision support systems (CDSSs) to diagnose diabetes has led to extensive research efforts to improve the accuracy, applicability, interpretability, and interoperability of these systems. However, this problem continues to require optimization. Fuzzy rule-based systems are suitable for the medical domain, where interpretability is a main concern. The medical domain is data-intensive, and using electronic health record data to build the FRBS knowledge base and fuzzy sets is critical. Multiple variables are frequently required to determine a correct and personalized diagnosis, which usually makes it difficult to arrive at accurate and timely decisions. In this paper, we propose and implement a new semantically interpretable FRBS framework for diabetes diagnosis. The framework uses multiple aspects of knowledge-fuzzy inference, ontology reasoning, and a fuzzy analytical hierarchy process (FAHP) to provide a more intuitive and accurate design. First, we build a two-layered hierarchical and interpretable FRBS; then, we improve this by integrating an ontology reasoning process based on SNOMED CT standard ontology. We incorporate FAHP to determine the relative medical importance of each sub-FRBS. The proposed system offers numerous unique and critical improvements regarding the implementation of an accurate, dynamic, semantically intelligent, and interpretable CDSS. The designed system considers the ontology semantic similarity of diabetes complications and symptoms concepts in the fuzzy rules' evaluation process. The framework was tested using a real data set, and the results indicate how the proposed system helps physicians and patients to accurately diagnose diabetes mellitus.","2018","2021-06-04 18:20:08","2021-06-04 18:20:22","","37371-37394","","","6","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Access","","C:\Users\Asus\Zotero\storage\PRRMW47D\El-Sappagh et al. - 2018 - An Ontology-Based Interpretable Fuzzy Decision Sup.pdf; C:\Users\Asus\Zotero\storage\GHPR3ZE9\8403911.html","","","Diseases; Medical diagnostic imaging; Diabetes; Clinical decision support system; Cognition; diabetes diagnosis; fuzzy inference system; fuzzy interpretability; Ontologies; ontology reasoning; Semantics","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"W63AUKWE","journalArticle","2018","Brisimi, Theodora S.; Xu, Tingting; Wang, Taiyao; Dai, Wuyang; Adams, William G.; Paschalidis, Ioannis Ch.","Predicting Chronic Disease Hospitalizations from Electronic Health Records: An Interpretable Classification Approach","Proceedings of the IEEE","","1558-2256","10.1109/JPROC.2017.2789319","","Urban living in modern large cities has significant adverse effects on health, increasing the risk of several chronic diseases. We focus on the two leading clusters of chronic diseases, heart disease and diabetes, and develop data-driven methods to predict hospitalizations due to these conditions. We base these predictions on the patients' medical history, recent and more distant, as described in their Electronic Health Records (EHRs). We formulate the prediction problem as a binary classification problem and consider a variety of machine learning methods, including kernelized and sparse Support Vector Machines (SVMs), sparse logistic regression, and random forests. To strike a balance between accuracy and interpretability of the prediction, which is important in a medical setting, we propose two novel methods: K -LRT, a likelihood ratio test-based method, and a Joint Clustering and Classification (JCC) method which identifies hidden patient clusters and adapts classifiers to each cluster. We develop theoretical out-of-sample guarantees for the latter method. We validate our algorithms on large data sets from the Boston Medical Center, the largest safety-net hospital system in New England.","2018-04","2021-06-04 18:20:08","2021-06-07 17:25:33","","690-707","","4","106","","","Predicting Chronic Disease Hospitalizations from Electronic Health Records","","","","","","","","","","","","IEEE Xplore","","Conference Name: Proceedings of the IEEE","","C:\Users\Asus\Zotero\storage\JLKNC3Z7\8283520.html; C:\Users\Asus\Zotero\storage\Q8DJYVLM\Brisimi et al. - 2018 - Predicting Chronic Disease Hospitalizations from E.pdf","","","Diseases; machine learning; Medical services; Machine learning; Predictive models; Hospitals; Diabetes; Classification; Clustering methods; electronic health records (EHRs); Electronic healthcare; heart disease; predictive analytics; Smart cities; smart city; smart health","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLT7NV55","journalArticle","2015","Wong, Shen Yuong; Yap, Keem Siah; Yap, Hwa Jen; Tan, Shing Chiang; Chang, Siow Wee","A A On Equivalence of FIS and ELM for Interpretable Rule-Based Knowledge Representation","IEEE Transactions on Neural Networks and Learning Systems","","2162-2388","10.1109/TNNLS.2014.2341655","","This paper presents a fuzzy extreme learning machine (F-ELM) that embeds fuzzy membership functions and rules into the hidden layer of extreme learning machine (ELM). Similar to the concept of ELM that employed the random initialization technique, three parameters of F-ELM are randomly assigned. They are the standard deviation of the membership functions, matrix-C (rule-combination matrix), and matrix-D [don't care (DC) matrix]. Fuzzy if-then rules are formulated by the rule-combination Matrix of F-ELM, and a DC approach is adopted to minimize the number of input attributes in the rules. Furthermore, F-ELM utilizes the output weights of the ELM to form the target class and confidence factor for each of the rules. This is to indicate that the corresponding consequent parameters are determined analytically. The operations of F-ELM are equivalent to a fuzzy inference system. Several benchmark data sets and a real world fault detection and diagnosis problem have been used to empirically evaluate the efficacy of the proposed F-ELM in handling pattern classification tasks. The results show that the accuracy rates of F-ELM are comparable (if not superior) to ELM with distinctive ability of providing explicit knowledge in the form of interpretable rule base.","2015-07","2021-06-04 18:20:08","2021-06-15 10:58:52","","1417-1430","","7","26","","","","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Neural Networks and Learning Systems","","C:\Users\Asus\Zotero\storage\LJAV77AF\6877713.html","","","Computational modeling; Training; Artificial neural networks; Accuracy; Extreme learning machine (ELM); fuzzy inference system (FIS); Fuzzy logic; Neurons; pattern classification; Pragmatics; rule based","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XS7E9SNC","journalArticle","2015","Deng, Zhaohong; Cao, Longbing; Jiang, Yizhang; Wang, Shitong","Minimax Probability TSK Fuzzy System Classifier: A More Transparent and Highly Interpretable Classification Model","IEEE Transactions on Fuzzy Systems","","1941-0034","10.1109/TFUZZ.2014.2328014","","When an intelligent model is used for medical diagnosis, it is desirable to have a high level of interpretability and transparent model reliability for users. Compared with most of the existing intelligence models, fuzzy systems have shown a distinctive advantage in their interpretabilities. However, how to determine the model reliability of a fuzzy system trained for a recognition task is still an unsolved problem at present. In this study, a minimax probability Takagi-Sugeno-Kang (TSK) fuzzy system classifier called MP-TSK-FSC is proposed to train a fuzzy system classifier and determine the model reliability simultaneously. For the proposed MP-TSK-FSC, a lower bound of correct classification can be presented to the users to characterize the reliability of the trained fuzzy classifier. Thus, the obtained classifier has the distinctive characteristics of both a high level of interpretability and transparent model reliability inherited from the fuzzy system and minimax probability learning strategy, respectively. Our experiments on synthetic datasets and several real-world datasets for medical diagnosis have confirmed the distinctive characteristics of the proposed method.","2015-08","2021-06-04 18:20:08","2021-06-04 18:20:22","","813-826","","4","23","","","Minimax Probability TSK Fuzzy System Classifier","","","","","","","","","","","","IEEE Xplore","","Conference Name: IEEE Transactions on Fuzzy Systems","","C:\Users\Asus\Zotero\storage\U5827FLC\6824841.html","","","Reliability; Classification; Clustering algorithms; Fuzzy systems; medical diagnosis; Medical diagnosis; minimax probability decision; Optimization; Partitioning algorithms; Takagi–Sugeno–Kang (TSK) fuzzy system; Training data","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""